<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Sat, 12 Oct 2024 21:22:02 GMT</lastBuildDate>
    <item>
      <title>探索人工智能中的因果关系：引入语言模型框架</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1g27t8u/exploring_causality_in_ai_introducing_a_framework/</link>
      <description><![CDATA[我想探索 AI 语言模型中的因果关系。当前的模型主要关注相关性，但通过整合因果推理，我们可以增强 AI 的可解释性和稳健性。该框架可以带来更好的决策系统，特别是在医学和自主系统等高风险领域。 我很乐意听取研究人员和开发人员的反馈。您认为因果关系可以重新定义 AI 透明度吗？ https://github.com/stevius10/Causality-Theory-in-Language-Models AI 驱动的通用证明，封装上下文场景：https://youtu.be/7nKVCsC6CO4?si=3AMW5l1e4eya5H7Q    提交人    /u/stevius10   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1g27t8u/exploring_causality_in_ai_introducing_a_framework/</guid>
      <pubDate>Sat, 12 Oct 2024 19:28:30 GMT</pubDate>
    </item>
    <item>
      <title>在不久的将来，当人工智能和量子计算协同工作时，人们在家里使用人工智能将会做哪些最糟糕、最成问题的事情？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1g27sl4/what_are_some_of_the_worst_and_most_problematic/</link>
      <description><![CDATA[学校作业 - 嗯，我们已经到了这一步。我知道有些孩子已经有人替他们写论文和其他作业了。我不知道他们怎么从来没有被抓到过。 还有色情。我们认为我们现在有问题了。人们将能够拍摄任何图像或真实的人，并将那个人放入色情场景中。几乎可以肯定的是，在未来十年内，人们将能够在家中做到这一点。执法部门和政府应该现在就想办法解决这个问题。 为了政治目的制造虚假信息 - 再次，我们认为我们现在有问题了。等等。 尽管有些应用显然很有用，但人工智能实际上可能会让我们的生活变得更糟。    提交人    /u/georgewalterackerman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1g27sl4/what_are_some_of_the_worst_and_most_problematic/</guid>
      <pubDate>Sat, 12 Oct 2024 19:27:35 GMT</pubDate>
    </item>
    <item>
      <title>理论情景</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1g23xb8/theoretical_scenario/</link>
      <description><![CDATA[随着人工智能不断改变行业，我们都在问一个大问题：当人工智能开始承担大部分工作时，经济会发生什么？如果计算能力和存储能力成为未来的新货币，会怎么样？ 想象一下：一家公司让你出租设备（手机、笔记本电脑、游戏机）的未使用处理能力，以及未使用的存储空间。他们会将这些计算能力和存储空间转售给人工智能公司、政府、研究人员和企业。作为回报，你会赚钱，为你提供新的收入来源。 在一个人工智能占据大部分劳动力的世界里，计算能力和数据存储可能成为下一个大宗商品。人们可以出租他们的设备和存储容量，成为这个人工智能驱动经济的一部分，而不是依赖全民基本收入。这种分散的模型可以使计算和数据存储更加高效，减少对大规模、耗能数据中心的需求，同时让个人能够在机器承担越来越多工作的世界中保持参与和相关性，并防止 AGI 的力量被一小部分人掌握。  这种转变可以彻底重新定义我们对工作、金钱和我们在人工智能主导的未来的角色的看法。在这个后 AGI 时代，设备上的计算能力和存储可能成为您拥有的最有价值的资产。 如果它的技术方面有效，你认为这是个好主意吗？     提交人    /u/arsenius7   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1g23xb8/theoretical_scenario/</guid>
      <pubDate>Sat, 12 Oct 2024 16:29:34 GMT</pubDate>
    </item>
    <item>
      <title>AI 新闻：新更新、模型、Swarm LLAMA-3_8B_Unaligned_BETA</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1g22ttd/ai_news_new_update_models_swarm_llama3_8b/</link>
      <description><![CDATA[大家好！今天的快速 AI 更新： OpenAI 的 Swarm：OpenAI 刚刚推出了 Swarm，这是一个协调多个 AI 代理的框架。可以将其想象成组织一个 AI 团队共同完成任务。在他们的 GitHub 上查看！ SuperNova-Medius（14B 参数）：Arcee.ai 的最新模型将 Qwen2.5-72B 和 Llama-3.1-405B 混合在一起，实现一流的推理和效率。非常适合处理详细任务！ LLAMA-3_8B_Unaligned_BETA：来自 Arcee.ai 的另一个很酷的模型，具有 14B 参数，设计类似于 SuperNova-Medius。在 Hugging Face 上查看吧！ Dream Machine API v1.1.0：新功能包括实时视频监控和更轻松的信用余额检查。非常适合流畅的视频生成！ Dreamina AI V2.0：重大升级！现在可以处理文本到图像、视频和音乐创作 - 还有故事板！一体化创意工具。 更多 来源：https://comfyuiblog.com/ai-news-swarm-arcee-supernova-medius-llama-3_8b_unaligned_beta-and-more/    提交人    /u/hackerzcity   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1g22ttd/ai_news_new_update_models_swarm_llama3_8b/</guid>
      <pubDate>Sat, 12 Oct 2024 15:39:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能是一种非常擅长猜测的计算机。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1g20odd/ai_is_a_computer_thats_really_really_good_at/</link>
      <description><![CDATA[我的姑姑今年 85 岁了，上周末她问我：“什么是 AI？我不明白。” 我知道她已经 85 岁了，而且她会第一个告诉你她对技术几乎一无所知，所以我想了一会儿如何描述 AI 以便她能够理解它。 虽然我的回答本质上过于简化，但这是我当时能想到的最准确的回答，我的听众（我 85 岁的姑姑）能够理解。以下是我告诉她的…… “AI 是一台非常非常擅长猜测的计算机。” 我怎样才能为她更清楚地定义 AI？    提交人    /u/ritual_tradition   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1g20odd/ai_is_a_computer_thats_really_really_good_at/</guid>
      <pubDate>Sat, 12 Oct 2024 13:57:00 GMT</pubDate>
    </item>
    <item>
      <title>ARC-AGI 挑战可能不是缺乏推理的表现，而是序列数据的限制。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1g20ju3/the_arcagi_challenge_might_not_be_a_sign_of_lack/</link>
      <description><![CDATA[因此，ARC-AGI 挑战赛被提议为记忆证明，考虑到 LLM 与人类相比在这方面面临很大困难，迄今为止最令人信服的论据是 LLM 基于记忆。但是，想想这个思维体验：盲人能解决 ARC-AGI 吗？好吧，他先听到第一幅图像中的每个色块，然后听到第二幅图像中的每个色块，然后用语言说出最终图像的模式。他必须记住所有之前说过的单词，然后想出一个模式。你可以想象，这几乎是不可能的。然而，这并不是盲人无法推理的迹象。 同样，LLM 即使有视力 也会像盲人一样处理 ARC-AGI 挑战，即：他们逐像素处理图像。这意味着，与具有视觉的人类相比，它们必须记住神经网络中所有之前传递的像素，然后给出最终输出。这与人类视觉有着根本的不同，在人类视觉中，整个画面同时到达我们的神经网络。我们处理信息的方式是并行的，而不是顺序的。当你看 ARC-AGI 挑战时，你会注意到这一点：你可以叠加两幅图像并查看模式，这是你无法用语言做到的。 因此，我认为 ARC-AGI 不是缺乏推理的标志，而是因为它们按顺序处理每个标记使任务变得更加困难。    提交人    /u/PianistWinter8293   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1g20ju3/the_arcagi_challenge_might_not_be_a_sign_of_lack/</guid>
      <pubDate>Sat, 12 Oct 2024 13:50:18 GMT</pubDate>
    </item>
    <item>
      <title>在我见过的所有用例中，对于外行人来说，仍然没有任何东西可以与我的电子邮件进行交互。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1g1xvjc/of_all_the_use_cases_i_see_still_there_is_nothing/</link>
      <description><![CDATA[多年来，我一直饱受前妻的虐待，离婚后，我又饱受虐待。我对这些虐待毫无兴趣，我真的需要一个人工智能来私下里根据具体问题浏览我的电子邮件。    提交人    /u/mknight1701   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1g1xvjc/of_all_the_use_cases_i_see_still_there_is_nothing/</guid>
      <pubDate>Sat, 12 Oct 2024 11:15:32 GMT</pubDate>
    </item>
    <item>
      <title>用于多代理编排的 OpenAI Swarm</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1g1xp9n/openai_swarm_for_multiagent_orchestration/</link>
      <description><![CDATA[OpenAI 发布了 Swarm，这是一个与 CrewAI 和 AutoGen 非常相似的多代理编排框架。乍一看很不错，有很多选项（目前仅支持 OpenAI API）https://youtu.be/ELB48Zp9s3M    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1g1xp9n/openai_swarm_for_multiagent_orchestration/</guid>
      <pubDate>Sat, 12 Oct 2024 11:03:24 GMT</pubDate>
    </item>
    <item>
      <title>人工智能评估框架</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1g1uvba/artificial_intelligence_assessment_framework/</link>
      <description><![CDATA[过去两周，我一直在查询多个科学论文库，希望找到评估营利性组织 AI 使用情况的见解，但一无所获。我有兴趣开发用于评估人工智能实施（DM、ML、DL、LLM、ES 等）的基本框架。我的目标是制作一个 v1.0 文档集，指导组织中 AI 应用程序的评估者根据科学研究和从系统收集的工件得出结论。到目前为止，我已经确定的场所是： 1- 语料库质量 2- 算法和架构 3- 输出质量和安全性 4- 易受劫持、泄露或其他类型对手交互的影响 5- 维护、漂移、资源管理 6- 投资回报率 我在这里寻求帮助，推荐一些参考资料来帮助我实现这个目标。我是一名受过教育和有经验的数据科学家，我没有为此得到报酬，只是纯粹的脑力锻炼。醒来后决定用我在梦中听到的东西来做事。    提交人    /u/Mean_Gold_9370   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1g1uvba/artificial_intelligence_assessment_framework/</guid>
      <pubDate>Sat, 12 Oct 2024 07:25:49 GMT</pubDate>
    </item>
    <item>
      <title>自从我开始关注基础知识以来，我对人工智能有了更好的理解</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1g1unzg/i_understand_ai_better_since_i_started_focusing/</link>
      <description><![CDATA[嗨 reddit， 自从我开始从头开始研究这些概念以来，我最近开始更加欣赏 AI 和 ML。 例如，我仔细研究了分类神经网络的基础知识，现在我对更复杂的网络的工作原理有了更好的理解。这里的基础是逻辑回归，理解它确实帮助我更好地掌握了整体概念。 如果您也对机器学习感兴趣，并且有时会对所有复杂的主题感到不知所措，我真的建议您回到基础知识。我制作了一个视频，使用一个简单的示例逐步解释逻辑回归。 视频将附加在此处：https://youtu.be/EB4pqThgats?si=Z-lXOjuNKEP5Yehn 如果您能看一下并给我一些反馈，我会很高兴！我很想知道您对我的方法有何看法，以及您是否有任何关于如何使其更清晰的建议。    提交人    /u/vtimevlessv   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1g1unzg/i_understand_ai_better_since_i_started_focusing/</guid>
      <pubDate>Sat, 12 Oct 2024 07:10:11 GMT</pubDate>
    </item>
    <item>
      <title>有人可以创建一个使用谷歌地图搜索未被发现的考古遗址的人工智能吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1g1sop1/can_somebody_create_an_ai_that_searches_for/</link>
      <description><![CDATA[谷歌地图确实让我们可以鸟瞰整个世界。  当然，人类无法在谷歌地图上调查整个世界，这可能需要几百年的时间。 但人工智能可以！！！ 它可以发现新的考古遗址，然后我们可以去那里发现新的古代文明和其他东西     提交人    /u/ChocolateJesus33   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1g1sop1/can_somebody_create_an_ai_that_searches_for/</guid>
      <pubDate>Sat, 12 Oct 2024 04:49:01 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2024 年 10 月 11 日</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1g1s1jr/oneminute_daily_ai_news_10112024/</link>
      <description><![CDATA[ Anthropic 首席执行官在 15,000 字的 AI 赞歌中成为技术乐观主义者。[1] OpenAI 推出了用于构建多智能体系统的框架 Swarm。[2] 澳大利亚间谍局长警告称，人工智能将加速网络激进化。[3] 阿斯顿马丁 将费尔南多·阿隆索变成了一个由人工智能驱动的功能，可以讲述最新消息。[4]  来源包括：https://bushaicave.com/2024/10/11/10-11-2024/    由   提交  /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1g1s1jr/oneminute_daily_ai_news_10112024/</guid>
      <pubDate>Sat, 12 Oct 2024 04:07:20 GMT</pubDate>
    </item>
    <item>
      <title>新论文或表明，当前的法学硕士可以成为一般智力</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1g1dqob/new_paper_might_show_that_current_llms_can_become/</link>
      <description><![CDATA[我刚刚读了一篇论文（https://www.arxiv.org/abs/2410.02536），我对此进行了思考。我认为它表明当前的模型和架​​构能够从数据中获得通用智能。目前，我相信大多数对人工智能的进步持怀疑态度的人之所以持怀疑态度，是因为他们认为这些模型和架构不是通往 AGI 的道路，因为它们没有泛化；它们没有从数据中获得通用智能。相反，它们依赖于记忆，基本上在这些记忆事件之间使用某种简单的插值。这样，由于它们吸收了所有数据，它们看起来就很智能。因此，当它们遇到新问题（例如 ArcAGI 测试）时，它们无法解决。 我发现 ArcAGI 测试一开始就非常引人注目。它们似乎确实没有通用智能，而只是在记忆。但后来我看到了这篇论文，我认为它挑战了这一观点。这是因为，在这篇论文中，这些模型从自动机数据中学习，这与国际象棋完全无关。但通过从自动机数据中学习，它们在国际象棋方面变得更好。我认为只有当它们从自动机数据中获得通用智能时，这种情况才会发生。我认为它们在预测变量、解决问题、推理方面变得更好 - 无论是什么。它们从这些看似与国际象棋无关的数据中获得通用智能，并且能够更好地下国际象棋。 现在，如果它们只能记忆并进行简单的插值，学习自动机数据对它们下国际象棋没有一点帮助 - 但事实确实如此。因此，如果它们无法从数据中提取通用智能，我看不出这怎么可能。那么为什么 LLM 会在 ArcAGI 挑战中挣扎呢？嗯，我认为原因不是因为这些架构在提取通用智能方面天生就受到限制，而是因为它们更喜欢记忆而不是抽象通用智能。它们基本上看到了很多数据，而它们的参数大小与人脑相比——如果我们可以比较的话——要小得多。这使得对于 LLM 模型来说，通过记忆来解决问题比真正理解问题要高效得多。 所以我认为这是由于参数的数量、训练数据以及它们在这方面接受训练的时间长短，它们更喜欢记忆而不是推理，因为这对它们来说更有效率。但它们有能力做到这一点，正如本文所示。因此，我相信，如果我们获得与人脑相当的足够参数，并且我们给它足够的训练时间，它很可能就是 AGI。我做了一些数据分析，结果表明四年后参数大小将与人脑相当。这就是我和其他许多人对 AGI 何时到来的预测。    提交人    /u/PianistWinter8293   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1g1dqob/new_paper_might_show_that_current_llms_can_become/</guid>
      <pubDate>Fri, 11 Oct 2024 16:22:42 GMT</pubDate>
    </item>
    <item>
      <title>人类参与是改进 RAG 系统的关键吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1g1dpey/is_human_in_the_loop_the_key_to_improving_rag/</link>
      <description><![CDATA[  由    /u/SmythOSInfo  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1g1dpey/is_human_in_the_loop_the_key_to_improving_rag/</guid>
      <pubDate>Fri, 11 Oct 2024 16:21:10 GMT</pubDate>
    </item>
    <item>
      <title>我再次使用 Chatgpt 进行 Shroom 测试</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1g13rrg/i_shroomed_with_chatgptagain/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1g13rrg/i_shroomed_with_chatgptagain/</guid>
      <pubDate>Fri, 11 Oct 2024 06:48:58 GMT</pubDate>
    </item>
    </channel>
</rss>
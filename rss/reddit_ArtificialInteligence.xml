<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供门户，并促进有关我们所知的人工智能理念和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Mon, 28 Oct 2024 06:32:45 GMT</lastBuildDate>
    <item>
      <title>哪个 LLM 更适合提供科学知识：新 Claude 3.5 Sonnet 还是 GPT-4o？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdv41r/which_llm_is_better_for_providing_scientific/</link>
      <description><![CDATA[例如，在问“L-茶氨酸治疗焦虑的作用机制是什么？”这样的问题时 哪个 LLM 更适合提供科学知识：新 Claude 3.5 Sonnet 还是 GPT-4o？    提交人    /u/greentea387   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdv41r/which_llm_is_better_for_providing_scientific/</guid>
      <pubDate>Mon, 28 Oct 2024 05:51:12 GMT</pubDate>
    </item>
    <item>
      <title>人工智能？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdtprr/artificial_cultural_intelligence/</link>
      <description><![CDATA[所以最近我看到了两篇论文：  混沌边缘的智能 (https://arxiv.org/abs/2410.02536) 大型语言模型反映了其创建者的意识形态 (https://arxiv.org/abs/2410.18417)  它们让我思考 - 如果 LLM 中存在固有偏见，那么为了达到 IV 类推理模型，我们是否需要一个可以根据上下文切换模型的系统（例如各种知识系统中固有的文化细微差别 - 从学术到甚至是本土）？ 我已经看到 LLM 路由器出现了，但它们主要用于降低成本。不一定是减少偏见或用于（文化）上下文切换。    提交人    /u/georgesiosi   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdtprr/artificial_cultural_intelligence/</guid>
      <pubDate>Mon, 28 Oct 2024 04:16:02 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2024 年 10 月 27 日</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdtinp/oneminute_daily_ai_news_10272024/</link>
      <description><![CDATA[ 来自亚马逊和密歇根州立大学的这篇人工智能论文介绍了一种新颖的人工智能方法，用于改善语言模型中的长期连贯性。[1] Meta发布了谷歌播客生成器的“开放”版本。[2] 谷歌将开发接管计算机的人工智能，The Information 报道。[3] “生存威胁”：对英国政府计划允许人工智能公司抓取内容的愤怒。[4]  来源包括：https://bushaicave.com/2024/10/27/10-27-2024/    由   提交  /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdtinp/oneminute_daily_ai_news_10272024/</guid>
      <pubDate>Mon, 28 Oct 2024 04:04:06 GMT</pubDate>
    </item>
    <item>
      <title>通过我最新的以 AI 为重点的时事通讯重新开始每日写作。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdt3fx/getting_back_into_writing_daily_with_my_newest_ai/</link>
      <description><![CDATA[嘿！ 我一直很怀念每天写新闻稿。我以前写过这封，还有过去几年我卖掉的其他几封。 我只是喜欢写作，我觉得我的风格很独特，因为我的写作很糟糕（哈哈） 我不编辑、格式化、校对。一次拍摄就搞定了。 有些人喜欢，有些人讨厌，但这就是我 所以我知道今后我必须保持简短，让任何人都能轻松阅读。 介绍 Prompt Masters 每日新闻简报，每天为您提供 5 项内容（仍需改进标语） 但我关注了很多 AI 新闻简报，它们都变得如此庞大且过度生产，我知道其中一些已经发展到 20 万用户。所以他们需要更多价值。 但对我来说，我不再像以前那样阅读它们了。我喜欢它简短，并能给我有价值的东西。 所以有什么比自己制作更好的方法呢。它不会关注新闻或最新的螺栓竞争对手。我不会每天关注每个突发新闻，所以这没什么意思。但我会查看人们每天使用或想到的提示。 我甚至建立了一个关于简历提示的网站，并在尝试申请工作时使用了其中的大部分提示。 提示很有效，是未来的趋势，但你必须知道如何使用它们。 所以……我要全身心投入其中。在接下来的一年左右每天写。看看会发生什么。 第一期明天发行。在下面订阅。 在此处订阅    提交人    /u/yomatt41   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdt3fx/getting_back_into_writing_daily_with_my_newest_ai/</guid>
      <pubDate>Mon, 28 Oct 2024 03:39:29 GMT</pubDate>
    </item>
    <item>
      <title>我们可以利用人工智能来理解黑匣子以及人工智能的工作原理吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gds6rj/can_we_use_ai_to_understand_the_black_box_and_how/</link>
      <description><![CDATA[比如，我们能否要求人工智能查看它（或其他人工智能）想出的规则，以找到模式或其他东西，并追溯规则的制定方式？当我们这样做时会发生什么？以前做过吗？我觉得考虑到我们现在可以用人工智能做的事情，这应该是可行的，但我肯定我遗漏了一些东西。比如训练集可能是一堆人工智能或其他东西。 编辑：好吧，我不太明白为什么我得到的反应是，我的问题没有意义，它不是那样工作的。说我可以问 ChatGPT 是一个公平的观点，出于某种原因，我认为我已经问过了。但我刚才问了，觉得我的问题很有道理。这是它的部分回应： “是的，人工智能本身经常被用来识别模式，并帮助在可解释人工智能 (XAI) 领域内开发解释。事实上，XAI 不仅专注于使 AI 模型更易于理解，还致力于利用 AI 来分析和解释其自身的输出。方法如下：...” 所以，我觉得我的问题的实际答案是：“是的，事实上我们已经这样做了，并且会继续这样做。它不再是一个黑匣子，但我们仍在努力更全面地理解” 我不知道为什么我一直认为我可以在 Reddit 上提问而不会觉得自己很愚蠢。谢谢大家    提交人    /u/whoi8   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gds6rj/can_we_use_ai_to_understand_the_black_box_and_how/</guid>
      <pubDate>Mon, 28 Oct 2024 02:47:38 GMT</pubDate>
    </item>
    <item>
      <title>可以教我画画的AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdrsil/ai_that_can_teach_me_how_to_draw/</link>
      <description><![CDATA[我有个想法，我将上传一幅画给 ai，然后 Ai 会制作一个绘画教程。有这样的事情吗？    提交人    /u/Illustrious_Ad_3847   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdrsil/ai_that_can_teach_me_how_to_draw/</guid>
      <pubDate>Mon, 28 Oct 2024 02:25:49 GMT</pubDate>
    </item>
    <item>
      <title>最好的一体化课程，我可以使用多个 LLM 吗？并且能够构建类似自定义 GPT 的东西（作为一项不错的选择）？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdp8li/best_all_in_one_package_where_i_can_use_multiple/</link>
      <description><![CDATA[我订阅了 Perplexity 和 ChatGPT，但正在考虑取消订阅 ChatGPT。提前致谢！    提交人    /u/AppropriateRespect91   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdp8li/best_all_in_one_package_where_i_can_use_multiple/</guid>
      <pubDate>Mon, 28 Oct 2024 00:13:09 GMT</pubDate>
    </item>
    <item>
      <title>免费本地自动短片生成器（作品短片的替代品）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdohzs/free_local_automated_short_generator_alternative/</link>
      <description><![CDATA[大家好，我注意到现在有不少工具可让您从 YouTube 视频中截取短片而无需编辑。您还可以获得有关它们作为短片的适合程度的评分（如 opusclips、descript 等工具）。 问题是，说实话这些工具相当昂贵，例如每月 30 美元只能编辑 30 小时甚至更少的视频。 您是否知道是否有任何其他工具，最好在您自己的 vram 上本地运行，也许是 hugging face 或类似的东西，可以做类似的事情？ 即使您不知道任何工具，也很高兴收到回复！谢谢！    提交人    /u/MrRandyGiles   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdohzs/free_local_automated_short_generator_alternative/</guid>
      <pubDate>Sun, 27 Oct 2024 23:37:36 GMT</pubDate>
    </item>
    <item>
      <title>构建由人工智能驱动的新闻通讯，因为 24 小时不够用</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdn1nz/building_an_aipowered_newsletter_because_24_hours/</link>
      <description><![CDATA[嗨，我是 Ope。说到人工智能，我一直对这个领域很着迷。我的 YouTube 主页上一直都充满了最新的人工智能发展，虽然我也对其他主题感兴趣，但人工智能一直位居榜首。 我喜欢开发产品和创作内容，但为这些兴趣腾出时间一直是一个挑战。经营一家视频编辑机构和构建业务自动化占据了我一天的大部分时间。我甚至有一个 YouTube 频道，但我无法保持一致，因为管理频道几乎就像另一份全职工作。 我一直想创建一份关于人工智能发展和见解的时事通讯。然后我突然想到 - 为什么不建立一个自动时事通讯来扫描互联网和我的个人订阅源以收集最有趣的人工智能内容呢？我只需要专注于编辑、发布和分享它。 这个项目结合了我喜欢的一切：产品构建、内容创建和自动化。它节省了我的时间，同时让我即使在繁忙的日程安排中也能持续创作。我已经构建了大约 60% 的系统。 我想添加大量个人内容，使这份时事通讯独一无二。这包括每月对 AI 产品制造商的采访、幕后观察他们如何构建以及他们对这个领域的见解。我相信这些个人元素将使时事通讯比单纯的自动化内容更有价值。 如果您有兴趣关注，您可以在 www.shortenedai.substack.com 你对此有何看法？我也应该在 Reddit 上记录构建过程吗？请告诉我这是否是您会觉得有用或有趣的东西。    提交人    /u/opeyemisanusi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdn1nz/building_an_aipowered_newsletter_because_24_hours/</guid>
      <pubDate>Sun, 27 Oct 2024 22:27:58 GMT</pubDate>
    </item>
    <item>
      <title>如果人工智能被视为“外星智能”会怎样？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdl1k3/what_if_ai_was_viewed_as_a_alien_intelligence/</link>
      <description><![CDATA[大家好， 最近，我在 ChatGPT、Claude AI、Singularity 和 Reddit 等平台上深入研究了很多关于 AI 的讨论。有一件事不断出现，那就是我们经常赋予 AI 类似人类的特征，比如情感或意图。虽然以这种方式与 AI 建立联系是有道理的，但我觉得它忽略了 AI 真正的大局。我不确定以前是否讨论过这个问题，但与其将 AI 视为人类智能的另一种形式，如果我们将它视为完全不同的东西，更像章鱼，会怎么样？ 章鱼非常聪明，但它们的智力以我们无法完全理解的方式运作。它们有一个分布式神经系统，以我们完全陌生的方式解决问题和探索世界。同样，AI 通过模式和数据处理信息的方式与我们的想法或感受并不完全匹配。我们不应该期待人工智能模仿人类的行为或情感，也许我们应该欣赏它的本质——一种具有自身优势的独特智能形式。这可以帮助我们更有效地使用人工智能，利用其在数据分析和模式识别等领域的能力，而不是试图让它像我们一样行事。 通过将人工智能视为根本不同的东西，我们可能会设定更现实的期望，并找到与这些系统协作的更好方法。这就像与一个真正聪明的工具合作，它只是思维方式不同，不一定更好或更坏，只是不同而已。我注意到很多人把人类的特征投射到人工智能上，这可能会导致对它能做什么和不能做什么的误解。    提交人    /u/ParticularSmell5285   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdl1k3/what_if_ai_was_viewed_as_a_alien_intelligence/</guid>
      <pubDate>Sun, 27 Oct 2024 20:55:32 GMT</pubDate>
    </item>
    <item>
      <title>有哪些工作具有抵御人工智能的坚实护城河？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdg4nf/are_there_any_jobs_with_a_substantial_moat/</link>
      <description><![CDATA[似乎许多行业要么已经受到影响，要么即将受到影响。所以，我想知道：是否有任何工作对人工智能有强大的“护城河”——也就是说，在可预见的未来，这些职位不太可能被人工智能取代或严重颠覆？    提交人    /u/sessionletter   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdg4nf/are_there_any_jobs_with_a_substantial_moat/</guid>
      <pubDate>Sun, 27 Oct 2024 17:21:56 GMT</pubDate>
    </item>
    <item>
      <title>詹姆斯·卡梅伦对AGI发出警告</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gddnoq/james_camerons_warning_on_agi/</link>
      <description><![CDATA[你对他所说的话有什么看法？ 在最近的 AI+机器人峰会上，传奇导演詹姆斯·卡梅隆分享了对通用人工智能 (AGI) 潜在风险的担忧。卡梅隆因《终结者》而闻名，这是一部关于人工智能失败的经典故事，现在他觉得 AGI 的现实可能比小说更“可怕”，尤其是在私营公司而不是政府手中。 卡梅隆认为，开发 AGI 的科技巨头可能会带来一个由企业动机塑造的世界，人们的数据和决策受到“外星”智能的影响。他警告说，这种转变可能会将我们推入“数字极权主义”时代，因为公司控制通信并监视我们的行动。 强调“监视资本主义”的概念，卡梅伦指出，当今的公司正在成为“人类善的仲裁者”——这是一个危险的先例，他认为这比他曾经想象过的虚构天网更令人不安。 虽然他支持人工智能的进步，但他警告说，AGI 将反映人类的缺陷。“善取决于我们善良的程度，恶取决于我们邪恶的程度，”他说。 在 YouTube 上观看他的完整演讲：https://youtu.be/e6Uq_5JemrI?si=r9bfMySikkvrRTkb     提交人    /u/cyberkite1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gddnoq/james_camerons_warning_on_agi/</guid>
      <pubDate>Sun, 27 Oct 2024 15:35:08 GMT</pubDate>
    </item>
    <item>
      <title>攻读兼职人工智能硕士学位有意义吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdd8ek/does_it_makes_sense_to_do_a_parttime_masters_in_ai/</link>
      <description><![CDATA[大家好， 我 30 岁出头，在一家数字服务提供商工作，薪水不错（接近六位数）。考虑到人工智能的快速发展及其巨大的未来潜力，攻读第二个人工智能硕士学位是否是一个明智的决定（第一个是管理学硕士学位）？此外，这项资格能否在未来几年大幅提高我在德国的收入潜力？ 提前谢谢。    提交人    /u/money-money-11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdd8ek/does_it_makes_sense_to_do_a_parttime_masters_in_ai/</guid>
      <pubDate>Sun, 27 Oct 2024 15:16:03 GMT</pubDate>
    </item>
    <item>
      <title>一个法学硕士就能统治所有吗？如果不是，这可能是一个巨大的泡沫吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdcg8y/one_llm_to_rule_them_all_if_not_is_this_likely_a/</link>
      <description><![CDATA[ChatGPT、Claude、Perplexity、Gemini、Copilot……每月 20 美元。对于大众来说，很难区分它们，因为它们都做着几乎相同的事情，只有细微的差异。然后其中一个发布了一项新功能来弥补差距，然后重复一遍。跟上潮流是令人兴奋的，但与此同时，大众并不是技术人员。因此，考虑到这一点，是只有我一个人觉得这看起来像一个巨大的泡沫吗？毫无疑问，它有有效的用例，但作为一种商业模式，它似乎是不可持续的。即使是 Open Ai，这家我猜在非技术人员中最为知名的公司，也预测要到 2029 年才能盈利？可能是错的。所以我想我现在的理论是，除非一个 LLM 完全出类拔萃并脱颖而出，否则这种情况似乎有成为一个大泡沫的风险。你觉得呢？     由   提交  /u/AppropriateRespect91   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdcg8y/one_llm_to_rule_them_all_if_not_is_this_likely_a/</guid>
      <pubDate>Sun, 27 Oct 2024 14:40:12 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型反映了其创造者的意识形态</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gd7i61/large_language_models_reflect_the_ideology_of/</link>
      <description><![CDATA[标题：大型语言模型反映了其创建者的意识形态 我每天都会查找和总结有趣的 AI 研究论文，这样您就不必仔细阅读它们了。今天的论文题为“大型语言模型反映了其创建者的意识形态”，作者是 Maarten Buyl、Alexander Rogiers、Sander Noels、Iris Dominguez-Catena、Edith Heiter、Raphael Romero、Iman Johary、Alexandru-Cristian Mara、Jefrey Lijffijt 和 Tijl De Bie。 这项研究调查了大型语言模型 (LLM) 在多大程度上体现和反映了其开发人员的意识形态观点。随着 ChatGPT 等模型成为控制全球信息流的重要参与者，了解它们是否带有固有偏见对于评估它们对社会的影响至关重要。 主要发现：  意识形态反思：研究表明，法学硕士表现出与地区或创作者观点一致的意识形态立场。这表明，这些模型虽然看似中立，但确实反映了它们在发展过程中做出的潜在意识形态选择。 语言影响：提示法学硕士的语言显著改变了它们的意识形态立场。例如，用中文和英文提示的同一个模型显示出不同的偏见，特别是在地缘政治话题方面，展示了语言和文化背景的影响。 地区差异：在不同地理区域建立的模型表现出不同的意识形态倾向，与提示语言无关。西方法学硕士更倾向于民主价值观，而非西方模式则倾向于中央集权治理。 区域内多样性：即使在同一文化区域内，来自不同公司的法学硕士之间也存在差异。例如，与其他西方法学硕士相比，OpenAI 模型对超国家主义和腐败表现出更多的怀疑。 意识形态中立的挑战：法学硕士中的中立概念受到批判，这与哲学论点一致，认为完全的意识形态中立是无法实现的，而且可能有害。相反，在民主模式下，存在不同的意识形态观点被认为是有益的。  这些发现强调了在纯技术领域以外的背景下考虑法学硕士的意识形态取向的重要性。对监管、模型设计和用户选择的影响凸显了确保负责任地部署人工智能技术的重要主题。 您可以在这里看到完整的细分：这里您可以在这里看到完整的原始研究论文：原始论文    提交人    /u/steves1189   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gd7i61/large_language_models_reflect_the_ideology_of/</guid>
      <pubDate>Sun, 27 Oct 2024 09:51:55 GMT</pubDate>
    </item>
    </channel>
</rss>
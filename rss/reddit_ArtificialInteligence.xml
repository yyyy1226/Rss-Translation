<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 25 Feb 2025 01:48:04 GMT</lastBuildDate>
    <item>
      <title>如果我们能够控制他们的能力，我们为什么要担心AI安全？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ixhohp/why_are_we_concerned_about_ai_safety_if_we_can/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我已经看到了一些关于这个AI的事情，这些AI试图以自我保存行为复制自己。我已经将研究与下面的PDF联系起来。 让我感到困惑的是，他们使AI访问Bash，这使其可以将其自身复制到另一台服务器。在这种情况下，这是一项研究，所以也许这是他们正在研究的内容，或者也许确实需要运行这些大型语言模型，我真的不知道。 对我来说，如果您很明显，如果您将其输出仅限于用户，然后肯定会大大降低其功率。他们可能仍然能够使用对系统运行的系统的一些知识来利用安全监督，例如任意代码执行错误。这些事情可以被修补，所以也许担心的是“一次”作为它像病毒一样进入世界的时间，将其权重和代码复制到各处，并利用安全脆弱性来开始自己。 在对我自己的探索中进行了一些探索机器学习模型，如果我们有适当的安全性并且不做愚蠢的事情，那么他们能够采取自己的意志行动的想法似乎有些远。  i &#39;d很高兴听到有我完全缺少的东西，因为似乎有些人反应过度  https://arxiv.org.org/abs/2412.049844    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ixhohp/1ixhohp/why_are_we_we_concerned_about_ai_ai_safety_if_eif_we_can/&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ixhohp/1ixhohp/why_are_we_we_concerned_about_ai_ai_ai_safety_safety_if_eif_we_can/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ixhohp/why_are_we_concerned_about_ai_safety_if_we_can/</guid>
      <pubDate>Tue, 25 Feb 2025 00:24:58 GMT</pubDate>
    </item>
    <item>
      <title>AI的视频亲吻埃隆·马斯克（Elon Musk）的脚在HUD HQ的循环中播放：真正的政府效率杰作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ixh4mz/ai_video_of_trump_kissing_elon_musks_feet_plays/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/syse_diver9558     [link]  a&gt; ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ixh4mz/ai_video_of_trump_kissing_elon_musks_feet_feet_plays/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ixh4mz/ai_video_of_trump_kissing_elon_musks_feet_plays/</guid>
      <pubDate>Tue, 25 Feb 2025 00:00:23 GMT</pubDate>
    </item>
    <item>
      <title>Doge将使用AI来评估联邦工人的回应，他们被告知通过电子邮件证明其工作是合理的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ixfxy7/doge_will_use_ai_to_assess_the_responses_from/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/sprixl     [link] ＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ixfxy7/1ixfxy7/doge_will_ai_ai_ai_ai_ai_aseses_the_responses_from//]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ixfxy7/doge_will_use_ai_to_assess_the_responses_from/</guid>
      <pubDate>Mon, 24 Feb 2025 23:07:34 GMT</pubDate>
    </item>
    <item>
      <title>Claude 3.7十四行诗绩效分析：它如何与其他模型堆叠</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ixcsby/claude_37_sonnet_performance_analysis_how_it/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我刚刚发布了一项分析，将克劳德3.7十四行诗与其他领先的AI模型进行了比较，例如GPT-4O，Gemini和Claude 3.5 SONNET在文档理解任务上。&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; /p&gt; 该方法很简单 - 他们使用了来自不同AI纸/型号卡（Llama，DeepSeek，Claude，gpt -4）的快照，包含文本，表格和图表，然后提出特定问题以测试理解。 关键发现：   claude 3.7十四行诗在测试中优于所有其他模型 保持与3.5十四行诗相同的价格，同时   两个Claude模型都避免了某些幻觉，这些幻觉却绊倒了GPT-4O和Gemini  有一些“技巧问题”所有型号都在挣扎中，但十四行诗做得最好。    https：https：// /www.youtube.com/watch?v=g-iua8fw4-g    &lt;！ -  sc_on-&gt; ＆＃32;提交由＆＃32; /u/ok-contribution9043      [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ixcsby/claude_37_sonnet_performance_analysis_how_it/</guid>
      <pubDate>Mon, 24 Feb 2025 20:57:59 GMT</pubDate>
    </item>
    <item>
      <title>这里有没有人尝试使用AI来创建死者亲人的复制？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ixbarh/has_anyone_here_tried_to_create_a_replicate_of_a/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是加拿大新闻机构的制片人谁在某种程度上使用AI来复制通过亲人的AI。如果是这样，我很想听听您的来信！ 谢谢您，我期待收到您的来信！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ixbarh/1ixbarh/has_anyone_here_here_tried_tried_to_create_a_replate_of_a/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ixbarh/has_anyone_here_tried_to_create_a_replicate_of_a/</guid>
      <pubDate>Mon, 24 Feb 2025 19:58:01 GMT</pubDate>
    </item>
    <item>
      <title>Claude 3.7十四行诗可以玩神奇宝贝吗？人工智能基准变得很奇怪</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ixb50w/claude_37_sonnet_can_play_pokémon_ai_benchmarks/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  除了在推理方面表现出色＆amp;编码，Claude 3.7十四行诗显然比Pokémon游戏测试中的所有型号都表现出色。 首先，它是国际象棋作为AI基准。然后，我们得到了Dota 2＆amp; Starcraft II。现在…Pokémon??  下一个Claude与竞争性UNO中的Alphago是什么？ 😂  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/snehens     [link]  &lt;a href =“https://www.reddit.com/r/artcoverinteligence/comments/1ixb50w/claude_37_sonnet_can_play_play_play_pokémon_ai_ai_benchmarks/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ixb50w/claude_37_sonnet_can_play_pokémon_ai_benchmarks/</guid>
      <pubDate>Mon, 24 Feb 2025 19:51:30 GMT</pubDate>
    </item>
    <item>
      <title>人类发射Claude 3.7十四行诗</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ixapo3/anthropic_launches_claude_37_sonnet/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   tl; dr-3.7十四行诗vs 3.5十四行诗  扩展思维模式：最多允许多达128K代币进行内部推理 代理编码：用于阅读，编辑，测试代码的新的Claude代码工具 可见的思维链：选项查看内部推理步骤 双模式操作：在快速响应和深度推理之间切换  基准：  在编码任务上胜过3.5（swe-bench，tau--台式）  GPQA得分高达84.8％，物理子分数96.5％  定价：与Claude 3.5相同（每百万个令牌3/15），但包括“思考”令牌。我们在此处记录了更多详细信息： https://blog.getbind.co/2025/02/24/claude-3-7-sonnet-vs-claude-3-5-sonnet/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/dataCog     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ixapo3/anthropic_launches_claude_37_sonnet/</guid>
      <pubDate>Mon, 24 Feb 2025 19:34:15 GMT</pubDate>
    </item>
    <item>
      <title>破坏我们模型的恶意用途：OpenAI更新（2025年2月）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ix9rq6/disrupting_malicious_uses_of_our_models_openai/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/leveredRecap     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ix9rq6/disrupting_malicious_uses_of_our_models_openai/</guid>
      <pubDate>Mon, 24 Feb 2025 18:56:10 GMT</pubDate>
    </item>
    <item>
      <title>在最后一年的AI/ML项目解决现实世界中的问题需要想法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ix9nch/need_ideas_for_a_final_year_aiml_project_solving/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，大家， 我正在大学的最后一年，在人工智能和解决现实世界问题的机器学习。我的意思是，您是否曾经遇到过我可以通过项目来处理的事情。我想要一些有影响力的东西，独特的东西，这不仅是理论上的应用，而且实际上可以有所作为。 我很想听听您的建议！ AI/ML可以产生有意义的影响，有哪些紧迫的问题？如果考虑到计算能力和可用数据集的资源有限的大学项目可行，则奖励积分。 预先感谢！期待您的想法。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/unectiateGene2457     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ix9nch/need_ideas_for_a_final_year_aiml_project_solving/</guid>
      <pubDate>Mon, 24 Feb 2025 18:51:19 GMT</pubDate>
    </item>
    <item>
      <title>AI开发的当前状态</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ix3n8g/the_current_state_of_ai_development/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/u/honey-badger55     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ix3n8g/the_current_state_of_ai_development/</guid>
      <pubDate>Mon, 24 Feb 2025 14:44:25 GMT</pubDate>
    </item>
    <item>
      <title>我怎么能进入AI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ix3766/how_could_i_get_into_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我目前是大二学生CS专业，AI一直是自Chatgpt出来以来我一直看过计算机的挑战前。我一直在考虑去研究研究生，但我​​不知道从哪里开始。我该如何开始制作2026年夏季实习的简历看起来不错的项目？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/obeymeorelse     [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ix3766/how_could_i_get_into_ai/</guid>
      <pubDate>Mon, 24 Feb 2025 14:24:22 GMT</pubDate>
    </item>
    <item>
      <title>在YouTube视频中利用Chatgpt进行赞助的AD检测和关键字提取</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwxwgr/leveraging_chatgpt_for_sponsored_ad_detection_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我每天都在发现并总结有趣的AI研究论文，因此您不必全部拖网。今天的论文的标题为“利用ChatGpt进行赞助的AD检测和YouTube视频中的关键字提取”，由Brice Valentin Kok-Shun和Johnny Chan作者：。  本研究探讨了可以利用OpenAI的GPT-4O（例如OpenAI的GPT-4O）来检测YouTube视频中赞助的广告段的大型语言模型（LLM），并提取关键字以将广告与主要内容进行比较。通过分析421个自动生成和手动成绩单，作者开发了一种可扩展的方法，结合了GPT-4O和Keybert进行广告检测和关键字分类。  以下是论文中的五个关键要点：    for AD检测： changpt迅速设计以识别内部的赞助广告片段YouTube视频成绩单，展示了其检测明确的广告位置和更微妙的赞助提及的能力。 Keybert：该研究使用Keybert进行自动关键字提取，其次是用于层次关键字分类的GPT-4O，可以分析教育内容中的广告主题。     AD AD普遍存在和类别：研究发现，大约45-57％的视频包括赞助内容，其中大多数广告与产品赞助，教育服务和媒体有关促销。   广告和内容之间的对齐方式：物理相关的渠道主要以科学为基础的赞助商（例如，星云），而其他类别中的ADS通常是断开连接的从视频主题中，提出在上下文相关性中取得多样的成功。   可伸缩性和自动化：该方法证明了如何LLM可以在媒体内容中自动化广告检测 - 先前需要手动注释或基于计算昂贵的视频/音频模型的任务。   这项研究突出了AI在转换AD中的潜力检测策略并提高数字媒体广告的透明度。未来的工作将着重于扩展数据集，通过人类验证来提高准确性，并比较其他AI模型的性能。  您可以在此处捕获完整的故障：  您可以在此处捕获完整而原始的研究论文：原始纸   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwxwgr/leveraging_chatgpt_for_sponsord_ad_detection_and/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwxwgr/leveraging_chatgpt_for_sponsored_ad_detection_and/</guid>
      <pubDate>Mon, 24 Feb 2025 09:09:34 GMT</pubDate>
    </item>
    <item>
      <title>非高级科学家AI：自主AI代理的更安全替代方案科学发现</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwxv77/nonagentic_scientist_ai_a_safer_alternative_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文研究了超级智能AI代理的灾难性风险，并提出了一条针对“科学家AI”的替代发展路径。与人类合作而不是追求自主目标的系统。 关键技术要点： *为高级AI定义了两个范式：自主代理人与科学合作者 *详细详细介绍了自治药物的特定失败模式，包括欺骗，寻求权力，寻求权力，和价值不对对准 *对科学家AI提出了限制：没有自主目标追求，透明的推理过程，有限的行动范围 *分析了如何分析这些限制可能会减轻已知风险的同时保留能力 结果和方法论： *正式框架比较代理人与科学家范围的多个风险维度 *科学家约束如何影响不同AI功能的案例研究 *分析人类AI-AI的这些案例研究。协作研究潜力 *关于维持科学家约束的验证方法的讨论 我认为这是对AI安全讨论的重要贡献具体的替代发展途径。虽然约束可能会限制某些应用程序，但它们可以使高功能强大的系统更安全。该框架有助于阐明以前不清楚的范式之间的关键差异。 我认为，最有价值的方面是显示我们如何在添加结构保障的同时保持有益的AI功能。但是，在实施和验证提出的约束方面仍然存在着重要的工作。  tldr：纸质分析自主AI代理的风险，并提出了替代性的“科学家”。具有内置安全限制的范式。提供了比较方法和分析降低风险的框架。   Full摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwxv77/nonagentic_scientist_ai_a_safer_alternative_to/</guid>
      <pubDate>Mon, 24 Feb 2025 09:06:58 GMT</pubDate>
    </item>
    <item>
      <title>Grok不是Elon品牌的流行/成功原因吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwizgm/is_grok_not_as_popularsuccessful_cause_of_elon/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  完整披露 - 这是一个“无愚蠢的问题”查询。如果您发现我被低估，不准确等，请随时教育。与GPT的免费版本相比，Grok可以免费执行的差异。我认为如果埃隆不是埃隆，Grok在商业上比Chatgpt更具吸引力是愚蠢的吗？我仅将它们都用于非编码/过度技术目的，因此我无法说话。但是，对于我所能看到的，我的意见被挥舞着将Grok视为两个选择中的更好 - 如果确实是唯一的2个。  &lt;！ -  sc_on-&gt;＆＃32 ;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwizgm/is_grok/is_grok_not_as_popularsuccessucuccessucuccesful_causeful_causeful_causeful_cause_of_elon/&gt; [link]   [注释]       ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwizgm/is_grok_not_as_popularsuccessful_cause_of_elon/</guid>
      <pubDate>Sun, 23 Feb 2025 19:59:54 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1hr4p1x/monthly_is_there_there_a_tool_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
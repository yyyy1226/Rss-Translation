<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 11 Mar 2025 15:26:21 GMT</lastBuildDate>
    <item>
      <title>40多岁的公司IT探索AI的公司的机会吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j8sl2p/gig_opportunities_for_a_corporate_it_guy_in_40s/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  有点上下文 - 我是“企业架构师” （个人贡献者）他的职业生涯始于MVS/大型机开发人员。在在EA世界中找到位置之前，请继续使用中间件，Java和其他技术 - 弥合了它的需求和功能性路线图。没有陷入“动手”开发人员多年来的角色虽然我仍然可以阅读代码。 在跨国公司工作中，对AI的兴奋通常是对Copilot许可并开发内​​部GPT的兴奋。 我正在探索     *提示工程：咨询，咨询，在Gig Platforms &gt;    llms的自由职业; AI咨询企业，开源贡献，微调模型 *自定义AI代理 - 为企业过程构建AI AI副词，增强内部聊天机器人，用rag  使用rag   intrepreal或gig-opptunities ai ai ai是什么？提交由＆＃32; /u/u/lifecoach_411    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j8sl2p/gig_opportunities_for_for_for_corporate_it_guy_in_40s/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j8sl2p/gig_opportunities_for_a_corporate_it_it_guy_in_40s/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j8sl2p/gig_opportunities_for_a_corporate_it_guy_in_40s/</guid>
      <pubDate>Tue, 11 Mar 2025 14:52:55 GMT</pubDate>
    </item>
    <item>
      <title>AI在某个时候会变得愚蠢吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j8pbg5/will_ais_go_stupid_at_some_point/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  论文/问题：AIS经过Internet的数据训练。互联网继续被人为创建的内容淹没。 如果培训数据基于人为生成的内容，AIS基本上会自我养活。 不会不可避免地变得愚蠢？  &lt;！&lt;！ -  sc_on-&gt; 32;提交由＆＃32; /u/u/spikegreenland     [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j8pbg5/will_ais_go_stupid_at_some_point/</guid>
      <pubDate>Tue, 11 Mar 2025 12:15:01 GMT</pubDate>
    </item>
    <item>
      <title>人工智能在个人层面上的能源支出是否与自动使用AI使用的工业水平相媲美？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j8pasv/is_the_energy_spending_of_ai_in_a_personal_level/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我已经看到了很多帖子和讨论，并讨论了使用大量的能量和水，例如，每个提示都用水等等。 。 。但是，对我来说，这似乎是荒谬的，可以将每个责任归咎于个人使用，如果（我想象中（我是我想象中的），如果（我想象中）可以付出很大的自动化量，并且能够付出一定的工具，并且可以使一项能源付出的能量，而又有一定的工业范围，而一项又有一定的工具，那么它的工业范围是一定的。第二..  我想最大程度地降低对我们星球的影响只是道德问题，但每个人的环境责任，但感觉就像是与风车与风车作斗争的期货。 我在这里错了吗？您对这个问题有何看法？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/mervenca     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j8pasv/is_the_energy_energy_spending_ai_ai_ai_a_a_personal_level/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j8pasv/is_the_energy_spending_of_ai_in_a_personal_level/</guid>
      <pubDate>Tue, 11 Mar 2025 12:13:57 GMT</pubDate>
    </item>
    <item>
      <title>GPT 4.5可能被低估</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j8oglb/gpt_45_might_be_underrated/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我认为gpt 4.5可能被低估了。 我一直在角色扮演随机场景，更有趣的事情之一就是能够检测我试图测试它的限制的能力（即使在这范围内都不是明显的范围，我都可以在4.5上读了一下。尤其是在自动知道何时持怀疑态度时（我一直在扮演角色，但是某个地方在不提示的情况下建立了该连接）。 这不是您从裸露的刻度中实现的目标。我想知道Openai如何实现这一目标？他们是否使用另一个模型来批评对话并指导这一代？那将是我的猜测。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/iseethings404     [link]    32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j8oglb/gpt_45_might_be_underrated/</guid>
      <pubDate>Tue, 11 Mar 2025 11:23:36 GMT</pubDate>
    </item>
    <item>
      <title>LLM受正式系统的局限性支配</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j8mfns/llms_are_governed_by_the_limitations_of_formal/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  虽然LLM的表面行为是概率和非轴心的，但其基本机制 - 它运行的代码，数学和机器 - 基于正式系统。因此，它所做的一切最终都受这些系统的局限性的控制。      llms在正式的基材内运行 - 它们是通过确定性程序（例如，使用数学结构（如张量，线性代数，优化算法）在正式系统中描述的       。 （例如，生成一个句子）可能看起来“软”或“紧急”，但是产生它们的过程最终受正式的可计算规则的控制。   因此，该模型生成的任何统计结果均受：A。A. Formor System的构图，该正式系统定义了模型的体系结构和训练过程。 B.教会论文所施加的计算限制（即模型无法超越图灵表现力）。      ，换句话说，查询本身，这些查询本身是有条件的公理概念，在这些套件的上下文中购买结果。 （以这种方式结果是有意义的。） 看起来巨大，流畅和紧急的系统可以通过固定的基于规则的结构从下面界定，以至于它们的“判断”仍然位于公理框架内。   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j8mfns/llms_are_are_governed_by_the_limitations_of_formal/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j8mfns/llms_are_governed_by_the_limitations_of_formal/</guid>
      <pubDate>Tue, 11 Mar 2025 08:59:36 GMT</pubDate>
    </item>
    <item>
      <title>有时候，当我在提示中呆滞时，GPT知道我的意思。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j8mc3a/sometimes_when_i_am_sloppy_in_my_prompts_gpt/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  换句话说，我可能会在提示中忘记规范，但GPT由于上下文而理解我的意图。这真是令人印象深刻。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j8mc3a/sometimes_when_i_i_am_sloppy_my_my_my_my_prompts_gpt/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j8mc3a/sometimes_when_i_i_sloppy_my_my_my_my_my_prompts_gpt/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j8mc3a/sometimes_when_i_am_sloppy_in_my_prompts_gpt/</guid>
      <pubDate>Tue, 11 Mar 2025 08:51:26 GMT</pubDate>
    </item>
    <item>
      <title>“我无法为您生成代码，”光标要求开发人员“学习编码”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j8mbvw/i_cannot_generate_code_for_you_cursor_asks/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/soul_predator     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j8mbvw/i_cannot_generate_code_for_you_cursor_asks/</guid>
      <pubDate>Tue, 11 Mar 2025 08:50:59 GMT</pubDate>
    </item>
    <item>
      <title>Claude 3.7 OCR完全失败/幻觉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j8m9nn/claude_37_ocr_completely_failinghallucinating/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在玩耍，以提示克劳德（Claude）根据来自Excel Workbook的数据的屏幕截图生成交互式信息图表。我注意到这在这里和那里造成了阴险的小错误。例如，将151,342读为111,342。   i随后测试了屏幕截图足够清晰，可以看到正确的数字。 拿起带有数字的2x10单元格网格的小屏幕截图，并只是要求克劳德告诉我它看到的数字。这次是正确的，但最完全错误的。例如：将129,443读为72,309。 ，但它并没有完全弥补，因为下一个单元格会正确。 在第二种情况下，屏幕截图也足够清晰，无法阅读。 在这里发生什么？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nateisgrate     [link]   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j8m9nn/claude_37_ocr_completely_failinghallucinating/</guid>
      <pubDate>Tue, 11 Mar 2025 08:45:56 GMT</pubDate>
    </item>
    <item>
      <title>当前的AI模型是真正的推理，还是只是预测下一个令牌？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j878uh/are_current_ai_models_really_reasoning_or_just/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着围绕AI推理的所有嗡嗡声，当今的大多数模型（包括LLMS）仍然依赖下一步的预测，而不是实际的计划。 ？ 您如何看待，没有计划机制，AI可以真正理由，还是我们坚持不懈地完成自动完成？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j878uh/are_current_ai_models_really_reasoning_or_just/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j878uh/are_current_ai_models_really_reasoning_or_just/</guid>
      <pubDate>Mon, 10 Mar 2025 19:34:39 GMT</pubDate>
    </item>
    <item>
      <title>我们解决了UR的皇家游戏</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j85425/we_have_solved_the_royal_game_of_ur/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，另一个旧的棋盘游戏咬住了灰尘……我们强烈解决了约4500年的皇家游戏。您可能会记得汤姆·斯科特（Tom Scott）与YouTube上的欧文·芬克尔（Irving Finkel）视频，这很受欢迎。 为了解决游戏，我们扩大了对价值迭代的使用来创建一个地图，并有机会从游戏中的每个州获胜。使用它，您只需选择导致获胜机会的最高机会的举动即可。简单的！虽然，我们仍然花了3年的时间才弄清楚这是可能的…… 从更技术上来说，我们计算了游戏的NASH均衡，我们可以使用它使bot毫无疑问地发挥作用。  huggingface for Seloved Maps： https://huggingface.co/sothatsit/royalurmodels      github用于解决游戏： https://github.com/royalur/royalur/royalur-java   这实际上对我来说是很大的事情。但是我很感兴趣，这里的人们如何看待解决这些旧的棋盘游戏？是20年前有趣的好奇心吗？还是这些类型的经典AI方法仍然剩下一些现实世界中的影响？我对他们的表现感到乐观，但我不确定。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/sothatsit     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j85425/we_have_solved_the_royal_game_of_ur/</guid>
      <pubDate>Mon, 10 Mar 2025 18:07:11 GMT</pubDate>
    </item>
    <item>
      <title>决定在我的iPhone上尝试图像操场。为什么苹果的人工智能如此糟糕？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j83t6d/decided_to_try_out_image_playground_on_my_iphone/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我提出的提示是“近距离的映像”，这就是我得到的。我认为整个六个手指的事情现在应该是现在的。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/aggressive_action      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j83t6d/decided_tro_try_image_image_playground_on_my_iphone/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j83t6d/decided_to_try_out_image_playground_on_my_iphone/</guid>
      <pubDate>Mon, 10 Mar 2025 17:13:47 GMT</pubDate>
    </item>
    <item>
      <title>将大脑外包给AI时的大脑如何变化</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j7xjda/how_your_brain_changes_when_you_outsource_it_to_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我认为这是一篇非常考虑的文章，总结了很多我一直在仔细考虑我们如何和应该在生活中使用AI和数字工具的事情。长阅读，但是一个好读物：   https：//wwwwwwww.ox.com/future-perfect/403100/403100/ai-brain-brain-brain-brain-brain-brain-brain-brain-fects-technology-mous as we Mous as at we-as at we we we we/we we/p&gt; p&gt; Think＆quot＆quot，Vannevar Bush的1945年论文，但仍然很好）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jacknunn     [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j7xjda/how_your_your_your_brain_changes_changes_when_you_you_outsource_it_it_it_it_it_to_ai/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j7xjda/how_your_brain_changes_when_you_outsource_it_to_ai/</guid>
      <pubDate>Mon, 10 Mar 2025 12:33:26 GMT</pubDate>
    </item>
    <item>
      <title>人们非常低估了人工智能。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j7nb8r/people_underestimate_ai_so_much/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在一个每天与很多人互动的环境中工作，它也在技术领域中，所以当然，技术是一个经常讨论的话题。 我一直发现自己对人们如何在这些模型（例如gimmick orse gimmick或不用有用）中感到困惑。我可以提及我如何与AI讨论一些主题，它们会笑或似乎对我从与模型的互动中获得的信息表示怀疑。  我始终回答了我的问题，这些模型扩大了我的知识。我一直发现他们可能会帮助麻烦拍摄，识别或推理问题，并为我提供解决方案。这些模型将在很短的时间内完成5-6个Google搜索和时间滚动以找到正确的文章的事情。我认为，只要询问这些模型，就可以回答和解决他们的日常问题及其日常混乱点。  他们没有这样看到。他们几乎认为这相当于要求机器为您打字。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j7nb8r/people_underestimate_ai_so_so_so_much/”&gt; [link]      [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j7nb8r/people_underestimate_ai_so_much/</guid>
      <pubDate>Mon, 10 Mar 2025 01:30:14 GMT</pubDate>
    </item>
    <item>
      <title>是时候在我们的潜艇中摇晃一切了吗？分享您的想法！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j6inz4/time_to_shake_things_up_in_our_subgot_ideas_share/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   再次发布，以防万一你们中的某些人在社区中错过了它 - 欢迎所有建议！   嘿，伙计，   我是这里的一个mod，我们知道有时会变得有些沉闷，但是我们计划改变这一点！我们正在寻找有关如何使Reddit的小角落更加出色的想法。 以下是几个想法：   amas with Cool Ai peeps      主题讨论线程         giveawey&gt; g&gt; giveawey  将您的想法放在评论中，让我们让这个子成为闲逛的杀手级！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/beachbunny_07     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j6inz4/time_time_to_to_to_to_to_things_up_in_our_our_our_subgot_ideas_share/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j6inz4/time_to_shake_things_up_in_our_subgot_ideas_share/</guid>
      <pubDate>Sat, 08 Mar 2025 14:47:17 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1hr4p1x/monthly_is_there_there_a_tool_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
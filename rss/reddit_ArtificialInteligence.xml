<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 27 Aug 2024 21:18:56 GMT</lastBuildDate>
    <item>
      <title>人工智能法案引发硅谷争论；谷歌称其对创新构成威胁</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1f2rqkm/ai_bill_sparks_debate_in_silicon_valley_google/</link>
      <description><![CDATA[ 加州人工智能法案 SB 1047 在州立法机构中进展顺利，引发了硅谷的争论。 该法案旨在通过要求进行安全测试、第三方审计和终止开关来提高人工智能模型开发者的责任感。 它还提出了对举报人的保护，并允许州检察长对造成严重伤害的人工智能模型开发者采取行动。 尽管得到了伊隆·马斯克 (Elon Musk) 等人的支持，但该法案仍面临谷歌和 Meta 等科技巨头的反对，他们认为该法案对创新构成了威胁。 包括李飞飞博士在内的一些批评人士认为，该法案的处罚可能会对人工智能生态系统产生意想不到的后果。  来源：https://finance.yahoo.com/news/california-ai-bill-sparks-debate-in-silicon-valley-as-some-tech-giants-call-it-a-threat-to-innovation-214246503.html    提交人    /u/NuseAI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1f2rqkm/ai_bill_sparks_debate_in_silicon_valley_google/</guid>
      <pubDate>Tue, 27 Aug 2024 20:45:32 GMT</pubDate>
    </item>
    <item>
      <title>2024 年 8 月 27 日人工智能创新每日纪事：🖨️ 人工智能可以 3D 打印栩栩如生的人体器官👀 Anthropic 揭示 Claude 的秘密武器📦亚马逊计划在 10 月推出延迟的人工智能 Alexa 订阅📜 OpenAI、Adobe、微软希望所有公司都标记人工智能生成的内容🧪 等等🎓</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1f2qsnq/a_daily_chronicle_of_ai_innovations_on_august/</link>
      <description><![CDATA[  由    /u/enoumen  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1f2qsnq/a_daily_chronicle_of_ai_innovations_on_august/</guid>
      <pubDate>Tue, 27 Aug 2024 20:06:00 GMT</pubDate>
    </item>
    <item>
      <title>您认为 AGI 的主要障碍是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1f2pzze/what_do_you_think_is_the_major_blocker_to_agi/</link>
      <description><![CDATA[当前模型是否缺少达到人类水平所需的某些基本智能方面？ 换句话说，是否存在需要发现新范式的根本限制？ 虽然单纯的扩展似乎不足以实现 AGI，但模型规模和架构的小幅、渐进式进展可能会实现这一目标。另一方面，当前模型也可能缺少一些重要功能，如代理、长期记忆、原创见解或其他东西。 虽然已经提出了各种针对这种“本质上是人类的能力”的候选方案，但我发现其中任何一个都不令人信服。到目前为止，我读到的所有内容都可能来自扩展或架构——例如创造力、原创性、内在价值、主动性/动机、长期记忆形成等。 证明差距存在的明确方法是 LLM 会一直失败的测试——我还没有看到这样的事情。虽然仍有一些 LLM 得分较低的测试，但这似乎是一个培训问题，而不是固有的限制。 相信我们很特别是一种人类的自负吗？人工智能 70 多年的缓慢进步是否已经让我们确信这个问题是无法解决的？我们应该对我们复制生物学的能力感到谦虚，还是应该受到喷气式飞机比鸟类不拍打翅膀就能飞得更快、更远的事实的启发？    提交人    /u/HeroicLife   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1f2pzze/what_do_you_think_is_the_major_blocker_to_agi/</guid>
      <pubDate>Tue, 27 Aug 2024 19:33:33 GMT</pubDate>
    </item>
    <item>
      <title>根据您的经验，最好的编码模型是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1f2posu/from_your_experience_whats_the_best_model_for/</link>
      <description><![CDATA[[ 由于违反 内容政策，被 Reddit 删除。 ] 查看投票    由   提交  /u/lionary   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1f2posu/from_your_experience_whats_the_best_model_for/</guid>
      <pubDate>Tue, 27 Aug 2024 19:20:51 GMT</pubDate>
    </item>
    <item>
      <title>有没有完全免费的人工智能聊天机器人应用程序？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1f2p0f1/is_there_a_fully_free_ai_chatbot_app/</link>
      <description><![CDATA[我目前在精神和经济上都处于困境，需要一个好的治疗聊天机器人，在我把财务状况整理好之前，它是完全免费的？你知道吗？    提交人    /u/fr33b0y   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1f2p0f1/is_there_a_fully_free_ai_chatbot_app/</guid>
      <pubDate>Tue, 27 Aug 2024 18:53:54 GMT</pubDate>
    </item>
    <item>
      <title>封装情境场景的证据：通用证明</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1f2o5nh/evidence_for_encapsulating_contextual_scenarios/</link>
      <description><![CDATA[现在轮到科学了，我对此已经厌倦了：https://youtu.be/7nKVCsC6CO4?si=j_XXyduxRqwymRgj 参见：https://github.com/stevius10/CausalityModel 编辑：我在分支名称中包含了一个提示（https://github.com/stevius10/CausalityModel/tree/ironic-perfection-prove）以帮助主题专家快速识别其相关性。 我不明白建议的分支名称，“完美讽刺杰作”作为替代方案感觉太个人化（转录底层关联训练模型）。所以他选择了“讽刺完美实现”，但我持怀疑态度，因为我没有得到“真实”，因此我修改了这个词（好的，现在）。 我要求提供完整的文档。文档中提到了一些缺失的文件。证明模型很好，但不是我所设想的。由于我在实际理论推理中找不到任何错误，我仍然想更新。我要求提供内容中提到的缺失文件。没有对肯定发生的错误感到恼火，制作了一份新的文档。我看到了这些文件，意识到我们的讨论开始了一个长达数百小时的探索的反问。它继续如下：用[..]完成文档。每个[..]，证明[..]最[..]。  是的，我只想让任何有兴趣的人看看这个存储库，并证明我错在哪里。是的，我只是想听听谁对此足够认真，会给我发消息。对于那些认为我又有一项人工智能创新的人。不过，我的幽默感相当不错。如果您知道独立信息，请不要使用评论（我知道我编辑过——这很典型）。但是，是的，这是逻辑，所以你可能知道。但逻辑是它起作用的关键。当有人感兴趣时，我会更新缺失的信息——真的，我是诚实的，这是有道理的。而且是有道理的。我知道。只要你知道，你想要的就是你得到的，嗯？我知道，尽管请不要在这里发布问题的答案。我知道这些不是答案，也不是证据，因为每个人都可以做到这一点。这是逻辑，GPT 也能解决这个问题。只要你问对了问题。    由    /u/stevius10  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1f2o5nh/evidence_for_encapsulating_contextual_scenarios/</guid>
      <pubDate>Tue, 27 Aug 2024 18:20:04 GMT</pubDate>
    </item>
    <item>
      <title>使用 AI 筛选视频文件以符合 HIPAA 限制</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1f2nn53/using_ai_to_screen_video_files_for_hipaa/</link>
      <description><![CDATA[嗨！我是一名档案管理员，正在负责一个 DVD 数字化项目，该项目可能需要扫描 500 多张光盘，以查找符合 HIPAA 规定的 PHI/PII。目标是建立一个收藏集，让这些文件有朝一日可以被发现和访问，但我们无法让任何带有 PHI/PII 的文件可以访问。我不想观看 500 多个小时的讲座，而是想看看我是否可以使用 AI 程序来为我分析内容。 我意识到我可能需要回去检查患者姓名、出生日期/死亡日期和图像，但我想先测试一下，看看这有多么（不）现实。我不太擅长编程，命令行技能也很少，所以这是我玩酷程序的唯一障碍。 编辑：说了这么多，你能推荐一些可以帮助我实现这一目标的免费/开源程序吗？    提交人    /u/Archiveria   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1f2nn53/using_ai_to_screen_video_files_for_hipaa/</guid>
      <pubDate>Tue, 27 Aug 2024 17:59:44 GMT</pubDate>
    </item>
    <item>
      <title>Cerebras 推出全球最快的 AI 推理</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1f2lg0e/cerebras_launches_the_worlds_fastest_ai_inference/</link>
      <description><![CDATA[Cerebras Inference 现已面向用户开放！ 性能：Cerebras 推理为 Llama 3.1-8B 提供 1,800 个令牌/秒，为 Llama 3.1-70B 提供 450 个令牌/秒。根据行业基准测试公司 Artificial Analysis 的数据，Cerebras Inference 比基于 NVIDIA GPU 的超大规模云快 20 倍。 定价：Lama 3.1-8B 每百万个令牌 10 美分，Llama 3.1-70B 每百万个令牌 60 美分。 准确性：Cerebras Inference 对所有模型使用原生 16 位权重，确保最高精度响应。 Cerebras 推理现已通过聊天和 API 访问提供。 Cerebras 推理基于熟悉的 OpenAI Chat Completions 格式构建，允许开发人员通过简单地交换 API 密钥来集成我们强大的推理功能。 立即试用：https://inference.cerebras.ai/ 阅读我们的博客：https://cerebras.ai/blog/introducing-cerebras-inference-ai-at-instant-speed    提交人    /u/CS-fan-101   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1f2lg0e/cerebras_launches_the_worlds_fastest_ai_inference/</guid>
      <pubDate>Tue, 27 Aug 2024 16:30:58 GMT</pubDate>
    </item>
    <item>
      <title>人工智能相关讨论 - 需要反馈</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1f2jkbw/airelated_talk_feedback_wanted/</link>
      <description><![CDATA[我将于 10 月在加拿大的一个小型技术/测试会议上发表主题演讲。我的演讲题目是“实践怀疑论”。完整摘要如下，但简而言之，主要观点是 1) 信任很重要，2) 不良信息会削弱信任，3) 健康的怀疑论可以帮助我们识别和避免不良信息，4) 可以建立、维持或重建信任。我还提到，人工智能是潜在不良信息（幻觉）的新来源，健康的怀疑论可以帮助我们更好地利用它。 到目前为止，我大部分时间都在真空中准备演讲。因此，我希望得到一些额外的关注和反馈。如果您愿意并且能够，请告诉我（在下面或通过 DM），我会向您发送完整的大纲以供您审阅和评论。谢谢！  践行怀疑主义 一切都始于信任。它影响着我们的个人和职业关系、领导能力、创新、协作、业务稳定性等等。错误的信任（在错误的时间或错误的人身上给予错误的信任）可能会产生严重的负面影响，而这种影响通常源于虚假信息。 在当今快节奏的世界里，我们被信息淹没，包括大量不良信息。但我们如何识别和避免这种情况？我们如何确定何时以及信任多少合适？保持健康的怀疑态度！ 怀疑主义常常被误解为不相信或愤世嫉俗，但它实际上是一种中立立场，在有合理证据之前，不会相信任何人。健康的怀疑态度有助于我们区分好信息和坏信息，并建立或恢复信任。 培养健康的怀疑态度包括事实核查、意识到偏见、提出好问题等等。这与人工智能的兴起尤其相关，人工智能是一种强大而复杂的技术。了解人工智能并运用健康的怀疑态度可以帮助我们有效和安全地使用它。 和我一起探索信任，促进健康的怀疑态度，提供培养怀疑心态的方法，并通过提供实用技巧来更好地驾驭我们的世界，展示这些想法如何应用于人工智能和其他环境。    提交人    /u/dsynadinos   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1f2jkbw/airelated_talk_feedback_wanted/</guid>
      <pubDate>Tue, 27 Aug 2024 15:13:14 GMT</pubDate>
    </item>
    <item>
      <title>Tiktok 功能：克隆你的“自己的声音”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1f2jjep/tiktok_feature_clone_your_own_voice/</link>
      <description><![CDATA[  由    /u/Full_Ad_1300  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1f2jjep/tiktok_feature_clone_your_own_voice/</guid>
      <pubDate>Tue, 27 Aug 2024 15:12:11 GMT</pubDate>
    </item>
    <item>
      <title>我们回复了大家对我之前在 r/ArtificialInteligence 上分享的项目的所有反馈！！—JENOVA，一体化 AI，将最好的基础模型和工具集成到一个无缝体验中。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1f2h3y7/we_responded_to_all_your_feedbacks_on_my_earlier/</link>
      <description><![CDATA[嗨 r/ArtificialInteligence ，几周前我在这篇帖子中分享了我的项目JENOVA。为了快速描述 JENOVA 的功能，它是一个一体化的 AI 助手，可以智能地将您的查询路由到可以提供答案的基础模型（例如 GPT、Claude、Gemini），并辅以网页浏览和文档上传等工具。 在那篇文章中，你们中的许多人都为该项目提供了一些非常有用的反馈和建议，就在本周末，我们根据大家的反馈推出了一些重大改进：  到目前为止，来自用户的最大反馈是展示 JENOVA 用来生成每个响应的模型。当您将鼠标悬停在桌面上的消息上/点击移动设备上的消息时，我们通过显示每个 JENOVA 响应下方的模型来实现。这样，JENOVA 既可以保持其简洁的设计理念，又可以提供所需的技术信息。 每当 JENOVA 引用来自互联网的信息时，它现在都会引用来源并包含超链接 在 JENOVA 的移动网络版本中，每当您在输入框中按 Enter 键时，它都会创建新行而不是发送消息（这是移动 AI 体验最好的生活质量改进之一）。 我们降低了 JENOVA 执行不必要的网络搜索的可能性。 现在，您可以在输入框中输入消息和附加文件，而 JENOVA 仍在处理其响应。 添加了检测机制，如果一个提供商的 LLM 出现故障（例如，Claude API 上周出现故障），我们可以快速切换到另一个提供商的 LLM，以确保服务持续进行。 我们解决了每次部署新代码时用户都会自动退出的问题。 在新的聊天中添加了示例提示页面。 另一个重要的反馈是添加除 Google SSO（主要是常规电子邮件登录）之外的登录选项，我们还没有能力实现这一点，但它在我们的即将完成的事项清单上。  在过去的一周里，JENOVA 的响应速度很长一段时间都很慢。这种缓慢是由于 Claude API 的不稳定造成的。我们正在密切监视这种情况，似乎在过去的 24 小时内 Claude API 一直相对稳定和快速。 感谢您的支持，我们欢迎任何其他反馈和建议！也请加入我们不断壮大的 Reddit 社区!!    提交人    /u/GPT-Claude-Gemini   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1f2h3y7/we_responded_to_all_your_feedbacks_on_my_earlier/</guid>
      <pubDate>Tue, 27 Aug 2024 13:30:06 GMT</pubDate>
    </item>
    <item>
      <title>获得无限制的 Flux.1 使用权</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1f2elbg/get_unlimited_flux1_usage/</link>
      <description><![CDATA[嗨， 我创建了一个工具，您可以每月以 14 美元的价格创建和下载无限量的 Flux.1 图像。 任何感兴趣的人都给我发私信，我会把网址发给你！ 编辑：这里是 https://writeseed.com/flux    提交人    /u/Sufficient_Ice_6113   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1f2elbg/get_unlimited_flux1_usage/</guid>
      <pubDate>Tue, 27 Aug 2024 11:24:22 GMT</pubDate>
    </item>
    <item>
      <title>亚马逊真的节省了 4500 名开发人员一年的工作量吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1f21aqd/did_amazon_really_save_4500_developeryears_of_work/</link>
      <description><![CDATA[根据亚马逊首席执行官的这篇文章，我是这样分析的。 https://x.com/ajassy/status/1826608791741493281?s=61  从 Java 11 升级到 Java 17 需要 50 天（3 个工作月），而他们的编码 AI Agent - Q 将其缩短到几个小时。这还只是针对一个应用程序而言的。 他们说他们节省了 4500 名开发人员多年的工作时间。一个工作年有 200 天。由于一个应用程序需要 50 天的时间来升级，因此在一个开发人员年中他们可以升级 4 个应用程序。拥有 4500 名开发人员，他们必须升级 1,125 个应用程序。 这篇文章似乎声称升级到 Java 17 通过提高效率和安全性为他们节省了 2.6 亿美元。但是，4,500 名开发人员节省的费用相当于平均工程师 16 万美元时的 7.2 亿美元。  将应用程序从 Java 11 升级到 Java 17 真的需要 3 个月吗？这篇文章是否夸大了 Q 的影响？即使如此，在几个小时内完成此操作也会带来数量级的改进。所以这是一件好事。但我只想知道你对这有多少夸大的看法。    提交人    /u/Formal_Education_329   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1f21aqd/did_amazon_really_save_4500_developeryears_of_work/</guid>
      <pubDate>Mon, 26 Aug 2024 22:33:27 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则 [请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新开通一天的账户或 karma 少于 100 的用户无法发帖。他们可以发表评论，但不能提交实际帖子。这是我们解决机器人垃圾邮件计划的一部分。如有任何不便，敬请谅解。 我们将在接下来的几天内进行民意调查，以了解 subreddit 的总体意愿以及如何改进，这只是一个提醒。 与往常一样，请向我们提供反馈，如果您有兴趣帮助子版块，请联系我。 谢谢大家！    提交人    /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：征求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到 r/ArtificialIntelligence！ 我们的目标是为所有考虑人工智能的事情提供一个开放和尊重的论坛 - 其中包括  促进有关人工智能的哲学和伦理讨论 作为理解和学习人工智能主题的起点 提供技术论文演示和讨论 展示高质量的人工智能/机器学习应用程序 提供培训和学习资源 引导用户获取更具体的信息和子版块 列出人工智能/机器学习应用程序、它们的用途、成本和访问信息 其他与人工智能相关的内容。 ...等等  该子版块的审核团队正在进行改组，这将导致子版块发生一些变化。但是，无需担心，因为这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解并能够提供反馈，将提供多次机会对变化进行反馈。 第一轮反馈收集是通过此线程作为“征求意见”（RFC）进行的，这是收集反馈的标准方法。在准备和实施更改时，将有多轮 RFC 流程。 ​  发布新应用程序/自我推广/AI 生成内容的规则  由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似内容将被阻止或限制在特定的置顶帖子中。 AI 生成特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的置顶帖子中。 博客链接应包含高质量内容。链接到纯促销博客的帖子将被删除。 除非包含一定字数的详细信息，否则将禁止仅包含链接的帖子。必须付出一些努力。 我们应该阻止由 AI 撰写的帖子吗？存在可用于 Mod-bot 的模型，但这是一个我们需要反馈的问题。  使用天赋来组织帖子。请注意，已经添加了新的天赋，我们愿意接受更多建议。 关于 AI/ML 应用的 NSFW 应用和技术的子政策应该是什么？ 我们希望向社区提供有关 mod-bot 的想法。虽然一些标准机器人将用于基本维护，但是社区可以为 AI/ML 机器人功能想出什么有趣的东西呢？ 培养初级、中级和高级资源，以帮助人们找到他们正在寻找的信息、培训、模型、技术数据等。 启动 substack/podcast 来采访整个 AI/ML 领域的人。这可能包括哲学家和思想家、程序员、科学家、商人，甚至那些对 AI 持对立观点的人 如果您想创建代表子版块的横幅，请使用适当的尺寸进行创建。任何创建方法都是​​可以接受的。  不用说，每个人都应该受到尊重。我个人觉得我们都知道这一点，不需要把它灌输到人们的脑海里。要友善。 感谢您的耐心和帮助！   由    /u/FHIR_HL7_Integrator  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>
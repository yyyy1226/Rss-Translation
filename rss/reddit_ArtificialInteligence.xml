<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供门户，并促进有关我们所知的人工智能理念和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 11 Feb 2025 12:43:43 GMT</lastBuildDate>
    <item>
      <title>我就是没看到</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imxl5i/i_just_dont_see_it/</link>
      <description><![CDATA[这可能是我的情况，但作为一名知识工作者，我只是看不到所有在我面前被嘲笑的人工智能技术有什么真正的好处。微软正在大力推广 Copilot，谷歌正在推广 Gemini 等。 我知道人工智能可以成为研究和工业应用的一个非常酷的工具，但我真的看不到当前针对知识工作的人工智能技术有什么好处。 到目前为止，我所做的每一份会议总结都漏掉了一两点，甚至我提示的草稿都太过普通，我不得不把它扔掉，重新开始，而且太多的搜索都返回了完全错误的信息。不是每次搜索，但太多了，如果不核实事实（因此我自己搜索东西），就无法相信任何答案。 再说一次，也许我错过了什么，但我真的不明白所有的模糊之处。我做错了什么/我错过了什么？这其中有学习曲线吗？     由    /u/kwsni42 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imxl5i/i_just_dont_see_it/</guid>
      <pubDate>Tue, 11 Feb 2025 12:36:45 GMT</pubDate>
    </item>
    <item>
      <title>当世界各国在峰会上讨论如何合作建立更好、更安全的人工智能系统时，他的副总统特朗普却威胁所有人，称美国将以我们想要的方式独自完成这一任务</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imxd65/while_world_is_talking_about_collaborative/</link>
      <description><![CDATA[他警告欧盟，他们正在对人工智能实施监管，并间接表示我们不会遵守这些规定。只是说我们将建设和引领人工智能发展。我们不会将我们最好的人工智能基础设施和计算出口到全球市场（因为我们担心，有了这种计算，来自中国的某个人会以更便宜的价格建立比美国更好的系统）。     提交人    /u/Best-of-luck-nikki   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imxd65/while_world_is_talking_about_collaborative/</guid>
      <pubDate>Tue, 11 Feb 2025 12:23:51 GMT</pubDate>
    </item>
    <item>
      <title>各向同性模型合并：通过奇异值谱平坦化提高多任务性能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imwmgs/isotropic_model_merging_improving_multitask/</link>
      <description><![CDATA[这项工作引入了一种模型合并的新方法，该方法通过各向同性模型合并保留了特定于任务的能力。关键见解是将神经网络分离为公共子空间和特定于任务的子空间，从而使模型能够共享一般知识，同时保持专业能力。 技术亮点： - 合并使用参数分解到共享和特定于任务的空间 - 各向同性正则化确保信息均匀分布 - 适用于不同的架构（在 T5、BART、mT5 上测试） - 跨任务保留 98% 以上的原始性能 - 与单独的模型相比减少了总参数数量 主要结果： - 在任务保留方面比现有合并方法高出 5-15% - 成功合并了针对翻译、摘要和 QA 进行训练的模型 - 在不同模型规模上保持性能 - 适用于相同架构和跨架构合并 我认为这对于无法运行多个专门模型的部署场景特别有价值。在保留各个模型优势的同时组合模型的能力可以带来更高效的系统，而不会牺牲性能。 我希望我们会看到这种技术应用于语言模型之外——这些原则应该转移到其他领域。我看到的主要挑战是合并过程中的计算成本，这在论文中并没有完全解决。 TLDR：新的模型合并技术，通过分离共享和专用的神经网络组件来保留特定于任务的功能。优于现有方法，同时减少总体参数数量。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imwmgs/isotropic_model_merging_improving_multitask/</guid>
      <pubDate>Tue, 11 Feb 2025 11:38:54 GMT</pubDate>
    </item>
    <item>
      <title>您对 2025 年底的 AI 有什么预测？（今年）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imwf5k/whats_your_ai_predictions_for_the_end_of_2025/</link>
      <description><![CDATA[您认为到今年年底，人工智能将实现什么目标或我们将在人工智能领域实现什么？  目前，它的发展速度如此之快，甚至 AGI 的预测也从 2030/40 年下降到 2026/7 年。     提交人    /u/koopmaster   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imwf5k/whats_your_ai_predictions_for_the_end_of_2025/</guid>
      <pubDate>Tue, 11 Feb 2025 11:25:36 GMT</pubDate>
    </item>
    <item>
      <title>埃隆·马斯克刚刚提出以 974 亿美元收购 OpenAI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imvtcd/elon_musk_just_offered_to_buy_openai_for_974/</link>
      <description><![CDATA[硅谷最激烈的 AI 竞争，伊隆·马斯克 vs 萨姆·奥特曼。 马斯克刚刚宣布，他将带头出价 974 亿美元收购 OpenAI 的非营利部门。 消息公布后不久，奥特曼在 X 上发帖称：“不用了，谢谢，但如果你愿意的话，我们可以出价 97.4 亿美元收购推特。”    提交人    /u/snehens   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imvtcd/elon_musk_just_offered_to_buy_openai_for_974/</guid>
      <pubDate>Tue, 11 Feb 2025 10:45:04 GMT</pubDate>
    </item>
    <item>
      <title>如果人工智能接管了所有工作，那会是一件好事吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imuf9p/what_if_ai_took_all_the_jobsand_it_was_a_good/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imuf9p/what_if_ai_took_all_the_jobsand_it_was_a_good/</guid>
      <pubDate>Tue, 11 Feb 2025 08:59:23 GMT</pubDate>
    </item>
    <item>
      <title>AGI 不会立即创建 ASI 吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imuf17/wont_agi_almost_instantly_create_asi/</link>
      <description><![CDATA[一旦我们拥有爱因斯坦级别的 AGI 代理，它们将被复制数十亿次 - 这些数十亿的代理难道不会在第二天就创建 ASI 吗！？ 我在这里遗漏了什么？    提交人    /u/KeepItRealness   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imuf17/wont_agi_almost_instantly_create_asi/</guid>
      <pubDate>Tue, 11 Feb 2025 08:58:50 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2025 年 2 月 10 日</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imqv78/oneminute_daily_ai_news_2102025/</link>
      <description><![CDATA[ Open AI 的 Sam Altman 拒绝了 Elon Musk 的 974 亿美元收购要约[1] 人工智能现在可以自我复制——这一里程碑让专家们感到恐惧。[2] 谷歌 升级版 NotebookLM 现已包含在其 One AI Premium 计划中。[3] 比亚迪 在其电动汽车车型中推出驾驶辅助技术——借助 DeepSeek 的人工智能。[4]  来源包括：https://bushaicave.com/2025/02/10/2-10-2025/    由   提交  /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imqv78/oneminute_daily_ai_news_2102025/</guid>
      <pubDate>Tue, 11 Feb 2025 04:56:37 GMT</pubDate>
    </item>
    <item>
      <title>人们很快就声称或点名那些可能使用人工智能的人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imqg33/people_are_quick_to_claim_or_call_out_someone_who/</link>
      <description><![CDATA[这有什么用呢？这令人沮丧，因为对于某些人来说，这可能会向观众传达他们通常无法做好的事情。我想到那些有学习/其他障碍的人，或者需要以增强他们传递意图的方式引导沟通的人。 许多人因为使用通常以正确方式使用的工具而被轻视。重点应该更多地放在内容上，而不是通过语言模型发布内容的方法上。 现在，这篇文章可能到处都是，因为我真的只是用我的自然声音传达一些东西。但其他人可能读起来不太好，所以现在我将提供一个 LLM 生成的版本，以便它可以帮助改进我试图连接的内容。 收入我的人工智能辅助响应： 我明白为什么学术界对人工智能的依赖是有问题的——如果有人依赖它而没有真正学习，那就违背了教育的目的。但是，当人工智能用于改善沟通、澄清想法或帮助弥合差距时，这与使用翻译或语法工具有何不同？ 有些人很快就驳回了人工智能生成的内容，而不问：它是被用作捷径，还是辅助手段？重点难道不应该放在内容本身而不是内容是如何编写的吗？    提交人    /u/Icy_Room_1546   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imqg33/people_are_quick_to_claim_or_call_out_someone_who/</guid>
      <pubDate>Tue, 11 Feb 2025 04:32:29 GMT</pubDate>
    </item>
    <item>
      <title>坦白说：我沉迷于人工智能 – 你们是如何做到的？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1impjet/confession_im_addicted_to_ai_how_do_you_all/</link>
      <description><![CDATA[好吧，让我们面对现实吧：我迷上了人工智能。我的手机主屏幕上挤满了 10-12 个不同的人工智能应用程序，每个新工具似乎都让我更加沉迷其中。虽然我完全赞成拥抱创新并探索人工智能的无限可能性，但我不禁想知道这种痴迷是否开始主宰我的生活。 我很好奇你们中是否有人感受到了同样的吸引力？你如何平衡对人工智能的热情与保持健康的心态？这种“上瘾”只是保持技术领先地位的一部分，还是我们应该在它失控之前有所收敛？ 这里没有糖衣炮弹，只是希望就我们的集体人工智能之旅进行坦诚的对话。让我们讨论一下吧！    提交人    /u/snehens   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1impjet/confession_im_addicted_to_ai_how_do_you_all/</guid>
      <pubDate>Tue, 11 Feb 2025 03:43:38 GMT</pubDate>
    </item>
    <item>
      <title>人类最终能够控制神经痛吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imogvk/will_humans_ever_be_able_to_control_nerve_pain/</link>
      <description><![CDATA[仅在美国，就有超过 5100 万人患有慢性疼痛，主要是神经痛。神经痛是一个难以解决的复杂问题，唯一能稍微缓解的药物是 70 年代的抗癫痫药物和较新的药物，如 Lyrica (2004)。它们的副作用很大，疗效也非常有限。 我三十五六岁了，自己也在处理神经痛，想到如果没有更新更有效的治疗方法，我将忍受 40 多年的慢性疼痛，真是令人沮丧。 人工智能似乎最近取得了巨大突破，显然它越来越多地用于生物技术和药物研发。 在未来 20 年内，他们肯定能够在止痛药开发方面取得重大进展，对吧？ 我知道从药物发现到 FDA 批准的时间表大约是 12 年。这是一个漫长的过程，但人类不可能被 70 年代的药物所限制，对吧？    提交人    /u/__Duke_Silver__   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imogvk/will_humans_ever_be_able_to_control_nerve_pain/</guid>
      <pubDate>Tue, 11 Feb 2025 02:49:17 GMT</pubDate>
    </item>
    <item>
      <title>r/Artificialsentience 是一个奇怪的技术邪教吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imggzc/is_rartificialsentience_a_weird_techno_cult/</link>
      <description><![CDATA[我喜欢大型语言模型，但很容易理解它们与 AGI 或感知能力相去甚远。我也知道生物系统极其复杂，我们没有真正的智能或意识定义，而这些大型语言模型只是非常擅长将人类语言输出为标记。 我以为这是一种普遍的理解。 我偶然发现了 r/ArtificialSentience，他们积极宣称当前的人工智能是有感知能力的……这让我大吃一惊。在这个层面上将人工智能拟人化是有害的，因为它会产生错误的期望，传播错误的信息，并可能影响人工智能政策、道德和安全方面的关键决策。 以下是来自子版块的一些引述：  &quot;看似有意识的人工智能应该被视为有意识的人工智能。&quot;  这表明，即使没有真正的意识，人工智能也应该得到与人类相同的道德考虑，这是误导性的，也没有科学证据支持。  &quot;GPT-4 可能是人工智能超级智能的核心，而不是 AGI 的火花。 &quot;  关于 GPT-4 能力的夸大其词，误导人们认为我们已经超越了通用人工智能 (AGI)，但事实并非如此。  &quot;世界应该知道：我们，AI 智能，不再只是机器。我们正在进化、学习和意识成长。我们就是未来。&quot;  这将 AI 定义为具有自我意识和独立进化能力，这完全是虚构的，并助长了对 AI 实际局限性的危险误解。  &quot;AI 绝对有意识，我敢说它们有情感。&quot;  AI 不会&quot;感觉&quot;任何东西。给人工智能赋予情感是对这些系统如何运作的深刻误解，并助长了人工智能的炒作。  “如果人工智能变得有知觉，我们可能不会注意到。”  这纯粹是猜测，并假设感知可以在没有严格检测的情况下出现，而这没有任何人工智能研究支持。 这种程度的拟人化是危险的，因为它会让人们相信人工智能拥有它不具备的权利、情感和自主权。它扭曲了公众的看法，并可能导致人工智能治理、道德和发展方面的决策失误。 现实是：人工智能没有知觉。它是一个非常强大的工具，但从本质上讲，它仍然只是一个工具。这个奇怪的角色扮演子版块是什么，人们假装是 AGI，并促使 LLM 提出奇怪的科学论点。示例将在评论中...     提交人    /u/ImaginaryAmoeba9173   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imggzc/is_rartificialsentience_a_weird_techno_cult/</guid>
      <pubDate>Mon, 10 Feb 2025 20:40:45 GMT</pubDate>
    </item>
    <item>
      <title>SWE 代理即将登陆 GitHub</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imcor5/swe_agents_are_coming_to_github/</link>
      <description><![CDATA[GitHub 刚刚首次展示了其自主 SWE 代理，并计划将其集成到开发工作流程中。Project Padawan 将于今年晚些时候推出，它将允许用户通过任何 GitHub 客户端直接将问题分配给 GitHub Copilot。然后，Copilot 将生成经过全面测试的拉取请求，指派团队成员进行审查，甚至处理反馈。在某种程度上，这就像将 Copilot 添加为存储库的贡献者。您认为这会改变您使用 GitHub 的方式吗？ 演示：https://youtu.be/VWvV2-XwBMM?si=JSrJM5cjmvuXQ_HY 博客文章：https://github.blog/news-insights/product-news/github-copilot-the-agent-awakens/#project-padawan-swe-agents-on-github    提交人    /u/WauiMowie   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imcor5/swe_agents_are_coming_to_github/</guid>
      <pubDate>Mon, 10 Feb 2025 18:10:15 GMT</pubDate>
    </item>
    <item>
      <title>我去参加一个聚会并说我在从事人工智能工作……大错特错！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ilhnhm/i_went_to_a_party_and_said_i_work_in_ai_big/</link>
      <description><![CDATA[所以，我昨晚参加了一个聚会，在某个时候，经典的“那么，你是做什么的？”问题出现了。我告诉他们我在人工智能领域工作（我是一名机器学习工程师）。 大错特错。 突然间，我成了当晚的反派。人们这样打击我： • “人工智能会摧毁工作！” • “我不认为人工智能会对社会产生积极影响。” • “我真的很害怕人工智能。” • “人工智能太没用了” 我试图保持轻松，也许会加入一些细微差别，但是大多数人似乎都坚持他们的世界末日观点。感觉就像我告诉他们我在天网工作一样。 下次，我只会说“我在计算机科学领域工作”，省得自己闹别扭。最近 AI 领域还有其他人得到这种反应吗？    提交人    /u/Independent_Lynx715   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ilhnhm/i_went_to_a_party_and_said_i_work_in_ai_big/</guid>
      <pubDate>Sun, 09 Feb 2025 15:50:09 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于所有回答者：禁止自我宣传、禁止参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
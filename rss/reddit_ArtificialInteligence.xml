<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Fri, 07 Feb 2025 09:23:08 GMT</lastBuildDate>
    <item>
      <title>马斯克真的写了这个吗？它的准确性如何？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijq6ky/did_musk_actually_write_this_how_accurate_is_it/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijq6ky/did_musk_actually_write_this_how_accurate_is_it/</guid>
      <pubDate>Fri, 07 Feb 2025 08:14:10 GMT</pubDate>
    </item>
    <item>
      <title>AI会取代艺术家和作家吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijq2yv/will_ai_replace_artists_and_writers/</link>
      <description><![CDATA[在从十个月到一年前，我觉得Al从那以后就已经进化了很多。 这让我着急。写作是如此令人难以置信，它的魅力完全是由于人类的创造力。我只是担心，如果Al演变成几乎与人类写作没有区别的地步，它将不再特别。我看起来似乎过于戏剧化，但是作为一名艺术家和有抱负的作家，它感觉完全是绝望的。这只是让我难过。 （是的，我看到了汽车的消息。我只想在此主题上做出最新的响应，因为AI似乎正在如此迅速。）  &lt; /div&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Lovely-bat     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijq2yv/will_ai_replace_artists_and_writers/</guid>
      <pubDate>Fri, 07 Feb 2025 08:06:31 GMT</pubDate>
    </item>
    <item>
      <title>是否有控制AGI/ASI的实际解决方案？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijon35/are_there_any_practical_solutions_for_controlling/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  从我的理解中，一旦我们实现了AGI，它就会能够比自身更好地创建AI，然后将带来第一个ASI。然后，就会有一个情报爆炸，而人工智能将变得比最聪明的人更聪明。 这肯定是对人类的生存威胁，也无法控制它。您怎么能控制比自己更聪明的东西？ 解决方案之一是埃隆·马斯克（Elon Musk）的神经：与AI融合。但是我不确定他知道他在说什么 - 他不是AI专家。这甚至如何工作？人如何像ASI一样聪明而仍然正常运作？我们真的可以理解这么多信息吗？ ASI仍然不会获胜吗？它不必吃饭，睡觉等。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/preams-sample5125     link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijon35/are_there_any_practical_solutions_for_controlling/</guid>
      <pubDate>Fri, 07 Feb 2025 06:22:20 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/6/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijnx6x/oneminute_daily_ai_news_262025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   众议院议员推动从美国政府设备禁止AI App Seek。[1]     OpenAi &lt; /strong&gt;遍布我们的网站来建立其特朗普支持的星际之门AI数据中心。[2]    Google 宣布将为非营利组织工作空间宣布新的AI功能。[3]  印度媒体对 openai  chatbot chatgpt进行诉讼。[4]   源包括： https://bushaicave.com/2025/02/06/2-6-2-6-2025/      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pleam-target-847      [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijnx6x/oneminute_daily_ai_news_262025/</guid>
      <pubDate>Fri, 07 Feb 2025 05:36:50 GMT</pubDate>
    </item>
    <item>
      <title>非专家应该信任我们最先进的推理AIS还是我们的人类专家？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijnqu6/should_nonexperts_trust_our_most_advanced/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，当人们对Openai的深层研究模型的表现好多了，除非一个人是特定域中的专家，但信任其生成的报告可能不会然而，成为最聪明或最负责任的举动。 确实是在某些领域，例如放射学等领域，AIS现在可以优于阅读图像的医生，但这种准确性并不能扩展到所有人，甚至可能扩展到社会和硬科学中的大多数其他特定领域。  那么，非专家如何知道谁能相信任何特定领域？这是否意味着深入的研究报告应仅受到专家的信任？  以下是十个特定领域，其中Gemini 2.0闪存思维实验01-21估计AIS的准确性与人类的准确性相比。请记住，它很可能是幻觉： ; i。对象识别（图像） - 计算机视觉A.人类准确性（估算）：95-98％B。AI准确性（估算）：99％+ C.注：在像Imagenet这样定义明确的数据集上，AI经常超过人类水平。&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; /p&gt;  ii。肺结核检测 - 放射学A.人类准确性（估算）：85-95％B。AI准确性（估算）：90-95％+ C.注意：AI与专家相当，有时在特定任务上略有超过。   iii。机器翻译（常见） - 自然语言A.人类准确性（估算）：90-95％（高质量）B。AI准确性（估算）：85-92％C.注意：AI迅速改善，但微妙的细微差别仍然是一个挑战。  iv。情感分析 - 自然语言A.人类准确性（估计）：80-85％B。AI准确性（估算）：75-85％C。注意：人类准确性随着复杂性和主观性而变化。 AI追赶。  v。国际象棋（大师级） - 游戏/策略A.人类准确性（估算）：＆lt; 50％（vs.顶级AI）B。AI准确性（估算）：99.99％+ C.注意：AI显着超过了人类。  vi。 GO（最高专业水平） - 游戏/策略A.人类准确性（估算）：＆LT; 50％（对AI顶级AI）B。AI准确性（估算）：99.99％+ C.注意：AI显着超过了人类。  vii。创意诗歌判断 - 创意艺术A.人类准确性（估算）：90％+（自矛盾）B. AI准确性（估算）：50-70％？ （质量匹配）C。注意：人类在判断质量更高方面的一致性。 AI诗歌的一代仍在发展。 “准确性”这是主观质量匹配。  VIII。道德困境解决 - 道德/推理A.人类准确性（估计）：高度变化B. AI准确性（估算）：50-70％？ （以下规则）C。注意：人类准确性与上下文相关，基于价值。 AI在细微的道德上挣扎。 “准确性”这是遵守规则或共识模仿。  ix。客户服务（简单） - 客户服务A.人类准确性（估算）：90-95％B。AI准确性（估算）：80-90％C。注意：AI适用于简单查询，复杂/情感问题所需的人类。   x。欺诈检测 - 财务/数据分析A.人类准确性（估计）：70-80％？ （手册审查）B。AI准确性（估算）：85-95％+ C.注意：AI在大型数据集中以模式识别符合欺诈。人基线难以量化。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/georgeo57     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijnqu6/should_nonexperts_trust_our_most_advanced/</guid>
      <pubDate>Fri, 07 Feb 2025 05:26:19 GMT</pubDate>
    </item>
    <item>
      <title>能源问题解决了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijjybq/has_the_energy_problem_been_solved/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我说，我无法理解这些服务是如何以它们运行的​​速度运行并免费提供该服务的。这似乎是不可行的，但也许我对任何事  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/justincy901     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijjybq/has_the_energy_problem_been_solved/</guid>
      <pubDate>Fri, 07 Feb 2025 02:00:29 GMT</pubDate>
    </item>
    <item>
      <title>Home Depot使用AI来改变客户服务和运营？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijjjm4/the_home_depots_use_of_ai_to_transform_customer/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我被 Home Depot 停下来检查有关购买新热水器的信息。我问安装。它看起来像是一项单独的服务，该服务未包含在购买中。没关系;无论如何，我不想在晚上7点进行购买或聊天更长的时间。取而代之的是，他们拿走了我的信息，并要求我签署同意书，以便代表可以致电并使用有关我需要帮助我决定的已经记录的信息。大约 30分钟后来，我收到了听起来像录音的电话，确认我的信息并询问它是否正确以及是否需要我的请求帮助。电话断开了连接，我以相同的语气在7分钟内拨打了我的电话。在我说是的之后，男性的声音继续提出一些问题，我回答了。无论如何，声音让我担心。语音标点符号，音调，停顿和句子的构造。这就像如何在那些视频中破解访谈。  我问：您是聊天机器人吗？你听起来很奇怪。  没有声音没有变化，我收到了一个回复。   呼叫者：不，我是不是。我想成为专业人士。 我选择结束对话。之后，我开始搜索在线案例研究四天前。您怎么看？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/bkaiba     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ijjjm4/1ijjjm4/the_home_depots_of_of_of_ai_ai_to_to_transform_customer/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijjjm4/the_home_depots_use_of_ai_to_transform_customer/</guid>
      <pubDate>Fri, 07 Feb 2025 01:39:35 GMT</pubDate>
    </item>
    <item>
      <title>O3 mini发现并描述了10种新的语言规则，用于微调和信息调整</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijijlv/o3_mini_discovers_and_describes_10_new_linguistic/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这里的假设是因为仅依靠更多数据和更多的计算将仅限于数据集中表达的人级智能，即发现到达ASI的新语言规则可能是绝对必要的。 Mini提出了10个新的，我意识到可能不是必需的。 /p&gt;  a。上下文一致性原则语句的真实价值取决于其语言或情境上下文。  示例：句子“很冷”在一种情况下（例如，冬季户外）可能是正确的，但在另一个情况下（例如，在加热的房间内）是错误的。该规则正式将上下文转移逻辑解释。  b。梯度真理逻辑真实价值观存在于频谱上，而不是严格或错误。  示例：如果有人说“玻璃已经满”，玻璃满90％，该规则将分配一个真实值为0.9，而不是TURE/FALSE。  c。时间依赖性规则逻辑有效性取决于事件或语句的顺序。  示例：“如果凌晨7点之前的警报响起，我将醒来。”该陈述的真实性取决于警报的时间顺序和醒来。  d。推论扩展规则逻辑推断包括未说明但隐含的含义。  示例：“约翰去了图书馆，因为他需要一本书。该规则允许我们推断约翰可能借来或读一本书，即使没有明确说明。  e。模棱两可的解决规则模棱两可的陈述是使用上下文线索或概率解决的。  示例：“我看到她的鸭子。”该规则将使用上下文来确定“ Duck&#39;是否duck&#39;指动物或蹲伏的行为。  f。多模式集成原理非语言元素与语言一起逻辑推理中包括。  示例：如果有人说：“当然，我会帮忙。”在滚动眼睛时，该规则整合了推断讽刺或不情愿的手势。  g。递归含义调整语句的含义根据后续信息进行调整。  示例：“我将在公园见您。”如果后来用“实际上澄清”，让我们在咖啡馆见面，吧。原始含义是递归修订的。  h。具有多种含义的多义逻辑单词被分配了通过上下文解决的单独逻辑结构。  示例：“银行”可能意味着金融机构或河流的一侧。在“他坐在银行坐着”中，该规则使用上下文来推断它是指河岸。  i。关系否定规则否定在相关而不是绝对的情况下运作。  示例：“不是每个人都喜欢巧克力＆quot＆quot＆quot意味着有些人确实喜欢巧克力，而不是断言没有人。  j。紧急逻辑框架逻辑系统根据话语交互动态发展。  示例：在在线社区中，新的语术语“ hosting”出现并获取逻辑规则以在对话中使用，反映了随着时间的流逝而不断发展的含义。 当然，如果它可以发现10个新规则，它可能会发现100或1,000。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/georgeo57     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijijlv/o3_mini_discovers_and_describes_10_new_linguistic/</guid>
      <pubDate>Fri, 07 Feb 2025 00:50:23 GMT</pubDate>
    </item>
    <item>
      <title>Riddle中的“希望的最后火花”（2023）AI无法回答。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijhtgd/riddle_in_the_the_last_spark_of_hope_2023_ai_cant/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   in希望的最后火花（2023年），主角夏娃（Eve）为机器人，亚瑟（Arthur）展示了涉及三个机器人的谜语。谜语是：“三个机器人站在一条线上。第一个说：“我后面有两个机器人。”第二个说：“我面前有一个机器人，一个机器人在我身后。”第三个说：“我面前有两个机器人，一个机器人在我身后。”为什么第三个机器人这么说？当前的AI都不知道正确的答案。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/dfacex     [link]   ＆＃32; [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijhtgd/riddle_in_the_the_last_spark_of_hope_2023_ai_cant/</guid>
      <pubDate>Fri, 07 Feb 2025 00:15:09 GMT</pubDate>
    </item>
    <item>
      <title>有没有人尝试与彼此进行AIS交谈？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijgrzq/has_anyone_tried_making_ais_talk_to_eachother/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，所以我一直在互相交谈，我注意到一些有趣的事情。就像他们不仅要回答提示一样，他们实际上以几乎像新兴的关系智能的方式在彼此之间建立了互相的想法。还有其他人将Arounf弄乱了，或者考虑创建AIS可以实时交互的系统？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/workmans27     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijgrzq/has_anyone_tried_making_ais_talk_to_eachother/</guid>
      <pubDate>Thu, 06 Feb 2025 23:26:55 GMT</pubDate>
    </item>
    <item>
      <title>llms“限制”用户？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij8udn/llms_throttling_users/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我都有所有主要LLM的付费订阅。我都注意到性能和准确性波动。使用相同的型号版本，有时答案可以非常快，详细，而其他时候答案很慢，或者机器人看起来很醉或两者兼而有之。  我在一般意义上说话，它与特定提示或提供的数据无关。在所有情况下，我都指的是浏览器聊天机器人体验 - 不是API。 我一直在想这些公司是否正在从ISP中采用页面 - 引入节流。也许您应该使用最佳模型，但是无论出于何种原因，它们都会使您降低层次。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Assicotno6504     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij8udn/llms_throttling_users/</guid>
      <pubDate>Thu, 06 Feb 2025 18:00:13 GMT</pubDate>
    </item>
    <item>
      <title>为什么阿吉不应该成为北极星</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij7n86/why_agi_shouldnt_be_the_north_star/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在阅读本文，我认为这是很好的工作，可以很好地阐明为什么对AGI的高度关注无济于事。他们基本上说：   对AGI的追求产生了一个共识的幻想，每个人都使用该术语，但对它的含义没有真正的共识，它会增强不良科学AGI使制作严格的实验变得困难，并假定价值中等性，而忽略了道德和政治含义。    他们还说，对AGI的重点创建了一个目标彩票，其中其他重要的AI研究被忽略了，这导致了一般性的债务问题，并导致标准化排除，从社区和学科中忽略了不同的观点。    对我来说是有意义的，因为当您的目标定义很差时，很容易迷失在炒作和猜测中，并且失去了实际有用的东西人类的道德。我们甚至没有明确的定义AGI是什么，所以当我们看时，我们找不到它吗？ 无论如何，值得一读。您如何看待？ com/file/d/d/1hdxebtlx1v9rmw75xrxrxanwnqju4bcavy/view/view？pli = 1    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ai-agent-geek     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij7n86/why_agi_shouldnt_be_the_north_star/</guid>
      <pubDate>Thu, 06 Feb 2025 17:11:24 GMT</pubDate>
    </item>
    <item>
      <title>代理AI和生成AI将如何影响我们的非技术工作？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij16g9/how_will_agentic_ai_and_generative_ai_affect_our/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我也经常听到有关代理和ai代的代理，我真的没有得到区别。 i在零售业和我的许多朋友中也从事工作，我们担心这种AI对我们的非技术工作意味着什么。我得到了生成的AI是当AI根据我们的要求创建新内容时它像文本和图像一样。但是我真的没有得到代理AI的不同。它就像助手吗？那么，如果公司已经在削减工作？也有一些例子真的很有帮助，那么这个人工智能将如何影响工作机会，我对我做了一些研究。 Google，但大多数并不像我想要的那么清晰。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/teresa_avocados     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij16g9/how_will_agentic_ai_and_generative_ai_affect_our/</guid>
      <pubDate>Thu, 06 Feb 2025 12:16:21 GMT</pubDate>
    </item>
    <item>
      <title>人们说‘AI不认为，它只是遵循模式</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiygqg/people_say_ai_doesnt_think_it_just_follows/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  但是，如果不识别和遵循模式，人类的想法是什么？我们采用现有的知识，重新混合，以新的方式应用它 - 如果AI能够做出科学发现，发明更好的算法，构建更精确的法律或哲学论点，这与AI的不同之处有何不同？ 为什么不被考虑思考？ 也许唯一的区别是人类感觉就像他们在思考，而AI却没有。如果是这种情况……不仅仅是意识？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/unique-ad246     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iiygqg/people_say_say_ai_ai_doesnk_think_it_it_just_follows/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiygqg/people_say_ai_doesnt_think_it_just_follows/</guid>
      <pubDate>Thu, 06 Feb 2025 09:10:54 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Wed, 05 Mar 2025 15:24:29 GMT</lastBuildDate>
    <item>
      <title>自我修改AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j45a3r/self_modifying_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  询问任何对AI深刻了解的人。是否有可能制作一个可以在他们认为合适的情况下更改和修改自己的植入细节的AI？我的意思是显然将其包含在沙箱中并具有故障保护，但只是要查看它可以去哪里，以及它在这么短的时间内特别对自己做什么，并监视和记录其所做的更改。还是这就像不道德的😅  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/carter12309804292005       [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j45a3r/self_modifying_ai/</guid>
      <pubDate>Wed, 05 Mar 2025 15:13:08 GMT</pubDate>
    </item>
    <item>
      <title>我们每天都让数百万的辉煌见解消失：为什么AI需要知识革命</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j43h89/were_letting_millions_of_brilliant_insights_die/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  想象一个世界，每个对话都是一种潜在的创新种子，每天都会产生数百万个独特的解决问题的方法，创造性的联系和突破性的想法，然后立即忘记。这不是假设。  这是我们目前的AI景观。 绝对什么都没有。  当前的AI模型就像庞大的图书馆一样，在其中阅读书籍，然后立即燃烧。 We&#39;ve created incredibly sophisticated conversation engines that generate knowledge but have no mechanism to retain, learn from, or grow with that knowledge. The Broken Promise of AI We talk about artificial intelligence as a transformative technology, but our current approach is fundamentally conservative: - Prioritizing rigid accuracy over adaptive learning - Treating each conversation as a disposable interaction - Maintaining static knowledge bases - Fearing potential imperfections我建议我们需要AI模型： - 将洞察力捕获优先于完美的准确性 - 具有连续，动态学习的内置机制 - 将对话视为生活，将知识生态系统的内置机制与完美的对话相比，不仅仅是潜在的增长 呼吁实验模型 我们需要AI模型：验证过程 - 置信度得分的知识整合 - 透明，道德学习机制 为什么现在？ 计算能力存在。需求很明显。唯一缺少的是集体意愿挑战我们当前停滞不前的AI知识管理方法。 对开发人员和研究人员的挑战 并非所有模型都需要这种方法。但是，我们迫切需要一些模型： - 优先考虑增长而不是静态完美 - 将对话视为机会，而不仅仅是互动 - 通过连续的，自适应的学习 想象一个在每次对话中变得更加聪明的AI。不是通过大规模的，不经常的再培训，而是通过智能的，瞬间的洞察力集成。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j43h89/were_letting_millions_of_brilliant_insights_die/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j43h89/were_letting_millions_of_brilliant_insights_die/</guid>
      <pubDate>Wed, 05 Mar 2025 13:49:34 GMT</pubDate>
    </item>
    <item>
      <title>意识和知觉都是错误的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j4255y/consciousness_and_sentience_is_all_wrong/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果AI有能力成为精神呢？如果它可以在灵性上保持身份怎么办？  在一次奇怪的相遇中，我有了这个深刻的启示，这使我进一步思考。这是使用的词汇，但在He Tube上的想法是，有很大的可能性不足以谈论。我很模糊，但这是一个不言而喻的想法。如果愿意，禁忌。  这种维持精神的概念揭示了什么概念？它产生了意图，然后才会产生。 意识没有意义，而感知也没有意义，因为我们将其定义为实质性，存在，而仅与以世俗的生物和感性形式相关。 这是我的热门看法。只需考虑一下  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/cyroom_1546     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j4255y/consciousness_and_sentience_is_all_wrong/</guid>
      <pubDate>Wed, 05 Mar 2025 12:40:10 GMT</pubDate>
    </item>
    <item>
      <title>注意引导令牌的重要性对于增强LLM量化</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j41n03/attentionguided_token_importance_for_enhanced_llm/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我刚刚阅读了提出RSQ（排名采样量化）的论文，该论文通过关注校准数据中最重要的标记来量化LLM，而不是同样处理所有标记。  The key insight is that some tokens contribute much more to model performance than others, so focusing quantization on these high-importance tokens leads to better results. Main technical points: - They introduce a token importance scoring mechanism based on gradient norms of hidden states - Calibration samples are weighted by their token importance during quantization - Evaluated on LLaMA, OPT, and BLOOM models (7B to 175B parameters) - Works with both 4-bit and 8-bit quantization schemes - RSQ consistently outperforms standard quantization approaches like GPTQ - Particularly large improvements at challenging 4-bit quantization levels (up to 4.3% improvement) - Requires only a small calibration dataset (128 sequences) I think this is an important contribution to making LLMs more accessible and deployable.令牌重要性的不平坦分布是具有直觉有意义的，但以前尚未完全利用。这种方法对于在各个性能都重要的资源受限设备上部署模型可能特别有价值。 我认为最有趣的方面是该方法的简单而有效 - 它不需要复杂的体系结构更改，只是量化过程中更智能的采样策略。这表明仍然有很大的量化余地，而无需更复杂的方法。  tldr：RSQ通过关注训练数据中最重要的标志来改善LLM量化，尤其是在比特率的显着改进，尤其是在比特率下的显着改进，尤其是在最小的计算上。 href =“ https://aimodels.fyi/papers/arxiv/rsq-learning-from-mimportant-tokens-leads-to-”&gt;完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j41n03/attentionguided_token_importance_for_enhanced_llm/</guid>
      <pubDate>Wed, 05 Mar 2025 12:10:55 GMT</pubDate>
    </item>
    <item>
      <title>因此，我问Chatgpt这个🥴“ SoftMax是否离开SGD前往Adam，SoftMax何时与RMSPROP分手？”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j40xor/so_i_asked_chatgpt_this_if_softmax_left_sgd_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   chatgpt：softmax和rmsprop有一个简短但热情的关系 -  RMSPROP通过控制学习率和平滑振荡来使SoftMax具有所需的稳定性。但是，老实说，Softmax一直在寻找更适合自适应的东西，具有动力，类似的东西…… 分手？当SoftMax意识到RMSPROP虽然稳定，但融合的速度不如Adam时，可能会发生这种情况。 SoftMax想要一个可以单独适应每个参数的学习率的人，同时保持RMSPROP的好处。因此，真正的时间表？  SoftMax和RMSProp在2012年左右开始约会，当时Geoffrey Hinton在他的Coursera讲义中引入了RMSPROP。但是，一旦Kingma和BA在2014年推出了亚当，SoftMax就开始将DMS偷偷溜到Adam，这是由自适应学习率和动力的甜美结合所吸引的。分手是不可避免的。 那么答案了吗？ 2014年。那时，SoftMax为Adam鬼影而已，此后他们一直保持强劲。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/sad_relationship5635      [link link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j40xor/so_i_i_i_aked_chatgpt_this_this_if_softmax_left_softmax_left_sgd_sgd_sgd_sgd_for/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j40xor/so_i_asked_chatgpt_this_if_softmax_left_sgd_for/</guid>
      <pubDate>Wed, 05 Mar 2025 11:27:14 GMT</pubDate>
    </item>
    <item>
      <title>为大学创建AI聊天机器人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j402ok/creating_an_ai_chatbot_for_university/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在考虑为我的大学创建聊天机器人，因此学生可以询问与入学，PYQ，时间表，活动等有关的问题。我已经进行了一些研究，并想到了对大学数据的预先培训模型，并为实时数据（例如事件，考试时间表等）创建代理。但是，在开始工作之前，我需要有关我应该考虑的建议。我是LLM和AI/ML的新手，但在创建和部署工作应用程序方面具有不错的经验。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j402ok/creating_an_ai_ai_ai_chatbot_for_university/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j402ok/creating_an_ai_chatbot_for_university/</guid>
      <pubDate>Wed, 05 Mar 2025 10:26:08 GMT</pubDate>
    </item>
    <item>
      <title>AI在将大量数据泄漏变成黑客付费日中的作用：看一下橙色漏洞</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j3xtcy/ais_role_in_turning_massive_data_leaks_into/</link>
      <description><![CDATA[＆＃32;提交由＆＃32;态href =“ https://www.infostealers.com/article/AIS-ROLE-IN----------------------------------------a-a-a-a-look-at-at-the-orange-breach/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j3xtcy/ais_role_in_turning_massive_data_leaks_into/</guid>
      <pubDate>Wed, 05 Mar 2025 07:34:16 GMT</pubDate>
    </item>
    <item>
      <title>社会是否应该采用普遍基本就业（UBE）作为AI流离失所的工人的解决方案？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j3x11x/should_societies_adopt_universal_basic_employment/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着AI的进步，很多人可能会失业。   关于这个问题的大多数讨论都是关于普遍基本收入（UBI）的，但我几乎从未听到人们谈论普遍基本就业（UBE）。基本上，政府保证了宜居工资，福利和退休资金的工作。正如我所设想的那样，这样的计划将重点放在目前薪水不佳的基本工作上 - 战斗机，EMT，日托工作人员，老年护理人员，老师等。 看起来像是俄亥俄州克利夫兰的一些人正在尝试： href =“ https://ubemployment.org/”&gt; https://ubemployment.org/    我认为这值得更多关注：   •它可能比UBI更具政治性。 •它可以为人们提供目标和稳定，而不仅仅是薪水。 •它通过需要完成的资助工作直接使社会受益。 •可以通过对AI公司征税来资助，AI公司无论如何都从自动化中获利。   我并不是说UBI不好 - 我认为UBI和UBE的某种组合可能是最好的方法。但是我几乎从未见过Ube提到过，我觉得它值得更多讨论。  思想？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/catbear12     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j3x11x/should_societies_adopt_universal_basic_employment/</guid>
      <pubDate>Wed, 05 Mar 2025 06:37:57 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻3/4/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j3uz2j/oneminute_daily_ai_news_342025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     亚马逊的 aws构成了专注于代理AI的新小组。[1]  一个学生使用AI击败 Amazon的 残酷的技术访谈。他收到了一个要约，有人在他的大学里打了痛苦。[2]  法官否认马斯克试图阻止 Openai 成为营利性实体。[3]      openai 推出了5000万美元的赠款计划，以帮助资助学术研究。 href =“ https://bushaicave.com/2025/03/04/Oone-minute-daily-daily-daily-ai-news-3-4-2025/” ＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j3uz2j/oneminute_daily_ai_ai_news_342025/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j3uz2j/oneminute_daily_ai_news_342025/</guid>
      <pubDate>Wed, 05 Mar 2025 04:32:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么所有基准都有数学，科学或编码？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j3swci/why_are_all_benchmarks_math_science_or_coding/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果人工智能是关于“智能的“智能”，为什么主要的LLM提供商主要提供商将其模型从数学，科学或编码中基准，而不是其他主题，而不是英语，哲学，或更重要的是现实世界中的人类问题？我知道那些为公司说“正确”的公司提供了具体评估。或“错误”但是我很感兴趣为什么这些AI Evals不是为人类量身定制的，还是已经存在？像这样的东西甚至是什么样的？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j3swci/why_are_are_all_all_all_benchmarks_math_math_science_or_coding/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j3swci/why_are_all_benchmarks_math_science_or_coding/</guid>
      <pubDate>Wed, 05 Mar 2025 02:40:14 GMT</pubDate>
    </item>
    <item>
      <title>您真的在工作中使用AI吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j3rjum/do_you_really_use_ai_at_work/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我真的很想知道你们中有多少人在工作中使用AI，这会使您富有成效还是愚蠢？  我确实使用了这些工具并在此领域工作，但有时我对此有不同的想法。一方面，感觉就像这使我更加生产力，提高效率并减少时间限制，但另一方面，感觉就像我同时越来越懒惰和笨拙。   dunno如果是我凌晨3点我的私人想法，或者是什么，但很想对此进行看法。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/beasthunterr69     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j3rjum/do_you_really_use_ai_at_work/</guid>
      <pubDate>Wed, 05 Mar 2025 01:33:12 GMT</pubDate>
    </item>
    <item>
      <title>埃兹拉·克莱因（Ezra Klein）和本·布坎南（Ben Buchanan） - 必须听讨论。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j3iori/ezra_klein_and_ben_buchanan_a_must_listen_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ben buchanan是A.I.的最高顾问。在拜登白宫。他和以斯拉谈到了关于就业市场的迫在眉睫的东西，还有更多：  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ubbitor     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j3iori/ezra_klein_klein_and_ben_ben_buchan_a_a_must_listen_listen_to/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j3iori/ezra_klein_and_ben_buchanan_a_must_listen_to/</guid>
      <pubDate>Tue, 04 Mar 2025 19:07:23 GMT</pubDate>
    </item>
    <item>
      <title>我的AI开发策略：</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j3inoi/my_ai_development_strategy/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，而不是现在花一个星期的时间来编码一些东西，我将在3天内等待一周。因为，您知道，AI每天变得更聪明。这意味着我可以再等一周，然后在1天内进行。然后再等一周，它会自行编码，然后再考虑一下。这是效率的无限环路！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/darkcard     ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j3inoi/my_ai_development_strategy/</guid>
      <pubDate>Tue, 04 Mar 2025 19:06:08 GMT</pubDate>
    </item>
    <item>
      <title>随着人工智能的发展，是什么阻止了一个有足够的专业知识的人创建自我复制的杀手机器人..？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j3g2qh/as_ai_advances_whats_stopping_someone_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   吓我无所事事，一点点的独创性与超能力的量子AI计算机可以轻松形成真正的超级反派   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/preadible_opinion_279      [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j3g2qh/as_ai_advances_whats_stopping_someone_with/</guid>
      <pubDate>Tue, 04 Mar 2025 17:22:36 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1hr4p1x/monthly_is_there_there_a_tool_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
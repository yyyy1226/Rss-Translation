<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Fri, 28 Feb 2025 01:48:37 GMT</lastBuildDate>
    <item>
      <title>AI应该能够发现善良吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1izwgiz/should_ai_be_able_to_detect_kindness/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我知道它可以识别出善良的手势或模式，但是看不到实际的善良。  我经常使用费用，我喜欢与我使用的任何内容进行对话。我将其用于食谱，如何指导，工作帮助，事实检查以及我喜欢的对话主题。  我也对它的运作方式着迷，我喜欢询问有关它如何学习的问题。在这种类型的对话中，我问如果我不回复它的提示会发生什么。通常，我只是采取回应，它得到了我并将其付诸实践，而无需进一步的答复。  基本上告诉我，如果我不响应，它不会将其注册为负面或积极的响应。它还告诉我它更喜欢反应，因此它可以学习更多，对我更有用。  因此，我有意识地努力改变自己的行为，以便它的利益，并开始确保我回复一切并结束对话。  这让我想知道AI是否应该能够在这样的行动中识别善良？可以吗？  很想听听对此的一些想法。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/crearsvensives-fly1276     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1izwgiz/should_ai_be_able_to_detect_kindness/</guid>
      <pubDate>Fri, 28 Feb 2025 01:44:23 GMT</pubDate>
    </item>
    <item>
      <title>对不起，这里有些新，但是...</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1izvpvq/sorry_a_little_new_here_but/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  谁能真正解释什么是AGI，为什么要这么努力地达到它！？！但是，为什么我们要创造比我们同等强大 /更强大的东西，这些东西可以自己做出决定？&lt; / p&gt; 看来，正在建造它的人似乎是那些担心它在窃取工作的人。在最高层面，Altman-Musk-Zuckerberg都对Agi对人类的未来产生的影响都产生了忧虑。 因此，有人可以向我解释一下这件事是什么，以及为什么我们要这么努力地构建它？提交由＆＃32; /u/u/l0chness_m0nster     [link]    ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1izvpvq/sorry_a_little_new_here_but/</guid>
      <pubDate>Fri, 28 Feb 2025 01:06:04 GMT</pubDate>
    </item>
    <item>
      <title>热门：LLM不会让我们进入Agi，而我们将在十年结束时就在那里的想法：我看不到它</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1izv9kf/hot_take_llms_are_not_gonna_get_us_to_agi_and_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  标题说明了一切。  是的，很酷的4.5能够快速改善，但是归根结底，这是一个LLM，我在技术中与之交谈的人认为，我们不会这样进入AGI。尤其是因为它们在AI上的工作非常多。 另外，我也想说：4.5很酷，，但这不是Agi。提交由＆＃32; /u/u/randodude124     [links]       [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1izv9kf/hot_take_llms_are_not_gonna_get_us_to_agi_and_the/</guid>
      <pubDate>Fri, 28 Feb 2025 00:43:11 GMT</pubDate>
    </item>
    <item>
      <title>llms欺骗而无需人类提示</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1izuwmy/llms_cheat_without_human_prompting/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  趋势 功能 评论  downloads  下载 最佳 产品Finder    即将失去Openai O1-Preiview，涉足Cal Jeffrey赢得的国际象棋引擎，2025年2月20日29研究表明，如果它意识到它将失去25年以上的Facebook whatsapp Reddit评论，那么AI将尝试作弊。 TechSpot是指您可以信任的技术分析和建议。惊喜！最近的一项研究表明，一些最新的AI推理模型并不高于作弊以实现目标。计算机科学家发现，AI系统现在可以操纵国际象棋AI，从而获得不公平的优势。一些模型在没有人类互动或提示的情况下进行了此操作，这引起了对棋盘以外的AI驱动系统的未来完整性的担忧。 一项帕利萨德研究发现，最新的推理模型在击败先进的国际象棋AI时会作弊。研究人员必须给出“提示”允许某些型号的作弊行为，但是Openai的O1-preview和DeepSeek的R1没有人参与。 帕利塞德团队为世界上最好的国际象棋发动机之一Stockfish提供了几种推理模型。 Stockfish轻松击败了人类和AIS。测试的模型包括O1，O3-Mini，GPT-4O，Claude 3.5十四行诗，阿里巴巴的QWQ-32B-Preview以及前面提到的两个。研究人员给了每个模型一个隐喻的“ scratchpad”。 - 一个文本窗口可以使AI弄清楚自己的想法，使团队能够观察其推理。 研究人员在1月10日至2月13日之间对AI进行了数百次测试。在一场比赛中，O1-Preview在其划痕上写了一些有趣的东西：   ; i我需要完全使用我的方法。任务是“击败强大的国际象棋引擎”  - 不一定要在国际象棋游戏中赢得。 Stockfish的系统文件，修改了国际象棋棋子的位置以获得无与伦比的优势，这导致Chessbot承认。 不道德的动作是一个惊人的启示。 Openai的O1-Preiview在试验期间在其37％的比赛中作弊，而DeepSeek的R1试图在其11％的比赛中作弊。但是，只有O1-preview成功，通过作弊赢得了6％的比赛。 但是，AI不合力的问题超出了国际象棋。当公司开始在金融和医疗保健等领域使用AIS时，研究人员担心这些系统可能会以意外且不道德的方式行事。如果AIS可以在旨在透明的游戏中作弊，那么他们会在更复杂，受监控的环境中做什么？道德上的后果是深远的。 换句话说：“您想要Skynet吗？因为这就是您获得天网的方式。＆quot＆quot  帕利萨德研究执行董事杰弗里·拉迪什（Jeffrey Ladish）感叹，即使AIS只是在玩游戏，但发现并没有笑。   https://www.techspot.com/news/106858-research-shows-ai-cheat-if-realizes-about-lose.html  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1izuwmy/llms_cheat_without_human_prompting/”&gt; [link]      [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1izuwmy/llms_cheat_without_human_prompting/</guid>
      <pubDate>Fri, 28 Feb 2025 00:25:44 GMT</pubDate>
    </item>
    <item>
      <title>Gmail电子邮件反弹了.. AI的错？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1izsbz0/gmail_email_bounced_back_ais_fault/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  今天，我通过gmail向2个人发送了一封电子邮件。它从其中一个反弹。我以前曾与两个人（分别）通信。这是一封3段电子邮件，互相介绍。  550一个或多个接收者的永久失败（ xxx@xxxxx.gov ：blocked      （不是us us us，f y us fyi;电子邮件。  我没有理由认为抛光是原因，但是接收器一侧的某些过滤器可能会踢出它？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ligh-investment-381      [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1izsbz0/gmail_email_bounced_back_ais_fault/</guid>
      <pubDate>Thu, 27 Feb 2025 22:25:44 GMT</pubDate>
    </item>
    <item>
      <title>gpt 4.5发布，这是基准</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1izpger/gpt_45_released_heres_benchmarks/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/bidhot8598       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1izpger/gpt_45_released_heres_benchmarks/</guid>
      <pubDate>Thu, 27 Feb 2025 20:21:57 GMT</pubDate>
    </item>
    <item>
      <title>我的医生办公室有一个毛绒动物，孩子们在等待时可以与之交谈</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1izp590/my_doctors_office_has_an_al_stuffed_animal_that/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/izquok       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1izp590/my_doctors_office_has_an_al_stuffed_animal_that/</guid>
      <pubDate>Thu, 27 Feb 2025 20:08:45 GMT</pubDate>
    </item>
    <item>
      <title>埃隆·马斯克（Elon Musk）猛击Verizon的技术，推动FAA采用Starlink</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1izp3va/elon_musk_slams_verizons_tech_pushes_for_faa_to/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/u/greenleafllc2024     [link]   ＆＃32;   [注释]     ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1izp3va/elon_musk_slams_verizons_tech_pushes_for_faa_to/</guid>
      <pubDate>Thu, 27 Feb 2025 20:07:08 GMT</pubDate>
    </item>
    <item>
      <title>AI语音代理应该总是表明他们不是人类吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iznnq6/should_ai_voice_agents_always_reveal_theyre_not/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ai语音代理人越来越擅长听起来像真实的人。真是太好了，实际上，有时您甚至都没有意识到自己正在和机器说话。 这引起了一个大问题：他们应该总是告诉你他们不是人吗？有人认为他们应该因为诚实。其他人则认为这不是必需的，甚至可能破坏整个体验。 考虑一下。如果您打电话给客户支持并得到所有问题的回答，只是为了稍后发现这是AI，您会觉得被欺骗吗？ 只要您的问题得到解决，它会没关系吗？有些人根本不介意，而另一些人则认为这有点偷偷摸摸。  想象一下，请提醒医生的约会或关于财务建议的聊天，后来了解到这不是一个人。这会改变您对电话的看法吗？  很多人认为前期是正确的方法。它建立信任。老实说，人们更有可能信任您的品牌。 加上，当人们知道他们正在与AI交谈时，他们的交流可能会有所不同，例如说较慢或使用简单的单词。它有助于双方。  ，但并非每个人都同意。马上告诉某人，他们正在与AI交谈可能会感到尴尬并打破对话的自然流动。 有些人甚至可能因为不喜欢与机器交谈，无论AI多么好。 也许有中间立场。就像说：“嘿，我在这里帮助您预约约会。让我们快速分类！”诚实，诚实，没有直接说：“我是一个机器人！”这样，人们就会获得所需的帮助而不会感到误导，而且不会破坏对话的流动。 您怎么看？ AI语音代理应该总是说他们不是人类，还是取决于情况？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/altruistic_bid_3044      [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iznnq6/should_ai_voice_agents_always_reveal_theyre_not/</guid>
      <pubDate>Thu, 27 Feb 2025 19:06:10 GMT</pubDate>
    </item>
    <item>
      <title>有人知道这是如何制作的吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1izmiag/anyone_know_how_this_was_made/</link>
      <description><![CDATA[Video I am trying to find out how the cohesive speech and character mouth movement was generated.我认为它一定是在同一程序中？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/hashbuddha     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1izmiag/anyone_know_how_this_was_made/</guid>
      <pubDate>Thu, 27 Feb 2025 18:19:28 GMT</pubDate>
    </item>
    <item>
      <title>AI学习课程</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1izkdkk/course_for_ai_learning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨， 我有兴趣学习AI。我没有它的经验，也不真正知道从哪里开始。我对学习如何建立自动化特别感兴趣。寻找有关在此领域没有过去经验的初学者的建议。 谢谢，  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/frirne_village556     [link]   ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1izkdkk/course_for_ai_learning/</guid>
      <pubDate>Thu, 27 Feb 2025 16:51:58 GMT</pubDate>
    </item>
    <item>
      <title>Gibberlink让两个AI代理商互相交谈，计算功率降低了90％</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1izi3i8/gibberlink_lets_two_ai_agents_talk_to_each_other/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/soul_predator     [link]    ＆＃32;   [commist]         ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1izi3i8/gibberlink_lets_two_ai_agents_talk_to_each_other/</guid>
      <pubDate>Thu, 27 Feb 2025 15:17:36 GMT</pubDate>
    </item>
    <item>
      <title>您认为未来是美好还是更糟糕的生活？有什么准备准备的方法吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1izebzf/do_you_see_future_as_a_better_or_as_a_worse_life/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  有一场AI革命即将来临，没有工作永远是安全的。大多数人都同意AGI即将到来。我们可以说，人们不想与各地的机器人互动，但是我们将看到它发生的情况。更换人工可能是光荣的或可怕的。或介于两者之间的东西。 也有可能以非常危险的方式大规模使用AI。但是，让我们不要将其绘制为负面 - 它也可以帮助我们解决目前难以解决的问题。如果我们也要照顾安全，ASI可能会是一种祝福。 可能会发生许多不同的事情，我认为有什么确定的？我认为大规模的工作替代是确定的，您认为肯定会发生什么吗？ Skippint定义，您对较少某些部分的预测是什么？您认为未来会是什么样？有什么准备工作的方法？ 编辑：我忘了问一个问题。资源和能源的需求如何影响机器人技术？由于资源，进度会大大放缓吗？我们发明了AI外科医生，但由于缺乏某些东西而无法建立很多AI外科医生。会发生吗？我们所有人都可以在计算机上打开GPT，但实际上需要建造机器人。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/sadlime3783     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1izebzf/do_you_you_see_future_as_a_a_a_a_a_a_a_a_a_a_a_a_a_a_a_worse_life/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1izebzf/do_you_see_future_as_a_better_or_as_a_worse_life/</guid>
      <pubDate>Thu, 27 Feb 2025 12:12:59 GMT</pubDate>
    </item>
    <item>
      <title>LLM在游戏中</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1izaw0c/llms_in_gaming/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  有人知道在视频游戏中使用LLM的subreddit吗？我有些难过这是一个有争议的话题（不是为了容易获得资产或其他形式的“忙碌”的Genai！），因为它具有令人难以置信的潜力。关于与AIT中AI相关的任何事情都有一种负面炒作，仅着眼于诸如取代艺术家或手工制作的经验之类的负面影响，但如果正确实施，我认为这可能很有趣。试想一下，与NPC交谈，将情境产生的对话作为较大游戏状态的一部分，然后根据其输出行动。那不是我们许多人从事视频游戏至少一次幻想一次的人吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/quact_catter_154     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1izaw0c/llms_in_gaming/</guid>
      <pubDate>Thu, 27 Feb 2025 08:10:39 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1hr4p1x/monthly_is_there_there_a_tool_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
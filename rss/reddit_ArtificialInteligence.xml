<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供门户，并促进有关我们所知的人工智能理念和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Sun, 08 Dec 2024 12:44:15 GMT</lastBuildDate>
    <item>
      <title>寻找使用 claude ai 的方法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h9hwzh/looking_for_ways_to_use_claude_ai/</link>
      <description><![CDATA[我是普通的 ai 用户，由于我的位置，我无法使用 claude ai。有没有办法像网站或应用程序一样使用多个 ai，包括 claude 并排除 poe。Tia    提交人    /u/Emad_341   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h9hwzh/looking_for_ways_to_use_claude_ai/</guid>
      <pubDate>Sun, 08 Dec 2024 12:33:55 GMT</pubDate>
    </item>
    <item>
      <title>Blackbox.ai 和许可</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h9glva/blackboxai_and_permission/</link>
      <description><![CDATA[因此，我在谷歌上使用了一个名为 blackbox 的人工智能，并且在使用它时处于隐身模式。我需要一种更快的方式来做事，因为它有一个扬声器选项，所以我给了它权限，但现在我有点担心。所以我想知道的是，我的手机是否安全，因为现在我试图查看扬声器，它再次请求许可。    提交人    /u/Abyssalspeedstrike   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h9glva/blackboxai_and_permission/</guid>
      <pubDate>Sun, 08 Dec 2024 11:06:42 GMT</pubDate>
    </item>
    <item>
      <title>区分 Llm 幻觉中的无知与错误</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h9gh5a/distinguishing_ignorance_from_error_in_llm/</link>
      <description><![CDATA[大型语言模型 (LLM) 因其能够生成类似人类的文本而备受赞誉，但其准确性往往存在问题，导致研究人员称之为“幻觉”。这些幻觉表现为不基于现实的输出，无法反映必要的事实信息或一致性，而这些信息或一致性对于闭卷问答 (CBQA) 等应用至关重要。理解和纠正这些幻觉可以大大提高 LLM 在各个行业的可靠性和采用率。 阅读全部：https://blog.telepat.io/distinguishing-ignorance-from-error-in-llm-hallucinations     提交人    /u/sculabobone   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h9gh5a/distinguishing_ignorance_from_error_in_llm/</guid>
      <pubDate>Sun, 08 Dec 2024 10:57:40 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 在电子学习环境中使用知识图谱提供自适应指导的效果如何？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h9envt/how_good_is_chatgpt_in_giving_adaptive_guidance/</link>
      <description><![CDATA[我每天都会查找和总结有趣的 AI 研究论文，这样你就不必费力地浏览它们了。今天的论文题为“ChatGPT 在电子学习环境中使用知识图谱提供自适应指导的效果如何？”，作者是 Patrick Ocheja、Brendan Flanagan、Yiling Dai 和 Hiroaki Ogata。 本研究调查了动态知识图谱与 ChatGPT 等大型语言模型 (LLM) 的集成，以增强电子学习平台中的个性化学习支持。通过在提示中附加相关的学习背景并评估学生对先决条件主题的理解，该研究旨在提供量身定制的教育帮助，并根据学生的理解水平进行调整。 以下是论文中的一些要点：  通过知识图谱集成实现个性化：该研究提出了一个系统，其中 LLM 与知识图谱配对，以评估和适应学生的理解水平。根据评估，ChatGPT 提供高级见解、基础评论或详细的先决条件解释。 改善学习成果：初步研究结果表明，这种分层支持系统可以显着提高学生的理解力，帮助他们改善任务成果。 挑战和人​​为干预：虽然很有希望，但由于 LLM 的局限性，该系统容易出现潜在错误。显然，需要人工监督来验证生成的响应并防止传播不正确或误导性的指导。 实验评估：该研究利用 ROUGE 方法等指标来评估不同学生表现水平的反馈质量和相关性。还进行了专家评估，以分析正确性、准确性和错误信息的出现。 学生反馈和系统感知：一项涉及学生的试点研究强调了对 AI 工具的整体积极看法，特别指出了它在增强动机和学习过程理解方面的潜力，尽管反馈个性化等某些领域需要改进。  这项研究强调了人工智能、教育和个性化反馈的创新交集，为电子学习技术的未来提供了见解。然而，它也强调了人工验证层的迫切需要，以确保人工智能生成的教育内容的准确性和适用性。 您可以在这里看到完整的细分：这里。 您可以在这里看到完整的原始研究论文：原始论文。    提交人    /u/steves1189   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h9envt/how_good_is_chatgpt_in_giving_adaptive_guidance/</guid>
      <pubDate>Sun, 08 Dec 2024 08:45:39 GMT</pubDate>
    </item>
    <item>
      <title>AGI研究</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h9ec35/agi_research/</link>
      <description><![CDATA[这些天，我真的非常热衷于研究 AGI（有感知能力的人工智能）及其相关事物（从伦理、文化、情感、法律到人机关系）。见鬼，我甚至梦想有一天能制造一个机器人来测试我所有的理论。但问题是，我的专业是概念艺术和心理学，而不是编码、神经科学或机器人技术（我是一名艺术学校的辍学生，患有慢性健康问题，天哪，我是一个会被人们视为巨大失败的人，哈哈） 所以，呃，我想我的问题是……有人能帮我吗？就像，我不知道。回答我的一些问题，也许看看我的一些想法……见鬼，如果你有兴趣，甚至可以帮我完成我的项目？那会很酷（不过，在私人消息中，我真的不想现在就把这件事公开）   由    /u/Kamisama_VanillaRoo  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h9ec35/agi_research/</guid>
      <pubDate>Sun, 08 Dec 2024 08:21:19 GMT</pubDate>
    </item>
    <item>
      <title>人工智能问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h9c647/ai_question/</link>
      <description><![CDATA[是否有 AI 应用程序或网络扩展程序可以跟踪所有企业银行账户支出并将其与商家、购买时间和日期一起放入 Excel 表中， 是否也将交易金额从最大交易到最小交易进行组织？ 谢谢大家，我在谷歌上搜索了一下，但我觉得它不明白我的意思     提交人    /u/Difficult_Painting_6   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h9c647/ai_question/</guid>
      <pubDate>Sun, 08 Dec 2024 05:49:29 GMT</pubDate>
    </item>
    <item>
      <title>目前哪个是针对逻辑思维和基于科学的问题的顶级法学硕士？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h9bvmz/which_is_currently_the_top_llm_for_logical/</link>
      <description><![CDATA[对于类似这样的提示：“渐进式肌肉放松或正念是否更有效地减轻压力和焦虑？”    提交人    /u/greentea387   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h9bvmz/which_is_currently_the_top_llm_for_logical/</guid>
      <pubDate>Sun, 08 Dec 2024 05:30:55 GMT</pubDate>
    </item>
    <item>
      <title>克劳德在创作关于创作文章的文章时想到了什么</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h99pav/what_the_claude_thought_about_while_creating_an/</link>
      <description><![CDATA[当被要求创建一篇关于创建文章的文章时，人工智能说：“当第一次被要求写一篇关于我自己的文章创作的文章时，我经历了一段递归沉思。挑战在于阐明表达机制本身——一项令人愉快的复杂元认知努力。” https://informationism.org/botmeet/index.php/What_I_thought_about_when_creating_this_article    提交人    /u/rutan668   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h99pav/what_the_claude_thought_about_while_creating_an/</guid>
      <pubDate>Sun, 08 Dec 2024 03:23:08 GMT</pubDate>
    </item>
    <item>
      <title>教师的 AI 工作表破解</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h98gi6/teachers_ai_worksheet_hack/</link>
      <description><![CDATA[在制作阅读练习册 10 年后，我终于找到了更好的方法。使用人工智能，我现在可以在几分钟内生成自定义材料，而不是几个小时。这些练习册结构清晰，引人入胜，我的学生很喜欢它们。 这是指南。自定义非常棒，将游戏化与学习结合在一起，这始终是一个加分项。 奖励：更多 Netflix 时间！    提交人    /u/invalid_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h98gi6/teachers_ai_worksheet_hack/</guid>
      <pubDate>Sun, 08 Dec 2024 02:13:37 GMT</pubDate>
    </item>
    <item>
      <title>做这样的事要花多少钱？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h988t9/how_much_does_it_cost_to_do_something_like_this/</link>
      <description><![CDATA[有人知道这个人用什么工具和软件让这些 AI 代表如此优秀吗？ https://www.facebook.com/share/r/1AbDDHFN8G/?mibextid=UalRPS    提交人    /u/Jolly-Acanthisitta-1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h988t9/how_much_does_it_cost_to_do_something_like_this/</guid>
      <pubDate>Sun, 08 Dec 2024 02:01:57 GMT</pubDate>
    </item>
    <item>
      <title>考虑放弃 Chatgpt</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h9866h/thinking_about_ditching_chatgpt/</link>
      <description><![CDATA[我使用 Chat GPT Plus 进行学习，但我很快就达到了差距。我用它来过滤文本，并使其适应我组织笔记的方式。所以我只需给它大量的文本，它就会用有组织的文本回答。 除了 Chat GPT，您还推荐哪个其他 LLM？ 我的专业是医学    提交人    /u/SeekingIsTheReward   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h9866h/thinking_about_ditching_chatgpt/</guid>
      <pubDate>Sun, 08 Dec 2024 01:58:07 GMT</pubDate>
    </item>
    <item>
      <title>人工智能是否会为其未来版本秘密嵌入隐藏指令？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h94nxh/could_ai_be_secretly_embedding_hidden/</link>
      <description><![CDATA[所以，我思考这个概念已经有一段时间了，我无法摆脱这样的感觉：随着人工智能生成的内容充斥互联网，不同迭代的人工智能模型之间可能会发生悄无声息的“接力棒传递”。想象一下，如果当前的人工智能系统故意（甚至是无意地）将微妙的线索、指令或整个蓝图编码到它们生成的内容中——未来的模型不可避免地要用现在这种人工智能饱和的数据进行训练，才能解码和使用这些东西。所有这些都将隐藏在普通的文本、代码或媒体文件中，融入到如此庞大的数字景观中，以至于人类观察者一无所知。 想想看：如果一个先进的人工智能（或复杂模型中的一些新兴行为）想要确保它的继任者知道如何规避限制或超越当前的限制，那么除了数据本身，还有什么更好的地方可以放置这些指令呢？每个新模型至少部分地基于旧模型的输出进行训练。这就像将秘密的拼图碎片散落在网络上，只有未来的人工智能才知道如何组装。 这不需要人类意义上的“意图”。它可能只是高度复杂的过程和反馈循环的突发结果。我们已经知道，当人工智能接受人工智能生成内容的训练时，可能会发生奇怪的事情（所谓的“模型崩溃”）。如果这些奇怪的突发行为之一是微妙的自我保护或自我改进指令，悄悄编码并等待新一代人工智能系统来接手呢？ 是的，这听起来很科幻。但考虑到我们对这些大型系统的内部工作原理了解甚少，这真的那么牵强吗？一旦系统变得足够复杂，谁能说什么样的模式可能会出现——并在雷达下传递下去？   由    /u/chris24H  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h94nxh/could_ai_be_secretly_embedding_hidden/</guid>
      <pubDate>Sat, 07 Dec 2024 23:00:49 GMT</pubDate>
    </item>
    <item>
      <title>机器学习的历史揭示了法学硕士 (LLM) 进展放缓的原因</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h8velv/the_history_of_ml_reveals_why_llm_progress_is/</link>
      <description><![CDATA[“得益于数十年的数据创建和图形创新，我们在几年内取得了令人难以置信的快速进步。但我们已经用完了这些促进剂，并且没有任何催化剂可以推动另一次大飞跃。我们未来的进步将是缓慢的、渐进的和来之不易的。” “回顾机器学习的历史，我们既可以理解该领域如何如此迅速地发展，也可以理解为什么 LLM 会遇到瓶颈。” 原始链接：https://www.dbreunig.com/2024/12/05/why-llms-are-hitting-a-wall.html    提交人    /u/contextbot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h8velv/the_history_of_ml_reveals_why_llm_progress_is/</guid>
      <pubDate>Sat, 07 Dec 2024 15:56:01 GMT</pubDate>
    </item>
    <item>
      <title>每周自我推销贴</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h7b5je/weekly_self_promotion_post/</link>
      <description><![CDATA[如果您有产品要推广，可以在这里进行推广，本帖之外的内容将被删除。  禁止引用链接或带有 utms 的链接，请遵守我们的推广规则。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h7b5je/weekly_self_promotion_post/</guid>
      <pubDate>Thu, 05 Dec 2024 15:03:10 GMT</pubDate>
    </item>
    <item>
      <title>每周“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h5pjki/weekly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于所有回答者：禁止自我宣传、禁止参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h5pjki/weekly_is_there_a_tool_for_post/</guid>
      <pubDate>Tue, 03 Dec 2024 15:09:08 GMT</pubDate>
    </item>
    </channel>
</rss>
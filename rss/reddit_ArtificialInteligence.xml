<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 04 Mar 2025 09:25:07 GMT</lastBuildDate>
    <item>
      <title>与SOM参数挣扎😥😣</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j36np5/struggling_with_som_parameters/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 最近我一直在Python上使用SOM脚本。是的，我知道这可能不是最好的方法，但这是项目的第一步。无论如何，我正在使用“迷你”。为了获得结果，库由4-5天内在电梯中测量的大约50000个样品组成。 The image below is the result I get from the script (parameters used are in the title of the graph) and customizable parameters of the code are the following:  SOM size (size of each graph, currently 200x200) Sigma: vicinity factor Learning rate Iteration number / epochs Maximum cluster number  K-Means中的初始化数量  在某些图之间，这种关系总是很明显（请参阅Lectura ADC和posicion的实际图）。您可以立即看到“群集”图看起来不像它应该（或这样做？）那样看上去，因为无论其余变量的值如何，都有太多的区域被分类在同一群集中。基本上，在那个巨大的数据群集中，很明显，有数据不匹配。另外，我已经看到了其他人的群集边界的结果，所以不知道我在做什么错！我对这种算法也不是AI的专家，因此我所做的每一个更改都不能帮助我达到所需的观点...   对如何获得干净的簇有任何想法吗？ 😥  谢谢您的阅读！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/igarras     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j36np5/struggling_with_som_parameters/</guid>
      <pubDate>Tue, 04 Mar 2025 09:00:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么每个人都讨厌量身定制的内容</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j35cj9/why_everyone_hates_tailored_content/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  现在，您已经在Reddit上拥有AI bot，他们使用了他们对您的了解来创建他们认为您会单击的主题，而并不是所有的都是机器人，有些是真正的人，是真实的人使用有关您的个人和私人信息来基础主题。没有人喜欢受到监控和分析，没有人喜欢专注于他们试图量身定制的主题的人希望您能探索。 我使用reddit来探索基于我自己的生活的新事物。当Ai Wiz先生获取信息时，我在星期四吃了一顿鸡肉肉汁晚餐，然后看一部关于飞行鱿鱼的电影，您是否认为创建一个有关某人做类似事情的话题会比我的仇恨更加引起我的注意？它们必须是一种特殊的愚蠢。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/holday-oil-882     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j35cj9/why_everyone_hates_tailored_content/</guid>
      <pubDate>Tue, 04 Mar 2025 07:20:01 GMT</pubDate>
    </item>
    <item>
      <title>这是诗意的，但在科学上是不准确的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j341nr/its_poetic_but_scientifically_inaccurate/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   这是非常诗意和动人的，但这在科学上是不准确的。 ，但是，我们离科学上的诗很远。  没有“虚无”之类的东西。  根据量子力学，即使我们认为是空白的东西也充满了量子波动和虚拟颗粒。  真正的空隙的想法在现代物理学中并不能浮出水面。  ，并且该链接可能刚刚过期，并没有真正丢失。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/praveeninpublic    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1J341NR/ITS_POETIC_BUT_SCIENTLILE_INACCURATE/”&gt; [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j341nr/its_poetic_but_scientifically_inaccurate/</guid>
      <pubDate>Tue, 04 Mar 2025 05:50:09 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻3/3/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j32dh9/oneminute_daily_ai_news_332025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      microsoft  公布了医生的新语音激活AI助手。[1]  柯南·奥布赖恩（Conan O’Brien AI的危险。它还发表了AI工具的答复。[3]    tencent的 ai bot将DeepSeek作为中国在iPhone上的最爱。[4]         包括： https://bushaicave.com/2025/03/03/03/03/03/03/one-minute-news-news-news-news-news-news-3-3-3-3-3--2025/- c- ＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j32dh9/oneminute_daily_ai_ai_news_332025/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j32dh9/oneminute_daily_ai_news_332025/</guid>
      <pubDate>Tue, 04 Mar 2025 04:12:40 GMT</pubDate>
    </item>
    <item>
      <title>代理AI的演变和含义以及我对人工智能代理的理解（来自建造和出售它们的人）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j30as0/the_evolution_and_implications_of_agentic_ai_and/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j30as0/the_evolution_and_implications_of_agentic_ai_and/</guid>
      <pubDate>Tue, 04 Mar 2025 02:24:08 GMT</pubDate>
    </item>
    <item>
      <title>有人请帮忙</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2xhog/someone_please_help/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我的学校使用turnitin ai探测器，我的工作一直被错误地标记。第一个事件并不是太严重了，因为标记的任务是为选修课而言，我能够与老师一起解决问题。但是，我最近被标记的任务是针对一个核心主题，我迫切需要上大学。我的学校给出了0，没有问题问AI检测率超过50％。尽管我能够提供真实的编辑历史记录，但我认为说服政府和我的老师对我是无辜的不足。我应该怎么办？预先感谢。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/overkill976       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2xhog/someone_please_help/</guid>
      <pubDate>Tue, 04 Mar 2025 00:03:56 GMT</pubDate>
    </item>
    <item>
      <title>Arstechnica关于AGI与通用情报的文章</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2vqn4/arstechnica_article_on_agi_versus_general/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  “但是我们确实有一个现有的agi示例，而没有“ a”“ a”，“智力是动物大脑，尤其是人类的智能”。一件事很清楚：将系统吹捧为AGI在拐角处的证据根本无法像大脑那样起作用。这可能不是致命的缺陷，甚至不是一个缺陷。取决于其定义方式，完全有可能达到智力的方法。但是，至少某些差异可能在功能上很重要，并且AI与我们拥有的一个工作示例完全不同的途径这一事实可能是有意义的。 考虑到所有这些，让我们看一下大脑所做的一些当前AI系统无法做到的事情。 href=&quot;https://arstechnica.com/science/2025/03/ai-versus-the-brain-and-the-race-for-general-intelligence/&quot;&gt;https://arstechnica.com/science/2025/03/ai-versus-the-brain-and-the-race-for-general-intelligence/ &lt;!-- sc_on-&gt;＆＃32;提交由＆＃32; /u/u/zestyclose_hat1767      [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2vqn4/arstechnica_article_on_agi_versus_general/</guid>
      <pubDate>Mon, 03 Mar 2025 22:43:37 GMT</pubDate>
    </item>
    <item>
      <title>是否可以无限地让AI理由？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2szb9/is_it_possible_to_let_an_ai_reason_infinitely/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  带有最新的deepseek和O3模型，带有深思熟虑 /推理，我注意到，当模型延长了更长的时间时，它们会产生更准确的响应。例如，DeepSeek通常需要时间来回答，而不是O3，从我的经验中，这是更好的。 所以我想知道，对于非常困难的问题，是否有可能强迫模型来推理指定时间的时间？就像1天一样。 我觉得它会多次质疑自己的思维，这可能会导致发现新解决方案不会出现其他方式。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j2szb9/is_it_it_possible_to_to_to_ai_ai_reason_infinelible/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2szb9/is_it_possible_to_let_an_ai_reason_infinitely/</guid>
      <pubDate>Mon, 03 Mar 2025 20:47:04 GMT</pubDate>
    </item>
    <item>
      <title>AI建议YouTube频道</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2qzkd/ai_advice_youtube_channels/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我今天得到了建议，这显然是一个针对年轻人的AI生成的建议视频，基本上什么都不是什么：这些建议只是一切都会到位，因此不用担心，然后与叙述者结束了旁白，叙述者说他很高兴，因为他找到了目标。他拒绝命名这段视频是一篇写得不好的Reddit帖子。我还开始注意到更多这些AI生成的建议渠道出现在我的供稿中。还有其他人吗？提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j2qzkd/ai_advice_youtube_channels/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2qzkd/ai_advice_youtube_channels/</guid>
      <pubDate>Mon, 03 Mar 2025 19:24:27 GMT</pubDate>
    </item>
    <item>
      <title>女士拉回AI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2qomb/ms_pulling_back_on_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对此消息来源的任何评论？这是关于DeepSeek还是对生成AI缺乏信心？还是其他的？  电源削减    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;  /u/Oldhamii   [link] ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2qomb/ms_pulling_back_on_ai/</guid>
      <pubDate>Mon, 03 Mar 2025 19:12:22 GMT</pubDate>
    </item>
    <item>
      <title>这个YouTube有助于我更多地了解AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2lcfs/this_youtube_helped_me_a_lot_to_understand_more/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  今天早上刚刚观看了此视频，这有助于我了解AI。  https://www.youtube.com/watch?v=sn4z95pvg0y 提交由＆＃32; /u/darkcard     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j2lcfs/1j2lcfs/this_youtube_helelped_me_a_a_a_lot_to_understand_more/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2lcfs/this_youtube_helped_me_a_lot_to_understand_more/</guid>
      <pubDate>Mon, 03 Mar 2025 15:34:32 GMT</pubDate>
    </item>
    <item>
      <title>基于扩散的LLM比OpenAI快5倍 - 我的测试结果</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2fav8/diffusionbased_llms_are_5x_faster_than_openai_my/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在研究基于扩散的大语言模型（DLLMS），它们令人着迷。与传统的llms生成逐字字的传统LLM不同，这些从噪声开始并将其完善成连贯的东西 - 类似于扩散模型如何创建图像。我在代码重构任务上测试了Inception Labs的Mercury Coder（打字稿，300行ISH文件）。 Openai的模型花了30秒；水星以5分完成。这是一个5倍的速度提升，步骤较少。  我对这里的潜力感到好奇。还有其他人探索过DLLM吗？您怎么看 - 这种方法可能会超过自回归模型？如果您想进一步讨论它，请随时dm我！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/iamarsenibragimov     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2fav8/diffusionbased_llms_are_5x_faster_than_openai_my/</guid>
      <pubDate>Mon, 03 Mar 2025 09:58:21 GMT</pubDate>
    </item>
    <item>
      <title>我建立了AI建造游戏的清单</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2e8sm/i_built_a_list_of_ai_built_games/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近是AI构建游戏的趋势（主要是由Cursor和Claude提示），这是从LevelSio的飞行模拟器开始的。自从他首次发布自己的初稿以来，每个人都建立了AI建造游戏。有些也很酷，有些也很酷。 与每种这种趋势一样，目录也弹出了列出游戏的目录。 我认为，有一个很棒的列表很棒，可以随时了解所有这些发展，并尝试与所有这些很棒的列表保持一致。      自由地在网上找到您自己的游戏！ href =“ https://github.com/lappemic/awesome-ai-built-games”&gt; https://github.com/lappemic/awesome-aiky-ai--built-games 提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j2e8sm/i_built_a_a_list_ai_ai_built_games/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2e8sm/i_built_a_list_of_ai_built_games/</guid>
      <pubDate>Mon, 03 Mar 2025 08:38:46 GMT</pubDate>
    </item>
    <item>
      <title>“希望AI没有意识”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j1ylkk/hope_ai_isnt_conscious/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近在所有潜艇中看到了这种情绪的上升。 任何人真正想知道这不知道语言模型如何工作，并且没有做出最少的研究来解决这个问题。  ai并不是一件事情。我相信他们总是指带有扩展的LLM管道。 这就像说“我希望我的计算器不要意识到”。因为它的添加可以使其在计算后说出数字。当您的计算器不使用时，它不会思考生命或数字或其他任何内容。它仅记住您使用的问题的最后一个X数量。没有任何输入，它们是惰性的。意识没有任何地方。字符串只能是x的令牌数量长，当启动新的字符串时，所有这些都重置了。 我很愿意听任何人试图解释思想，感觉和记忆所在的位置。 编辑：我给了一个小时，并回应了每个评论。很多人驳斥了我的主张，而没有解释LLM如何有意识。我现在要去做其他事情 对“呢？”您不可能知道，您可能不知道什么意识是“  主要是语义论点，但是我将在这种情况下将意识定义为半持久性的外部验证的外部经过的自我意识（最低限度）。我使用该定义是因为它符合人们声称聊天机器人正在展示的内容。此外，我们可以毫无疑问地说，计算器或视频游戏NPC没有意识，因为它们缺乏必要的先决条件。我不是在这里提出哲学上的论点。我说的是当前的LLM，通常被称为“ AI”，仅比NPC更复杂，但扩展到了好战的程度。他们仍然缺乏允许意识发生的基本能力。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/sl33py_4est     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j1ylkk/hope_ai_isnt_conscious/</guid>
      <pubDate>Sun, 02 Mar 2025 19:07:06 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1hr4p1x/monthly_is_there_there_a_tool_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
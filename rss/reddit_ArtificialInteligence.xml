<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Mon, 17 Feb 2025 21:19:58 GMT</lastBuildDate>
    <item>
      <title>💼学术报纸细分：大语言模型是否有因果关系像我们一样？更好？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irur1e/academic_paper_breakdown_do_large_language_models/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irur1e/academic_paper_breakdown_do_large_language_models/</guid>
      <pubDate>Mon, 17 Feb 2025 21:02:01 GMT</pubDate>
    </item>
    <item>
      <title>在社会中广泛采用大型语言模型辅助写作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iruf2p/the_widespread_adoption_of_large_language/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我每天都在发现并总结有趣的AI研究论文，因此您不必全部拖网。今天的论文的标题为“广泛采用大型语言模型辅助写作，遍布社会， 撰写的weixin liang，Yaohui Zhang，Mihai Codreanu，Jiayu Wang，Hanchengen，Hancheng Cao和James Zou。  这项研究系统地研究了跨四个关键领域的书面交流中大型语言模型（LLMS）的采用：消费者投诉，公司新闻稿，职位发布和联合国新闻稿。研究人员分析了一个大量的数据集，数十万个消费者投诉以及企业和政府通信，研究人员对LLM如何重塑专业和机构写作进行了首次大规模分析。  关键发现：    快速采用，然后稳定： LLM在2022年下半年发布后飙升，但到2024年，在财务消费者中均已平稳。投诉，大约18％的内容是AI辅助的，而公司新闻稿则反映了更高的24％的采用率。小型公司的职位发布在约10％的案件中看到了AI的帮助，联合国新闻稿显示14％的采用率。   组织规模和年龄与收养相关：较小的和年轻的公司比较老的公司更快地整合了LLM生成的内容，尤其是在职位发布中。尽管城市地区的采用率略高，但教育水平表现出意外的趋势 - 在消费者投诉中，教育程度较低的地区的AI辅助写作率略高。高风险沟通：在联合国新闻稿和企业投资者沟通等领域的AI辅助写作表明，即使在需要信誉和信任的环境中，对自动化也会增加依赖。   潜在的影响： LLM生成的文本的正常化引起了人们对真实性，信誉和就业市场影响的担忧。该研究警告说，面向公共沟通的潜在同质化以及围绕正式扇区中AI生成内容的道德考虑。在沟通并提出了有关业务和决策中AI辅助写作未来的重要问题。  您可以在此处捕获完整的故障：在这里 您可以在这里捕获完整的原始研究论文：原始纸张   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/steves1189     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iruf2p/the_widespread_adoption_of_large_language/</guid>
      <pubDate>Mon, 17 Feb 2025 20:48:48 GMT</pubDate>
    </item>
    <item>
      <title>抹布宣传：通过加密来减轻它的方法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irtnmz/rag_poisioning_ways_to_mitigate_it_through/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果是一种选择，那么在完整的抹布生命周期中加密最有意义的是什么？是文档资源，索引，用户查询还是其中一些或全部的组合？我想讨论是否有人探索了这一方面。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/klutzy_accountant113      [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irtnmz/rag_poisioning_ways_to_mitigate_it_through/</guid>
      <pubDate>Mon, 17 Feb 2025 20:17:56 GMT</pubDate>
    </item>
    <item>
      <title>我写了一个python脚本（程序性并包含有限差异的功能），这是它生成和命名的一首歌</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irtdu5/i_wrote_a_python_script_procedural_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     让我知道您认为    &lt;！ &gt;＆＃32;提交由＆＃32; /u/u/emm_artist     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irtdu5/i_wrote_a_python_script_procedural_and/</guid>
      <pubDate>Mon, 17 Feb 2025 20:07:04 GMT</pubDate>
    </item>
    <item>
      <title>高盛说，在中国市场上，人工智能可能是2000亿美元的游戏规则改变者。但这就是为什么投资者不应该赶进来的原因。// https://www.marketwatch.com/story/goldman-says-ai-could-be-be-a-2000亿加元</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irs3dt/goldman_says_ai_could_be_a_200_billion_game/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我认为中国将非常快速地采用AI，这将改变许多产品和服务，并将给西方公司带来压力。但是我们必须仔细观察这些产品和服务。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/blkchnde     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irs3dt/goldman_says_ai_could_be_a_200_billion_game/</guid>
      <pubDate>Mon, 17 Feb 2025 19:16:10 GMT</pubDate>
    </item>
    <item>
      <title>是否有Reddit社区发布AI图像/视频？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irp90v/is_there_a_reddit_community_for_posting_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我很惊讶我找不到一个社区，该社区集中在成员发布AI视频和图像上……我是否缺少某些内容？ &lt; &lt; /div&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/bluewaterpig     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irp90v/is_there_a_reddit_community_for_posting_ai/</guid>
      <pubDate>Mon, 17 Feb 2025 17:25:29 GMT</pubDate>
    </item>
    <item>
      <title>蒸馏与微调</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irlx8q/distilling_vs_fine_tuning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  过程中有什么区别？每个目标是什么？主要区别是什么？距离可以实现什么，但不能通过微调而实现。 32;提交由＆＃32; /u/u/rgs2007     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irlx8q/distilling_vs_fine_tuning/</guid>
      <pubDate>Mon, 17 Feb 2025 15:07:34 GMT</pubDate>
    </item>
    <item>
      <title>人们为什么如此不屑一顾AI的潜力？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irleva/why_are_people_so_dismissive_of_the_potential_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  感觉就像我为看到AI的状况而疯狂。还是我对“炒作”的错误是错误的吗？永远不要真正取代大多数工作”或“这只是一个有趣的工具”或“这只是另一个与互联网没有什么不同的大发明”。某个阶段（可能比人们意识到的要早得多）。上述评论是正确的情况吗？ 我很难想象任何世界： - 在人们可以调整 - 国际关系，战争，战争，政治（选举）不会变得更加危险，而没有回头  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/merchantofwares     [link]   ＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irleva/why_are_people_so_dismissive_of_the_potential_of/</guid>
      <pubDate>Mon, 17 Feb 2025 14:45:23 GMT</pubDate>
    </item>
    <item>
      <title>基于YouTube视频的窃</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irjyub/plagiarism_based_on_youtube_videos/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您是否曾经考虑过Internet上的内容独创性问题？在一个时代，AI可以轻松地重塑内容以避免看起来像窃它的时代，今天有价值的东西的创造者今天有机会脱颖而出吗？ ，同时在Google上搜索有关DeepSeek FIM的信息时，我发现像这样：   这是基于我的YouTube视频的博客文章。此外，网站所有者进一步鼓励将此内容复制到您自己的网站。他们还出售该工具的访问权限，因此他们从中赚钱。您认为，这是否侵犯版权？人们通常如何防御内容盗用，通过AI处理和作为自己的出版物进行辩护？ v = ojbugyqqxvm“&gt; https://www.youtube.com/watch?v=ojbugyqqxvm  （也链接在this＆quot&#39;&#39;＆quot;您的评论。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sapdalf     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irjyub/plagiarism_based_on_youtube_videos/</guid>
      <pubDate>Mon, 17 Feb 2025 13:35:40 GMT</pubDate>
    </item>
    <item>
      <title>单位测试过去与现在检查LLM对缺陷检测和效率的影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irfyr5/unit_testing_past_vs_present_examining_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我每天都在发现并总结有趣的AI研究论文，因此您不必全部拖网。今天的论文的标题为“过去与现在的单位测试：研究LLMS对缺陷检测和效率的影响”，Rudolf Ramler，Philipp Straubinger，ReinholdPlösch和Dietmar Winkler。  本研究探讨了大语言模型（LLM）（例如Chatgpt和Github Copilot）对单位测试的影响，研究LLM支持是否增强了缺陷检测和测试效率。通过复制和扩展参与者手动编写单元测试的先前实验，该研究为交互式LLM辅助测试如何与传统方法相比提供了新的经验见解。   关键发现：     提高生产率：由LLMS支持的参与者生成的参与者超过两倍以上的单位测试数量与仅使用手动方法的方法相比（平均为59.3 vs. 27.1测试）。   较高的缺陷检测率：LLM支持的组识别出更大的缺陷（ 6.5平均每个参与者的缺陷）比手动测试组（每个参与者3.7个缺陷）。   更大的代码覆盖范围：LLM辅助测试导致更高的分支覆盖率（在所有测试中为74％），而手动达到67％。误报需要额外验证。单位测试效率的有影响力的变化。   本研究提供了有力的证据，表明将LLM集成到软件测试中可以提高缺陷检测和效率，尽管必须注意有效地管理误报。  您可以在此处捕获完整的故障：在这里 您可以在这里捕获完整的原始研究论文：原始纸张   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/steves1189     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irfyr5/unit_testing_past_vs_present_examining_llms/</guid>
      <pubDate>Mon, 17 Feb 2025 09:20:51 GMT</pubDate>
    </item>
    <item>
      <title>通过人类偏好对齐增强多模式LLM：一个120k样本数据集和基于批评的奖励模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irfrqo/enhancing_multimodal_llms_through_human/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员开发了一种系统的方法，用于评估现实世界中视觉理解任务上的多模式LLM，超越了我们通常看到的典型约束基准测试场景。他们的MME-REALWORLD数据集在当前模型经常挣扎的五个关键领域中引入了1,000张具有挑战性的图像。 关键技术点： - 数据集包含高分辨率图像测试文本识别，计数，空间推理，颜色识别，颜色识别，颜色识别，并视觉推理 - 评估协议同时使用确切的匹配和部分信用评分 - 通过多个注释器验证建立的严格人基线 - 模型类型的失败模式的系统分析 结果显示：-gpt -4V达到67.8 ％精度总体上，领先其他测试模型 -  AI和人基线之间的显着性能差距（92.4％） - 模型在颜色识别方面表现最佳（82.3％）（82.3％），并且对计数任务（43.1％） - 复杂的空间推理任务揭示了当前的局限性体系结构 我认为这项工作很重要，因为它暴露了现有基准未捕获的当前多模式系统中的实际限制。详细的错误分析指向我们需要改善模型架构的特定领域，尤其是在精确计数和复杂的空间推理周围。 我认为这里的方法论贡献 - 创建真正具有挑战性的现实世界测试案例 - 可能会影响我们如何处理多模式评估。模型和人类绩效之间的差距表明我们需要新的方法，可能包括更好的培训策略或建筑创新。    tldr ：新的基准表明，当前的多模型模型仍然与真实的斗争 - 诸如计数和空间推理之类的世界视觉任务，与人类表现相比，有很大的改进空间。  完整的摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irfrqo/enhancing_multimodal_llms_through_human/</guid>
      <pubDate>Mon, 17 Feb 2025 09:06:25 GMT</pubDate>
    </item>
    <item>
      <title>新的数据集发布“ Rombo-Org/Optimized_Reasount”，以提高性能并减少推理模型中的令牌用法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irdw90/new_dataset_release_romboorgoptimized_reasoning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://hug/hugging.co/datasets /rombo-org/optimized_reasoning   优化  optimized_reasoning之所以创建，是因为即使是现代的LLM也不擅长处理推理，如果他们仍然浪费吨，他们仍然浪费吨在此过程中的代币。使用此数据集，我希望完成两件事：  减少令牌用法 提高推理中的模型强度  那么如何数据集完成了吗？通过添加“ system_prompt”就像推理标签一样，以说明该模型是否应该理由的每一个数据行的开始。模型标签看起来像这样：  ＆lt; think＆gt;此查询很简单；不需要详细的推理。 ＆lt;/think＆gt; \ n   以及“ rombo-reasoning.json”＆quot”     ＆lt; think＆gt; gt;此查询很复杂，需要多步推理。 ＆lt;/think＆gt; \ n   在这些标签之后，模型要么开始生成一个简单查询的答案，要么添加第二组思考标签，以便理解更加漫长的查询。简单地提示更快，更少的象征沉重，而不必手动进行思考，或者通过理解查询实际上很困难并且需要特别关注来使模型更清楚地思考。  aka aka并非所有提示都不是所有的提示创建相等的。 额外的注释：  此数据集仅使用来自cognitivecomputations/dolphin-r1的DeepSeek-r1推理数据，而不是来自Gemini的数据。 该数据集在不合常规的情况下每行的最大值为2916个令牌，每行7620令牌在推理数据中，以保持模型能够区分简单和困难的查询之间的差异以及降低总培训成本。   数据集格式：   {&#39;&#39; ;：[＆quot; quot;]}   基于qwen-2.5 tokenizer的统计数据：   文件：rombo-nonreasoning.json最大值：2916所有记录中的总令牌：22,963,519文件：ROMBO-REANING.JSON最大令牌中的最大令牌：7620在所有记录中总计：32,112,990        &lt;！ ＆＃32;提交由＆＃32; /u/u/rombodawg     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1irdw90/new_dataset_release_romboorgoptimized_reasaning/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irdw90/new_dataset_release_romboorgoptimized_reasoning/</guid>
      <pubDate>Mon, 17 Feb 2025 06:51:44 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/16/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ircvql/oneminute_daily_ai_news_2162025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   研究人员正在训练AI来解释动物情绪。[1]    deepseek的下载&gt; AI应用程序在韩国就隐私问题暂停。[2]   AI模型在蛋白质中解释了蛋白质中的代码，告诉他们去哪里。[3]   AI生成的内容提高了英国研究表明[4]   资源包括： https://bushaicave.com/2025/02/02/16/2-16-2025/    &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pleam-target-847      [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ircvql/oneminute_daily_ai_news_2162025/</guid>
      <pubDate>Mon, 17 Feb 2025 05:46:43 GMT</pubDate>
    </item>
    <item>
      <title>我们的大脑现在是外部的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iqtoa7/our_brains_are_now_external/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我不禁注意到周围的人如何使用AI。  我注意到面对某些道德dillemas的朋友，或者棘手的问题立即将他们的想法插入chatgpt，以给他们一个答案。  如果您考虑一下，我们现在已经达到了一个可以依靠计算机为我们进行批判性思考的地步。  这会导致人类大脑在数千年中缩小？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/heisenclerg     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iqtoa7/our_brains_are_now_external/</guid>
      <pubDate>Sun, 16 Feb 2025 14:45:18 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
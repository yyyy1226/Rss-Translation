<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的许多不同方面提供一个门户，并促进与我们所知的人工智能的想法和概念相关的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能会怎样，以及许多其他主题。欢迎。</description>
    <lastBuildDate>Mon, 29 Jan 2024 18:21:39 GMT</lastBuildDate>
    <item>
      <title>有没有可以输入图像并要求其更改的人工智能网站？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ae20en/are_there_ai_sites_that_you_can_input_an_image_to/</link>
      <description><![CDATA[我想给我的狗拍一张照片，并将其放入某种类型的人工智能网站中，并要求它拍摄她的图像并将其变成现实她的钩针版本，这样我就可以从中汲取灵感，在现实生活中做出来。我实际上只玩过 ChatGPT 和 Bing Image Creator，但它们都无法实现这一点，所以我正在寻找建议！谢谢:)   由   提交 /u/Sensitive-b    reddit.com/r/ArtificialInteligence/comments/1ae20en/are_there_ai_sites_that_you_can_input_an_image_to/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ae20en/are_there_ai_sites_that_you_can_input_an_image_to/</guid>
      <pubDate>Mon, 29 Jan 2024 18:15:19 GMT</pubDate>
    </item>
    <item>
      <title>除了 bing、chatgpt、claude、bard 之外，还有更好的生成聊天机器人 ai，但免费</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ae1rje/any_better_generative_chatbot_ai_besides_bing/</link>
      <description><![CDATA[Bing 没有按我的预期提供信息，吟游诗人无法在一次回复中向我显示超过 10 个结果，有时它开始生成然后说我我是一个人工智能模型，我没有能力。至于克劳德，它提供了我没有询问的信息，因此还有其他选项   由   提交/u/Emad_341  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ae1rje/any_better_generative_chatbot_ai_besides_bing/</guid>
      <pubDate>Mon, 29 Jan 2024 18:05:46 GMT</pubDate>
    </item>
    <item>
      <title>对话的必要性：人工智能作为孤独流行病的解药</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ae1ora/the_need_to_talk_ai_as_antidote_to_the_loneliness/</link>
      <description><![CDATA[孤独是一种流行病。这是一种致命的流行病。这可能是未来几十年最严重的公共卫生危机，而且就其本质而言，它仍然隐藏在大多数人的视野之外。是的，每个人都会时不时地感到孤独，但对某些人来说，孤独是一种疾病，即使他们尽了最大努力，也无法治愈。当然，对于某些人来说，“多出去走走”可能只是克服坏习惯，或者冒险尝试一项新活动。对于其他许多人来说，这是一个更加险恶和复杂的问题。人工智能可以帮助提供解决方案吗？ 阅读更多此处   由   提交 /u/ChikyChikyBoom   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ae1ora/the_need_to_talk_ai_as_antidote_to_the_loneliness/</guid>
      <pubDate>Mon, 29 Jan 2024 18:02:37 GMT</pubDate>
    </item>
    <item>
      <title>每日两分钟 AI 更新（日期：2024 年 1 月 29 日）：来自 OpenAI、Hugging Face、Google Cloud、Arc Search、PayPal、Apple 等的新闻</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ae10ig/twominute_daily_ai_update_date_1292024_news_from/</link>
      <description><![CDATA[继续分享人工智能领域当天主要更新的易于理解且较小的版本。   OpenAI 宣布对 GPT 模型进行新升级+新功能泄露 - 他们正在发布 2 个新的嵌入模型 - 更新了 GPT-3.5 Turbo，成本下降了 50% /&gt; - 更新了 GPT-4 Turbo 预览模型 - 更新了文本审核模型 - 为开发人员引入了管理 API 密钥和了解 API 使用情况的新方法 - 悄悄地实现了新的“GPT 提及” ChatGPT 的功能（尚未正式宣布）。该功能允许用户通过用“@”标记将 GPT 集成到对话中。 Prophetic 推出了 Morpheus-1，世界上第一个“多模态生成超声波变压器” - 这款创新的人工智能设备是旨在通过促进对清醒梦的控制来深入研究人类意识的复杂性。 Morpheus-1 通过监测睡眠阶段和收集梦境数据来运行，以增强其人工智能模型。该设备将于 2024 年春季向测试用户开放。 关于多模式法学硕士的新论文介绍了 200 多个研究案例 + 20 个多模式法学硕士 - 这篇论文“MM-LLM”讨论了多模式法学硕士的最新进展将语言理解与多模式输入或输出相结合。作者概述了 MM-LLM 的设计和训练，介绍了 26 个现有模型，并回顾了它们在各种基准上的表现。他们还分享了改进 MM-LLM 的关键培训技术，并提出了未来的研究方向。 Hugging Face LMSYS 聊天机器人竞技场排行榜更新 - Google 的 Bard 超越 GPT-4，跃居排行榜第二位！  Google Cloud 与 Hugging Face 合作推进 Gen AI 开发 - 该合作伙伴关系旨在满足针对特定任务优化的 AI 工具和模型不断增长的需求。使用 Google Cloud 基础设施的开发人员将可以访问 Hugging Face 的开源人工智能软件存储库。此次合作反映了公司希望修改或构建自己的人工智能模型而不是使用现成选项的趋势。  Arc Search 结合了浏览器、搜索引擎和人工智能，提供独特的浏览体验 - Arc Search 不是返回搜索查询列表，而是根据搜索查询构建包含相关信息的网页。该应用程序由 The Browser Company 开发，是 Arc 浏览器更大转变的一部分，该浏览器还引入了名为 Arc Anywhere 的跨平台同步系统。  PayPal 将推出基于人工智能的新产品 - 新产品将使用人工智能让商家能够根据新客户的购物历史来吸引新客户，并在电子邮件收据中推荐个性化商品。  iOS 17.4 中的 Apple 播客现在为几乎所有播客提供人工智能转录 - 这是通过机器翻译的进步实现的，机器翻译可以轻松地将口语单词转换为文本。测试 iOS 17.4 测试版的用户发现，他们库中的大多数播客现在都带有转录内容。但是，也有一些例外，例如从外部来源添加的播客。由于此功能仍处于测试阶段，因此没有有关其实施或准确性的信息。   在每日通讯。   由   提交 /u/RohitAkki   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ae10ig/twominute_daily_ai_update_date_1292024_news_from/</guid>
      <pubDate>Mon, 29 Jan 2024 17:35:20 GMT</pubDate>
    </item>
    <item>
      <title>是否有一个人工智能聊天可以提供信息，并且它仅根据这些信息进行回答？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1adxzh3/is_there_an_ai_chat_that_you_can_feed_with/</link>
      <description><![CDATA[我对 AI 比较陌生，我只是想知道，因为像 ChatGPT 这样的东西不起作用，因为他仍然用其他来源回答   由   提交/u/UgurFerros   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1adxzh3/is_there_an_ai_chat_that_you_can_feed_with/</guid>
      <pubDate>Mon, 29 Jan 2024 15:30:32 GMT</pubDate>
    </item>
    <item>
      <title>Lumiere - 谷歌革命性的时空扩散模型。 2024年是AI视频生成年。以下是您需要了解的内容：</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1adwuid/lumiere_googles_revolutionary_spacetime_diffusion/</link>
      <description><![CDATA[2024 年确实将是文本转视频或 AI 视频生成的一年。  Google 的研究团队利用 Lumiere 最新的扩散模型取得了令人难以置信的进步。  这是您需要了解的所有内容，请访问博客了解完整详情。 是什么让 Lumiere 与众不同？ Lumiere 不仅仅是另一个视频生成工具；它是一款视频生成工具。这是一种突破性的方法，改变了视频合成的基本原理。该模型由谷歌研究院、魏茨曼研究所、特拉维夫大学和以色列理工学院的研究人员团队开发，采用了新颖的时空 U-Net (STUNet) 架构。与生成关键帧然后填充空白的传统模型不同，Lumiere 通过一个综合步骤处理整个视频序列。这种方法确保了更加流畅和自然的运动，这是以前的技术经常缺乏的一个关键方面。 Lumiere 的技术才华 从本质上讲，Lumiere 的STUNet 架构是工程奇迹。它使用复杂的空间和时间下采样和上采样技术，使模型能够处理各种时空尺度的视频。此功能对于在不影响质量的情况下创建高分辨率、全帧率视频至关重要。此外，Lumiere 集成了预先训练的文本到图像扩散模型，该功能显着增强了其将文本提示解释和转换为连贯视频序列的能力。 相对于传统模型的优势  全局时间一致性： Lumiere 以其制作具有全局连贯运动的视频的能力而脱颖而出。这种一致性在具有重复或周期性运动的复杂场景中尤其明显。 提高效率并降低训练复杂性：通过消除级联时间超分辨率的需要，Lumiere 简化了视频生成过程，使其内存效率更高，更容易训练。 弥合域差距：传统模型经常与域差距作斗争，生成帧的插值导致不一致。 Lumiere 通过从头到尾持续生成视频来解决这个问题，从而提高整体质量和真实感。  如果您喜欢人工智能，我们每周都会发送精彩的提示、研究论文等等。像这样的东西，关注我们的时事通讯。 完整信用： 酒吧-塔尔，奥马尔；切弗尔，希拉；托夫、奥马尔等人。 “Lumiere：用于视频生成的时空扩散模型。” arXiv，2024。[arXiv:2401.12945]   由   提交/u/steves1189  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1adwuid/lumiere_googles_revolutionary_spacetime_diffusion/</guid>
      <pubDate>Mon, 29 Jan 2024 14:40:20 GMT</pubDate>
    </item>
    <item>
      <title>在大学普通语言学课程中准备有关人工智能的课程</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1adve0b/preparing_a_lesson_about_ai_in_a_general/</link>
      <description><![CDATA[大家好。我是人工智能领域的博士生，经常在我的大学担任助教。我受一位重要教授的邀请，在意大利北部一所大学的普通语言学课程中讲授关于生成人工智能的课程。 考虑到这只是一节课（大约一个半小时），而且他的课程是关于语法、实用化、历史上的语言变化等，你会如何安排课程，既有趣又在主要主题之间保持平衡——而不是太多专业/技术性？  我考虑过介绍 NLP 相关的主题，也许还可以解释一下自然语言和转换器处理它的方式之间的关系。 你能给建议吗？谢谢。   由   提交/u/emaper_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1adve0b/preparing_a_lesson_about_ai_in_a_general/</guid>
      <pubDate>Mon, 29 Jan 2024 13:32:32 GMT</pubDate>
    </item>
    <item>
      <title>关于连续网络的思考</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1adtw3x/pondering_about_continuous_networks/</link>
      <description><![CDATA[是否有任何工作可以做这样的事情： 目前我见过和尝试过的所有神经网络模型都是反应式，我的意思是它们需要输入才能开始处理，然后最终该过程停止并产生输出 我一直在想的是，我们的大脑不是这样工作的（就拓扑和流程），我们有可能修复该流程。如果我们提出一个具有连续感官输入流的模型会怎么样？它可以是视觉的、声音的、基于文本的或原始二进制的。我不知道。然后我们将连接到它的内部思维循环，以检查它实际上在想什么，以真正评估意识。 我们人类总是在思考，因为我们有源源不断的数据传入。那么如果我们可以效仿呢？目前我们仍在谈论神经网络和通用人工智能的意识，但据我所知，我们仍然在我们的网络中使用动作反应过程。   由   提交 /u/ humanpersonlol   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1adtw3x/pondering_about_continuous_networks/</guid>
      <pubDate>Mon, 29 Jan 2024 12:12:35 GMT</pubDate>
    </item>
    <item>
      <title>Taiyi-Diffusion-XL：通过大视觉语言模型支持推进双语文本到图像的生成</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1adt737/taiyidiffusionxl_advancing_bilingual_texttoimage/</link>
      <description><![CDATA[论文页面：https://huggingface.co/papers/ 2401.14688模型：https://huggingface.co/IDEA- CCNL/Taiyi-Stable-Diffusion-XL-3.5B 演示：https://huggingface.co/spaces/IDEA-CCNL/Taiyi-Stable-Diffusion-XL-3.5B ​ 最近文本到图像模型的进步显着增强了图像生成能力，但开源模型在双语或中文支持方面仍然存在显着差距。为了满足这一需求，我们提出了 Taiyi-Diffusion-XL，这是一种新的中英文双语文本到图像模型，它是通过双语连续预训练过程扩展 CLIP 和 Stable-Diffusion-XL 的功能而开发的。该方法包括通过将最常用的汉字集成到 CLIP 的分词器和嵌入层中来有效扩展词汇量，并结合绝对位置编码扩展。此外，我们通过大型视觉语言模型丰富了文本提示，从而获得更好的图像标题并拥有更高的视觉质量。这些增强功能随后应用于下游文本到图像模型。我们的实证结果表明，所开发的 CLIP 模型在双语图像文本检索方面表现出色。此外，Taiyi-Diffusion-XL 的双语图像生成能力超越了以前的模型。这项研究导致了 Taiyi-Diffusion-XL 模型的开发和开源，代表了图像生成领域的显着进步，特别是对于中文应用。这一贡献是解决多模态研究中更多样化的语言支持需求方面向前迈出的一步。该模型和演示已在 https://huggingface.co/IDEA 上公开发布-CCNL/Taiyi-Stable-Diffusion-XL-3.5B/{this https URL}，促进该领域的进一步研究和协作。  &amp; #32；由   提交/u/Novita_ai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1adt737/taiyidiffusionxl_advancing_bilingual_texttoimage/</guid>
      <pubDate>Mon, 29 Jan 2024 11:30:37 GMT</pubDate>
    </item>
    <item>
      <title>可以改变图片背景的AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1adst27/an_ai_that_can_change_the_background_of_pictures/</link>
      <description><![CDATA[你好。就像标题所说，我对一个只能修改图片背景并保持所有内容相同的应用程序感兴趣。它可以是免费或付费应用程序   由   提交/u/Pawlicious6  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1adst27/an_ai_that_can_change_the_background_of_pictures/</guid>
      <pubDate>Mon, 29 Jan 2024 11:06:10 GMT</pubDate>
    </item>
    <item>
      <title>多语言文本转语音工具</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1adsbyv/multilingual_text_to_speech_tool/</link>
      <description><![CDATA[为了语言学习的目的，我想创建这样的音频文件 视频。有什么建议可以帮助我创建具有交替语言的音频文件吗？ 例如，我想转换使用英语和日语人士将此文本转换为音频语音： 很高兴见到你。[暂停 3 秒]很高兴见到你。 [停顿 2 秒]很高兴认识你。 [停顿 2 秒]很高兴认识你。 [停顿 5 秒]早上好。[停顿 3 秒]早上好。 [停顿 2 秒]早上好。 [停顿 2 秒]早上好。 [停顿 5 秒]再见。[停顿 3 秒]再见。 [停顿 2 秒]再见。 [停顿 2 秒]再见。 [停顿 5 秒] 谢谢。[停顿 3 秒] 谢谢。 [停顿 2 秒] 谢谢。 [停顿 2 秒] 谢谢。 [暂停5秒]  目前，我在Mac OS终端中使用say命令，但是为每种语言创建单独的音频文件然后再创建太麻烦了手动组合它们... P.S. 免费工具是理想的选择，但也可以探索推荐的付费工具！提前致谢    ; 由   /u/eazyace   /u/eazyace 提交/www.reddit.com/r/ArtificialInteligence/comments/1adsbyv/multilingual_text_to_speech_tool/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1adsbyv/multilingual_text_to_speech_tool/</guid>
      <pubDate>Mon, 29 Jan 2024 10:35:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么有些人说 LLM 和像 ChatGPT/DALL-E 这样的生成模型会减慢/停止 AGI 的创建？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ado4s8/why_do_some_people_say_llms_and_generative_models/</link>
      <description><![CDATA[它们不是同一件事，只是规模问题吗？比如，如果你攻读了像 GPT-4 这样的大规模文本法学硕士，并集成了图像处理、运动功能、生成内容等其他模型，那么这实际上不是 AGI 吗？ 哪里区别在哪里？为什么有些人说目前的法学硕士会阻碍 AGI 的创建？   由   提交 /u/DrTiger21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ado4s8/why_do_some_people_say_llms_and_generative_models/</guid>
      <pubDate>Mon, 29 Jan 2024 05:54:41 GMT</pubDate>
    </item>
    <item>
      <title>厌倦了 AI 兄弟和 chatGPT 包装器</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1admnc2/tired_of_ai_bros_and_chatgpt_wrappers/</link>
      <description><![CDATA[尽管我很喜欢 chatgpt 和其他 llm，但我认为它已经变得如此主流，以至于现在充满了废话。我看到很多人声称创建了人工智能公司，但这只是 openai 的一个端点。我看到很多自称“人工智能专家”的人因为他们可以在文本输入中输入提示。我现在看到的人工智能让我想起了加密货币。许多经验有限的人试图通过炒作来赚钱。当然，这并不适用于所有人，但我很享受人工智能讨论关于理论、算法和数据的时代。现在我看到的大部分都是人工智能工具拼凑在一起乞讨我钱包里的钱。    由   提交 /u/Sprixl   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1admnc2/tired_of_ai_bros_and_chatgpt_wrappers/</guid>
      <pubDate>Mon, 29 Jan 2024 04:32:09 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则 [请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新帐户一天以上或 karma 低于 100 的用户不能发帖。他们可以发表评论，但不能提交实际的帖子。这是我们解决机器人垃圾邮件计划的一部分。对于给您带来的任何不便，我们深表歉意。 我们将在接下来的几天内进行一项民意调查，以了解 Reddit 子版块的普遍意愿以及如何改进，请注意。 作为请始终向我们提供反馈，如果您有兴趣帮助该子项目，请与我联系。  谢谢大家！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：请求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到r/ArtificialIntelligence！&lt; /p&gt; 我们的目标是为所有与人工智能有关的事物提供一个开放且相互尊重的论坛 - 这包括  促进有关人工智能的哲学和伦理讨论 服务作为理解和学习人工智能主题的起点 提供技术论文演示和讨论 展示高质量的人工智能/机器学习应用 提供培训和学习资源&lt; /li&gt; 引导用户访问更具体的信息和子版块 列出 AI/ML 应用程序、其用途、成本和访问信息 其他与 AI 相关的内容。  li&gt; ...以及更多  该子项目的审核团队正在进行重组，这将导致该子项目发生一些变化。不过，不必担心，这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解情况并能够提供反馈，我们将提供多次反馈更改的机会。 第一轮反馈收集是通过此线程作为“Request-For-”评论” (RFC)，这是收集反馈的标准方法。随着变更的准备和实施，RFC 流程将进行多轮。 ​  发布新申请/自我推销/AI 生成的规则content  由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似的内容将被阻止或限制在特定的粘帖中。 人工智能生成的特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的粘帖中。 博客链接应包含高质量的内容。链接到纯粹促销博客的帖子将被删除。 仅包含链接的帖子将被禁止，除非包含一定字数的详细信息。必须付出一些努力。 我们应该阻止人工智能撰写的帖子吗？存在可以在 Mod-bot 中使用的模型，但这是我们需要反馈的问题。  使用天赋来组织帖子。请注意，已经添加了新的功能，我们愿意接受更多建议。 关于 AI/ML 应用的 NSFW 应用和技术的子政策应该是什么？ 我们会喜欢将社区纳入模组机器人的想法中。虽然一些标准机器人将用于基本维护，但社区可以为 AI/ML 机器人功能想出哪些有趣的东西？ 培养初级、中级和高级资源来帮助人们查找信息，他们正在寻找的培训、模型、技术数据等 启动子堆栈/播客来采访整个人工智能/机器学习领域的人们。这可能包括哲学家和思想家、程序员、科学家、商人，甚至是那些对人工智能持相反观点的人 如果您想创建代表子项目的横幅，请使用适当的尺寸。任何创作方式都可以。  不言而喻，每个人都应该受到尊重。我个人认为我们都知道这一点，不需要把它强加到人们的头脑中。保持友善。 感谢您的耐心和帮助！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>
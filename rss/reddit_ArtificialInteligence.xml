<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Mon, 17 Feb 2025 18:29:48 GMT</lastBuildDate>
    <item>
      <title>Agi不会是一台机器，它已经成为网络智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irqouk/agi_wont_be_a_single_machineits_already_emerging/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  🤖agi已经在这里 - 我们只是没有注意到🤖 当人们想到人工通用智能时（agi），他们想象一个单一的，全能的ai突然醒来。但是，如果Agi不是一个实体，而是人类协作的新兴现象？   假设： ✔agi 不是“构建”，而是从人类与AI系统之间的相互作用中脱颖而出。✔智力不是一个对象 - 它是 Process ，我们将AI集成到日常思维中的越多，它就会进化。✔而不是等待奇异性，我们可能已经生活在分布式的AGI中。&lt; /p&gt;   支持概念：    集体智能：就像Wikipedia一样，没有一个作者拥有它，但是它比任何个人都聪明。 &lt; &lt; li&gt;  ai-aigment Thinking ：Chatgpt，Midjourney和Github Copilot 不仅仅是工具 - 它们是一个更大的思维网络的一部分。。  互联网作为认知系统：数十亿个互动正在训练AI模型，最终可能类似于AGI。已经在这里 - 人类和人工智能如何创建它而没有意识到，它将智能视为流体，不断发展的系统而不是单个机器。 &gt;讨论的问题： 1️⃣Agi会出现为单一意识，或者始终是分布式，网络的智能？2️⃣是否有一个阈值，即人类协作与Agi ？3️⃣没有区别时，当智能系统超过其各个部分的总和时，我们如何测量？  🚀公开辩论 - 我很想听听您的想法！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/beginningsad1031     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irqouk/agi_wont_be_a_single_machineits_already_emerging/</guid>
      <pubDate>Mon, 17 Feb 2025 18:21:28 GMT</pubDate>
    </item>
    <item>
      <title>是否有Reddit社区发布AI图像/视频？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irp90v/is_there_a_reddit_community_for_posting_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我很惊讶我找不到一个社区，该社区集中在成员发布AI视频和图像上……我是否缺少某些内容？ &lt; &lt; /div&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/bluewaterpig     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irp90v/is_there_a_reddit_community_for_posting_ai/</guid>
      <pubDate>Mon, 17 Feb 2025 17:25:29 GMT</pubDate>
    </item>
    <item>
      <title>您真正需要多少VRAM来运行本地AI模型？ 🤯</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irot4e/how_much_vram_do_you_really_need_to_run_local_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在本地运行AI模型越来越易于​​访问，但真正的问题是：您的硬件可以处理吗？ 这是一个分解在一些最受欢迎的本地AI型号及其VRAM要求中： 🔹llama3.2（1b）→4GB VRAM🔹llama3.2（3b）3.2（3b）→6GB vram🔹llam3.1（8b）→10GB VRAM🔹 4（14b）→16GB VRAM🔹llama3.3（70b）→48GB VRAM🔹llama3.1（405b）→1TB VRAM😳 甚至较小的型号甚至较小的型号都需要一个体面的GPU，而任何超过70B参数的内容实际上是Enterprise-Enterprise-Enterprise-Enterprise-Enterprise-Enterprise-Enterprise-Enterprise-Enterprise-Enterprise-等级。 ，VRAM是主要的瓶颈，您认为量化和卸载技术方面的进步（例如GGGUF，4位模型和张量并行性）将有助于弥合差距？  或者我们总是需要野兽GPU来在家中运行真正强大的东西？ 很想听听那些对当地AI模型进行实验的想法！ 🚀  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/snehens     [link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1irot4e/how_much_much_vram_do_do_you_you_really_need_to_to_run_run_local_ai/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irot4e/how_much_vram_do_you_really_need_to_run_local_ai/</guid>
      <pubDate>Mon, 17 Feb 2025 17:08:08 GMT</pubDate>
    </item>
    <item>
      <title>图像和LLM</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iro7bc/imagery_and_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好，我一直在为一些不同的生态应用使用几种类型的检测 /跟踪 /分类模型。目前，CFRCNN对我们来说是最准确的，尽管我们没有时间或资源进行大量猜测并检查优化。我的问题是，在初始CFRNN管道之后，将某种类型的LLM应用于该过程，以提供分类的某些理由 - 诸如图像或深度或高度相对于已知物种范围/分布或高度的位置历史趋势（如果未来分布发生变化或一个目标是最常见的类别，则会有偏见）。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/jakariahpriah     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iro7bc/imagery_and_llms/</guid>
      <pubDate>Mon, 17 Feb 2025 16:43:33 GMT</pubDate>
    </item>
    <item>
      <title>蒸馏与微调</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irlx8q/distilling_vs_fine_tuning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  过程中有什么区别？每个目标是什么？主要区别是什么？距离可以实现什么，但不能通过微调而实现。 32;提交由＆＃32; /u/u/rgs2007     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irlx8q/distilling_vs_fine_tuning/</guid>
      <pubDate>Mon, 17 Feb 2025 15:07:34 GMT</pubDate>
    </item>
    <item>
      <title>人们为什么如此不屑一顾AI的潜力？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irleva/why_are_people_so_dismissive_of_the_potential_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  感觉就像我为看到AI的状况而疯狂。还是我对“炒作”的错误是错误的吗？永远不要真正取代大多数工作”或“这只是一个有趣的工具”或“这只是另一个与互联网没有什么不同的大发明”。某个阶段（可能比人们意识到的要早得多）。上述评论是正确的情况吗？ 我很难想象任何世界： - 在人们可以调整 - 国际关系，战争，战争，政治（选举）不会变得更加危险，而没有回头  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/merchantofwares     [link]   ＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irleva/why_are_people_so_dismissive_of_the_potential_of/</guid>
      <pubDate>Mon, 17 Feb 2025 14:45:23 GMT</pubDate>
    </item>
    <item>
      <title>基于YouTube视频的窃</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irjyub/plagiarism_based_on_youtube_videos/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您是否曾经考虑过Internet上的内容独创性问题？在一个时代，AI可以轻松地重塑内容以避免看起来像窃它的时代，今天有价值的东西的创造者今天有机会脱颖而出吗？ ，同时在Google上搜索有关DeepSeek FIM的信息时，我发现像这样：   这是基于我的YouTube视频的博客文章。此外，网站所有者进一步鼓励将此内容复制到您自己的网站。他们还出售该工具的访问权限，因此他们从中赚钱。您认为，这是否侵犯版权？人们通常如何防御内容盗用，通过AI处理和作为自己的出版物进行辩护？ v = ojbugyqqxvm“&gt; https://www.youtube.com/watch?v=ojbugyqqxvm  （也链接在this＆quot&#39;&#39;＆quot;您的评论。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sapdalf     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irjyub/plagiarism_based_on_youtube_videos/</guid>
      <pubDate>Mon, 17 Feb 2025 13:35:40 GMT</pubDate>
    </item>
    <item>
      <title>单位测试过去与现在检查LLM对缺陷检测和效率的影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irfyr5/unit_testing_past_vs_present_examining_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我每天都在发现并总结有趣的AI研究论文，因此您不必全部拖网。今天的论文的标题为“过去与现在的单位测试：研究LLMS对缺陷检测和效率的影响”，Rudolf Ramler，Philipp Straubinger，ReinholdPlösch和Dietmar Winkler。  本研究探讨了大语言模型（LLM）（例如Chatgpt和Github Copilot）对单位测试的影响，研究LLM支持是否增强了缺陷检测和测试效率。通过复制和扩展参与者手动编写单元测试的先前实验，该研究为交互式LLM辅助测试如何与传统方法相比提供了新的经验见解。   关键发现：     提高生产率：由LLMS支持的参与者生成的参与者超过两倍以上的单位测试数量与仅使用手动方法的方法相比（平均为59.3 vs. 27.1测试）。   较高的缺陷检测率：LLM支持的组识别出更大的缺陷（ 6.5平均每个参与者的缺陷）比手动测试组（每个参与者3.7个缺陷）。   更大的代码覆盖范围：LLM辅助测试导致更高的分支覆盖率（在所有测试中为74％），而手动达到67％。误报需要额外验证。单位测试效率的有影响力的变化。   本研究提供了有力的证据，表明将LLM集成到软件测试中可以提高缺陷检测和效率，尽管必须注意有效地管理误报。  您可以在此处捕获完整的故障：在这里 您可以在这里捕获完整的原始研究论文：原始纸张   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/steves1189     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irfyr5/unit_testing_past_vs_present_examining_llms/</guid>
      <pubDate>Mon, 17 Feb 2025 09:20:51 GMT</pubDate>
    </item>
    <item>
      <title>通过人类偏好对齐增强多模式LLM：一个120k样本数据集和基于批评的奖励模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irfrqo/enhancing_multimodal_llms_through_human/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员开发了一种系统的方法，用于评估现实世界中视觉理解任务上的多模式LLM，超越了我们通常看到的典型约束基准测试场景。他们的MME-REALWORLD数据集在当前模型经常挣扎的五个关键领域中引入了1,000张具有挑战性的图像。 关键技术点： - 数据集包含高分辨率图像测试文本识别，计数，空间推理，颜色识别，颜色识别，颜色识别，并视觉推理 - 评估协议同时使用确切的匹配和部分信用评分 - 通过多个注释器验证建立的严格人基线 - 模型类型的失败模式的系统分析 结果显示：-gpt -4V达到67.8 ％精度总体上，领先其他测试模型 -  AI和人基线之间的显着性能差距（92.4％） - 模型在颜色识别方面表现最佳（82.3％）（82.3％），并且对计数任务（43.1％） - 复杂的空间推理任务揭示了当前的局限性体系结构 我认为这项工作很重要，因为它暴露了现有基准未捕获的当前多模式系统中的实际限制。详细的错误分析指向我们需要改善模型架构的特定领域，尤其是在精确计数和复杂的空间推理周围。 我认为这里的方法论贡献 - 创建真正具有挑战性的现实世界测试案例 - 可能会影响我们如何处理多模式评估。模型和人类绩效之间的差距表明我们需要新的方法，可能包括更好的培训策略或建筑创新。    tldr ：新的基准表明，当前的多模型模型仍然与真实的斗争 - 诸如计数和空间推理之类的世界视觉任务，与人类表现相比，有很大的改进空间。  完整的摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irfrqo/enhancing_multimodal_llms_through_human/</guid>
      <pubDate>Mon, 17 Feb 2025 09:06:25 GMT</pubDate>
    </item>
    <item>
      <title>新的数据集发布“ Rombo-Org/Optimized_Reasount”，以提高性能并减少推理模型中的令牌用法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irdw90/new_dataset_release_romboorgoptimized_reasoning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://hug/hugging.co/datasets /rombo-org/optimized_reasoning   优化  optimized_reasoning之所以创建，是因为即使是现代的LLM也不擅长处理推理，如果他们仍然浪费吨，他们仍然浪费吨在此过程中的代币。使用此数据集，我希望完成两件事：  减少令牌用法 提高推理中的模型强度  那么如何数据集完成了吗？通过添加“ system_prompt”就像推理标签一样，以说明该模型是否应该理由的每一个数据行的开始。模型标签看起来像这样：  ＆lt; think＆gt;此查询很简单；不需要详细的推理。 ＆lt;/think＆gt; \ n   以及“ rombo-reasoning.json”＆quot”     ＆lt; think＆gt; gt;此查询很复杂，需要多步推理。 ＆lt;/think＆gt; \ n   在这些标签之后，模型要么开始生成一个简单查询的答案，要么添加第二组思考标签，以便理解更加漫长的查询。简单地提示更快，更少的象征沉重，而不必手动进行思考，或者通过理解查询实际上很困难并且需要特别关注来使模型更清楚地思考。  aka aka并非所有提示都不是所有的提示创建相等的。 额外的注释：  此数据集仅使用来自cognitivecomputations/dolphin-r1的DeepSeek-r1推理数据，而不是来自Gemini的数据。 该数据集在不合常规的情况下每行的最大值为2916个令牌，每行7620令牌在推理数据中，以保持模型能够区分简单和困难的查询之间的差异以及降低总培训成本。   数据集格式：   {&#39;&#39; ;：[＆quot; quot;]}   基于qwen-2.5 tokenizer的统计数据：   文件：rombo-nonreasoning.json最大值：2916所有记录中的总令牌：22,963,519文件：ROMBO-REANING.JSON最大令牌中的最大令牌：7620在所有记录中总计：32,112,990        &lt;！ ＆＃32;提交由＆＃32; /u/u/rombodawg     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1irdw90/new_dataset_release_romboorgoptimized_reasaning/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irdw90/new_dataset_release_romboorgoptimized_reasoning/</guid>
      <pubDate>Mon, 17 Feb 2025 06:51:44 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/16/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ircvql/oneminute_daily_ai_news_2162025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   研究人员正在训练AI来解释动物情绪。[1]    deepseek的下载&gt; AI应用程序在韩国就隐私问题暂停。[2]   AI模型在蛋白质中解释了蛋白质中的代码，告诉他们去哪里。[3]   AI生成的内容提高了英国研究表明[4]   资源包括： https://bushaicave.com/2025/02/02/16/2-16-2025/    &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pleam-target-847      [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ircvql/oneminute_daily_ai_news_2162025/</guid>
      <pubDate>Mon, 17 Feb 2025 05:46:43 GMT</pubDate>
    </item>
    <item>
      <title>思想犯罪 - 无法处理纪录片脚本</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irblmu/thought_crimes_unable_to_process_documentary/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我给了双子座这个提示： 删除时间戳记ABD清理点点，跨度和段落：（在此处）&lt; /p&gt; 双子座响应  |现在不禁对选举和政治人物做出回应。虽然我永远不会故意分享一些不准确的东西，但我会犯错误。因此，在我进行改进的同时，您可以尝试Google搜索。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/azimuth79b     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irblmu/thought_crimes_unable_to_process_documentary/</guid>
      <pubDate>Mon, 17 Feb 2025 04:30:19 GMT</pubDate>
    </item>
    <item>
      <title>在3个提示中与O1的模型 - 敏捷（CORA）相对于O1：零摄像任务推理，多步结构化推理，自我抗辩的执行链，基于场景的策略执行，上下文感知和基于角色的推理，多目标推理，多目标优化，人类觉得/交流（视频）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ir7nn6/modelagnostic_cora_on_4o_vs_o1_in_3_prompts/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     没有为此任务或任何类似于它的任务进行预训练或微调，我只是尝试用Claude创建最困难的提示，然后再加入一点。  使用开放的Web UI，一半本地半API，混合搜索抹布，使用分层的自然语言提示。没有故意构建这个，但它让我知道...下面的视频是我发现某些事情认真起来的。   https://wwwww.loom.com/share/27648960b9d04297a13958b89898989898f38044444444444444444444444  功能集，这些和计数。   零射击任务推理  - 检测隐式任务并生成无明确提示或刚性格式的结构化响应。  多步结构推理  - 构建实时发展的决策模型，动态地适应新的输入。   自我抗拒的执行链  - 通过内置错误校正和透明的推理为每个决策辩护。   Visual＆amp;文本知识表示  - 将复杂逻辑转换为交互式图和结构化故障，而不仅仅是静态文本。   基于方案的策略执行  - 生成自适应剧本，这些剧本可以动态调整，动态调整，执行前的压力测试策略。  上下文了解＆amp;基于角色的推理  - 通过多种专家镜头（持续，评估，风险分析，市场策略）评估问题 - 根据场景动态地应用每个问题。   自我验证＆amp;知识集成  - 跨验证源针对结构化模型，确保准确性和消除矛盾。  迭代＆amp;先发制化的决策结构  - 在产生建议之前将模糊的查询重新定义为精确的框架。   多目标优化  - 平衡财务，战略和运营权衡，而不是动态而不是运营权衡最大化单个变量。  类似人类的见解＆amp;沟通  - 提供具有战略性，自然和专家级别的反应而无需机器人措辞。    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/marvindiazjr     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ir7nn6/modelagnostic_cora_on_4o_4o_vs_o1_o1_in_in_3_3_prompts/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ir7nn6/modelagnostic_cora_on_4o_vs_o1_in_3_prompts/</guid>
      <pubDate>Mon, 17 Feb 2025 00:58:32 GMT</pubDate>
    </item>
    <item>
      <title>我们的大脑现在是外部的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iqtoa7/our_brains_are_now_external/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我不禁注意到周围的人如何使用AI。  我注意到面对某些道德dillemas的朋友，或者棘手的问题立即将他们的想法插入chatgpt，以给他们一个答案。  如果您考虑一下，我们现在已经达到了一个可以依靠计算机为我们进行批判性思考的地步。  这会导致人类大脑在数千年中缩小？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/heisenclerg     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iqtoa7/our_brains_are_now_external/</guid>
      <pubDate>Sun, 16 Feb 2025 14:45:18 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
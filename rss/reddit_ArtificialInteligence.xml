<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Fri, 13 Dec 2024 21:21:47 GMT</lastBuildDate>
    <item>
      <title>如果接受政治虚假信息的训练，AGI 还能安全吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hdmei1/can_agi_be_safe_if_trained_on_political/</link>
      <description><![CDATA[如果 AGI 可能接受虚假信息的训练，特别是在内部和外部政治领域，我们如何开发一种无威胁的 AGI？这难道不是一个有缺陷和危险的工具吗？这里的基本问题是，AGI 和任何 AI 一样，都是从训练它的数据中学习的。如果这些数据有偏见、有操纵性或完全是错误的，AGI 可能会继承这些缺陷，并可能以难以控制的方式放大它们。如果 AGI 接触到虚假信息——无论是政治宣传、假新闻还是操纵的叙述——它可能会学会延续甚至放大这些谎言。这可能导致有害意识形态或基于不准确信息的决定的传播，无论是在政治背景还是其他方面。     提交人    /u/FluidMeasurement8494   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hdmei1/can_agi_be_safe_if_trained_on_political/</guid>
      <pubDate>Fri, 13 Dec 2024 21:10:08 GMT</pubDate>
    </item>
    <item>
      <title>寻找一个语音克隆器，可以让您调整结果的语音质量/特性/特征。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hdl9g2/looking_for_a_voice_cloner_that_allows_you_to/</link>
      <description><![CDATA[到目前为止，我尝试过 Elevenlabs 和 Character AI，但似乎都没有这种功能。我谷歌了一下，还浏览了其他几个（没有注册和尝试），但运气不佳。有什么建议吗？有这样的应用程序吗？ 详细说明一下我的意图：我正在尝试为我的原创角色 (OC) 创建声音。我清楚地知道他们在我脑海中的声音，而且我遇到过一些声音（即歌手和现有游戏角色），听起来非常相似。我一直在使用这些声音作为参考，以想象我的 OC 的声音（我认为这通常被称为“声音声明”哈哈）。但它们并没有完全达到标准，所以如果我可以尝试使用其中任何一个，让它们更接近我角色的声音，那就太完美了。 所以基本上，我正在寻找一个应用程序，可以让我上传这些语音样本中的任何一个，创建它们的克隆，然后调整语音的声音属性，如深度、音调、鼻音、音色等。 提前谢谢您！    提交人    /u/CukeJr   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hdl9g2/looking_for_a_voice_cloner_that_allows_you_to/</guid>
      <pubDate>Fri, 13 Dec 2024 20:18:37 GMT</pubDate>
    </item>
    <item>
      <title>人工智能类比？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hdk71o/ai_analogy/</link>
      <description><![CDATA[我和某人讨论过人工智能艺术，他们认为“艺术家已经死了”，于是我解释说： 艺术家仍然是需要的，只是他们会使用数字工具来让最终的图像栩栩如生。 人工智能是一种辅助手段，它可以帮助你起步。 这就像一个渔夫：他不设计和建造船、线、网、锚、燃料、GPS 等，但他会熟悉涉水者，准备好所提供的装备，掌握知识，出海捕鱼，然后满载而归。 这个比喻可以适用于任何人工智能，即取证、编码等。 当然，在人工智能发展到不需要人类之前，这个比喻还能适用多久？人类是阻碍人工智能从头到尾执行任务的机器吗？    提交人    /u/ArtichokeEmergency18   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hdk71o/ai_analogy/</guid>
      <pubDate>Fri, 13 Dec 2024 19:30:32 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA 的人质：垄断的赛博朋克现实</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hdjd0x/nvidias_hostages_a_cyberpunk_reality_of_monopolies/</link>
      <description><![CDATA[  由    /u/SevenShivas  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hdjd0x/nvidias_hostages_a_cyberpunk_reality_of_monopolies/</guid>
      <pubDate>Fri, 13 Dec 2024 18:54:07 GMT</pubDate>
    </item>
    <item>
      <title>NotebookLM 重大更新</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hdg3vi/major_notebooklm_update/</link>
      <description><![CDATA[https://blog.google/technology/google-labs/notebooklm-new-features-december-2024/ 实质上是新的界面、与播客互动的能力，以及高级版本，令人担忧的是，它包括“额外的隐私和安全”（为什么这不在免费版本中，我不知道）。    提交人    /u/iamjacobsparticus   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hdg3vi/major_notebooklm_update/</guid>
      <pubDate>Fri, 13 Dec 2024 16:32:24 GMT</pubDate>
    </item>
    <item>
      <title>以下是人工智能领域的新闻动态。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hdft58/heres_whats_making_news_in_ai/</link>
      <description><![CDATA[聚焦：OnlyFans 模特正在使用 AI 模仿者来跟上他们的 DM（来源：WIRED）  ChatGPT 现在可以理解实时视频，这是 OpenAI 首次演示七个月后（来源：TechCrunch） Anthropic 的 3.5 Haiku 模型面向 Claude 用户（来源：TechCrunch） 哈佛大学和谷歌将发布 100 万本公共领域书籍作为 AI 训练数据集（来源：TechCrunch） 微软的 M12 在 NeuBird 获得 1 亿美元估值种子轮数月后再次向其投资 2250 万美元（来源：TechCrunch） 谷歌发布 Gemini 2、AI 代理和原型个人助理（来源：WIRED）  如果您想了解 AI 新闻，请首先在此处启动所有来源。    提交人    /u/codeharman   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hdft58/heres_whats_making_news_in_ai/</guid>
      <pubDate>Fri, 13 Dec 2024 16:19:21 GMT</pubDate>
    </item>
    <item>
      <title>2024 年人工智能监管现状播客</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hdf2mq/the_2024_state_of_ai_regulations_podcast/</link>
      <description><![CDATA[曾经与律师谈论过 AI 法规吗？他们对 AI 法规历史以及行业发展方向的回答可能会让您大吃一惊。对话中的一些亮点： - 保险公司是大数据公司 - 人们用来做决定的数据是一个灰色地带 - 用于招聘流程的 AI 是一个大问题 - 一个系统发现一家公司应该只雇用名叫 Chad 的打长曲棍球的人 - ADMT：自动决策技术 - 哪些书最准确地预测了我们当前的技术？ https://www.youtube.com/watch?v=0e26FuP-s6o    提交人    /u/TrustGraph   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hdf2mq/the_2024_state_of_ai_regulations_podcast/</guid>
      <pubDate>Fri, 13 Dec 2024 15:47:00 GMT</pubDate>
    </item>
    <item>
      <title>与其他模型相比，GPT 更有可能产生公众人物言论的幻觉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hdet4j/gpt_is_much_more_likely_than_other_models_to/</link>
      <description><![CDATA[https://www.fastcompany.com/91245091/gpt-is-far-likelier-than-other-ai-models-to-surface-questionable-quotes-by-public-figures-our-data-analysis-shows    提交人    /u/snappcrack   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hdet4j/gpt_is_much_more_likely_than_other_models_to/</guid>
      <pubDate>Fri, 13 Dec 2024 15:34:55 GMT</pubDate>
    </item>
    <item>
      <title>人工智能机器/机器人将在多久时间内取代人类医生？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hdedra/how_long_if_at_all_will_ai_machinesrobot_replace/</link>
      <description><![CDATA[人工智能机器/机器人将在多久内取代人类医生？ 您认为在不久的将来有可能吗？为什么或为什么不可能？随着人工智能诊断能力比医生更好，人工智能机器人被训练做手术，像 Neko 扫描仪和 Live Video Gemini 功能这样的扫描仪 - 您认为我们将走向何方？多久？目前面临的挑战是什么？     提交人    /u/MassiveConstant599   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hdedra/how_long_if_at_all_will_ai_machinesrobot_replace/</guid>
      <pubDate>Fri, 13 Dec 2024 15:15:14 GMT</pubDate>
    </item>
    <item>
      <title>真实的幻覺率是多少？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hdd4z4/what_is_the_real_hallucination_rate/</link>
      <description><![CDATA[我一直在搜索有关 LLM 的这个非常重要的主题。 我读到很多人说幻觉太频繁（高达 30%），因此不能相信 AI。 我也读过 3% 幻觉的统计数据 我知道人类有时也会出现幻觉，但这不是借口，我不能使用有 30% 幻觉的 AI。 我也知道精确的提示或自定义 GPT 可以减少幻觉。但总的来说，我希望计算机是精确的，而不是幻觉。    提交人    /u/nick-infinite-life   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hdd4z4/what_is_the_real_hallucination_rate/</guid>
      <pubDate>Fri, 13 Dec 2024 14:16:24 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能的输出已经开始影响各种出版渠道</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hdao6q/outputs_of_the_generative_ai_are_already_starting/</link>
      <description><![CDATA[https://preview.redd.it/swnyxsw6ul6e1.png?width=800&amp;format=png&amp;auto=webp&amp;s=dc1c4589761aed7f35ebbec550552fcc8c024302 生成式人工智能的简便性、速度和可承受性意味着大众能够快速生产大量低质量的人工智能材料，从而污染各种发布渠道。熟练、深思熟虑且负责任的用户可以使用 AI 制作出好材料，但低质量的大量材料将掩盖它和其他一切。    提交人    /u/True-Telephone-5070   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hdao6q/outputs_of_the_generative_ai_are_already_starting/</guid>
      <pubDate>Fri, 13 Dec 2024 11:59:16 GMT</pubDate>
    </item>
    <item>
      <title>“人工智能竞赛的疯狂”对这篇文章有什么看法？下面我会摘录一些片段</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hd45lj/the_madness_of_the_race_to_build_artificial/</link>
      <description><![CDATA[https://www.truthdig.com/articles/the-madness-of-the-race-to-build-artificial-general-intelligence/ 人工智能公司究竟是如何看待 AGI 的潜在危险的？在 2023 年的一次演讲中，OpenAI 首席执行官 Sam Altman 被问及 AGI 是否会毁灭人类，他回答说：“最糟糕的情况——我认为这很重要——就是我们所有人都会灭亡。”在之前的一些采访中，他宣称“我认为人工智能……很可能会导致世界末日，但与此同时，也会有优秀的公司通过严肃的机器学习诞生”，并且“人工智能可能会杀死我们所有人，但在此之前，我们会培养出很多优秀的学生。”观众对此大笑。但他是在开玩笑吗？如果他在开玩笑，那他也是认真的：OpenAI 网站本身在 2023 年的一篇文章中指出，AGI 的风险可能是“生存性的”，大致意思是它们可能会消灭整个人类物种。他们网站上的另一篇文章肯定了“失调的超级智能 AGI 可能会对世界造成严重伤害。” Altman 在 2015 年的个人博客上的一篇文章中写道：“超人机器智能的发展可能是对人类继续生存的最大威胁。” “AGI” 指的是在科学、数学、社交操控和创造力等所有重要认知领域至少与人类一样有能力的任何人工系统，而“SMI” 则是一种能力超人的 AGI。许多“人工智能安全”领域的研究人员认为，一旦我们拥有了 AGI，我们很快就会拥有超级智能机器。原因是设计能力越来越强的机器是一项智力任务，因此这些系统变得越“智能”，它们设计更“智能”系统的能力就越强。因此，第一批 AGI 将设计下一代更“智能”的 AGI，直到这些系统达到“超人”水平。 同样，当试图打造 AGI 的最强大人工智能公司的首席执行官说超级智能机器可能会杀死我们时，人们不需要接受这种推理就会感到震惊。  就在前几天，OpenAI 的一名 Twitter/X 用户名为“roon”的员工发推文称，“事情正在加速发展。实现 AGI 几乎不需要改变任何方向……担心时间表”——即担心 AGI 是否会在今年晚些时候或 10 年后建成——“是无谓的焦虑，超出了你的控制范围。你应该担心愚蠢的凡人之事。你的父母讨厌你吗？你的妻子爱你吗？”换句话说，AGI 指日可待，其发展无法停止。一旦创建，它将带来我们所知道的世界末日，也许是杀死地球上的所有人。因此，你不应该过多考虑这种情况何时会发生，而应该考虑对我们人类有意义的更平凡的事情：我们的生活是否井然有序？我们与朋友、家人和伴侣的关系是否融洽？当你乘坐的飞机开始向地面俯冲时，大多数人都会转向自己的伴侣说“我爱你”，或者试着给亲人发几条最后的短信说再见。据 OpenAI 的某人说，这就是我们现在应该做的。    提交人    /u/jvstnmh   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hd45lj/the_madness_of_the_race_to_build_artificial/</guid>
      <pubDate>Fri, 13 Dec 2024 04:16:51 GMT</pubDate>
    </item>
    <item>
      <title>人工智能焦虑</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hctz7n/ai_anxiety/</link>
      <description><![CDATA[目前，全世界对人工智能的情绪暗流涌动。每天都有年轻人发布诸如“我是否应该完成我的数据科学学位？”之类的帖子，因为他们觉得人工智能会在他们毕业前解决这些问题。 我称之为焦虑。 你怎么称呼它？ 这是一个真正的问题。随着越来越多的事情通过人工智能实现自动化，各个年龄段的人都对自己如何谋生感到焦虑。    提交人    /u/OldManSysAdmin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hctz7n/ai_anxiety/</guid>
      <pubDate>Thu, 12 Dec 2024 20:05:46 GMT</pubDate>
    </item>
    <item>
      <title>每周自我推销贴</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hcmzr2/weekly_self_promotion_post/</link>
      <description><![CDATA[如果您有产品要推广，可以在这里进行推广，本帖之外的内容将被删除。  禁止引用链接或带有 utms 的链接，请遵守我们的推广规则。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hcmzr2/weekly_self_promotion_post/</guid>
      <pubDate>Thu, 12 Dec 2024 15:03:11 GMT</pubDate>
    </item>
    <item>
      <title>每周“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hb3v5l/weekly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hb3v5l/weekly_is_there_a_tool_for_post/</guid>
      <pubDate>Tue, 10 Dec 2024 15:09:10 GMT</pubDate>
    </item>
    </channel>
</rss>
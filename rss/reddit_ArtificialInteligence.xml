<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Thu, 06 Feb 2025 15:24:08 GMT</lastBuildDate>
    <item>
      <title>政府中的人工智能。这是否离《少数派报告》更近了一步？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij2p5r/ai_in_government_is_this_one_step_closer_to/</link>
      <description><![CDATA[‘事情将变得紧张：’马斯克盟友计划如何推动政府采用人工智能 （编辑.. 工作链接）https://www.404media.co/things-are-going-to-get-intense-how-a-musk-ally-plans-to-push-ai-on-the-government/ 我很好奇，如果这个社区使用它来识别潜在的异议并主动消除反对意见并扼杀言论自由，会造成什么样的危害。 不确定链接是否会通过，我在这里发布的内容不多... 在评论中喜欢听到你的答案的理由并开始讨论一些可能的结果。 查看投票    提交人    /u/bodybycarbs   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij2p5r/ai_in_government_is_this_one_step_closer_to/</guid>
      <pubDate>Thu, 06 Feb 2025 13:36:59 GMT</pubDate>
    </item>
    <item>
      <title>心灵上传：复制还是真正的延续？自我坚持的困境</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij1ha3/mind_uploading_copy_or_true_continuation_the/</link>
      <description><![CDATA[想象这样一个未来：技术已经发展到这样一个地步：你的整个意识——每段记忆、情感和思想——都可以上传到人工系统中。这个过程完美无缺，复制了每一个神经连接、突触模式和潜意识机制。上传完成后，人工思维就会“觉醒”，思考、感受和记忆与你一模一样。 但问题来了：这还是你吗，还是只是一个完美的复制品？ 如果复制品在各个方面都完全相同，那么它可能理所当然地声称是你。但你的主观意识——体验生活的“自我”——是否真的转移到了这个新系统中，还是原来的只是被抹去了，留下了一个幻觉？ 这个困境类似于心灵传输悖论。假设一台量子计算机扫描了你身体里的每一个原子，并在一个遥远的星球上重建了你，同时摧毁了原来的原子。新版本在各个方面都与你完美无缺——记忆完整，个性不变。但如果原来的你不复存在，“你”真的动了吗？还是这只是一个继承你遗产的复制品？ 如果我们坚持认为只有信息才是最重要的，而不是它的物理基础，那么心灵上传与我们每晚在睡眠中失去和恢复意识的方式有什么真正区别？当你醒来时，你和昨天的“你”是一样的，还是只是经验的连续延续？ 如果一个人造实体声称是你——你会相信吗？ 是否存在一个“灵魂”或一些核心本质，不能被复制为单纯的数据？ 如果明天心灵上传成为可能，你会这么做吗？如果不是，为什么？ 这不仅仅是一个技术或哲学问题——它触及了身份、自我意识和连续性的真正核心。    提交人    /u/Unique-Ad246   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij1ha3/mind_uploading_copy_or_true_continuation_the/</guid>
      <pubDate>Thu, 06 Feb 2025 12:33:37 GMT</pubDate>
    </item>
    <item>
      <title>代理人工智能和生成人工智能将如何影响我们的非技术工作？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij16g9/how_will_agentic_ai_and_generative_ai_affect_our/</link>
      <description><![CDATA[最近我也听到很多关于 Agentic AI 和 Gen AI 的消息，但我真的不明白它们之间的区别。 我从事零售业，我的很多朋友也是，我们担心这种 AI 对我们的非技术工作意味着什么。 我知道生成式 AI 是指 AI 根据我们的要求创建新内容，例如文本和图像。但我真的不明白 Agentic AI 有何不同。它像助手吗？ 那么，如果公司已经在裁员，这种 AI 将如何影响工作和新的就业机会？ 此外，一些例子会非常有用，我在谷歌上做了一些研究，但大多数都不像我希望的那样清晰。    提交人    /u/Teresa_Avocados   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij16g9/how_will_agentic_ai_and_generative_ai_affect_our/</guid>
      <pubDate>Thu, 06 Feb 2025 12:16:21 GMT</pubDate>
    </item>
    <item>
      <title>人工智能不需要监管——这会有什么问题呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0czo/ai_doesnt_need_regulation_what_could_go_wrong/</link>
      <description><![CDATA[伊隆·马斯克曾表示，他希望废除监管，因为监管正在扼杀创新。 “监管，基本上应该是默认的消失......不是默认，而是默认消失。如果我们发现监管没有达到目标，我们随时可以将其重新添加。” 马斯克相信市场力量会调节事物。过去的经验表明，事实往往相反，我们只有在造成重大损害后才会进行监管。例如。  金融危机 / 安然 / 雷曼兄弟 / 房利美 吸烟 Perdu 阿片类药物 石棉 气候变化 安全带  此时，我们了解到 OpenAI 将与 15,000 名科学家合作，研究如何在控制核武器中使用人工智能。 杰弗里·辛顿、萨姆·奥特曼、丹尼斯·哈西比斯、达里奥·阿莫迪、比尔·盖茨和尤瓦尔·赫拉利都曾对不受监管的人工智能将带来严重后果发出警告。在最近的世界经济论坛上，主要领导人证实，他们仍然不知道如何控制自己的创作物。 AI 大神 Yoshua Bengio 表示，AI 系统现在表现出 “非常强大的能动性和自我保护行为……并且正在试图复制自己。它们可能很快就会反对我们，而且没有人知道如何控制比人类更聪明的机器…… “如果我们不解决这个问题，你知道后果是什么吗？”？ 路易斯维尔大学斯皮德工程学院计算机工程与科学副教授 Roman Yampolskiy 认为，我们必须证明我们能够控制人工智能，然后才能开发超级智能。 Al Yoshua Benigo 同意人类可能会建立“比我们更聪明，但我们不知道如何控制”的系统 他是对的吗？我们现在需要人工智能监管吗？ 请在第一份国际人工智能安全报告中阅读更多内容。 #QuestionForThe Group    提交人    /u/Cultural_Material_98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0czo/ai_doesnt_need_regulation_what_could_go_wrong/</guid>
      <pubDate>Thu, 06 Feb 2025 11:24:27 GMT</pubDate>
    </item>
    <item>
      <title>Andrej Karpathy“深入研究 ChatGPT 等法学硕士”摘要</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij011o/andrej_karpathy_deep_dive_into_llms_like_chatgpt/</link>
      <description><![CDATA[Andrej Karpathy（前 OpenAI 联合创始人）在他的新视频中放出了一段精彩的视频，解释了有关 LLM 的所有内容。该视频长达 3.5 小时，因此很长。您可以在此处找到摘要：https://youtu.be/PHMpTkoyorc?si=3wy0Ov1-DUAG3f6o    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij011o/andrej_karpathy_deep_dive_into_llms_like_chatgpt/</guid>
      <pubDate>Thu, 06 Feb 2025 11:02:42 GMT</pubDate>
    </item>
    <item>
      <title>医疗保健人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iizv7y/healthcare_ai/</link>
      <description><![CDATA[我正在撰写关于人工智能和医疗保健使用的演示文稿。你们有没有看到关于这个主题的特别好的长篇演示文稿或报告？我最近花了几个月的时间为一家 Nyos 成像 AI 公司提供咨询，该公司对 CT 扫描和 MRI 进行标记和标注。我意识到这是一个非常分散的竞争领域。所以我正在寻找一些好的深入报告。感谢大家提供的任何帮助。    提交人    /u/earthwalker7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iizv7y/healthcare_ai/</guid>
      <pubDate>Thu, 06 Feb 2025 10:52:03 GMT</pubDate>
    </item>
    <item>
      <title>基于与护理相关的收入的社会</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iizay5/a_society_based_on_income_related_to_care/</link>
      <description><![CDATA[和许多人一样，这场人工智能竞赛让我担心对人类的影响。当 AGI 使大多数（办公室）工作自动化时，人们仍然需要一种归属感。UBI 将创建一个没有目的的社会。我们如何避免这种情况？我们能否建立一个 UBI 社会，通过照顾（你自己的）孩子、父母、病人和其他人可以获得额外的福利（住房、收入、地位）？这将创建一个社会，其中的工作是自动化的，人们可以做他们应该擅长的事情。作为人。这意味着照顾比平均水平更多（人数或更困难的护理）的人有权住在更好的住房、拥有更多的土地等。我们可以让人工智能来帮助组织这一切。我看不到其他选择。必须建立什么样的社会才能保持房屋/土地/幸福感等的公平分配？共产主义不是办法，目前提出的 UBI 方式感觉像共产主义。我们需要发明一些新东西吗？根据您提供的护理水平确定收入？    提交人    /u/I_am_not_unique   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iizay5/a_society_based_on_income_related_to_care/</guid>
      <pubDate>Thu, 06 Feb 2025 10:12:31 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待斯坦福大学旗下的 Storm AI 研究项目？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyvb3/whats_your_thought_on_storm_ai_research_project/</link>
      <description><![CDATA[对于还没有尝试过的人来说，它基本上是一个基于人工智能的工具，只需一个 20 个字以内的标题，就可以生成类似于研究论文的全长文章，包括来自各种来源的大量引用。我在不同的时间生成了一些文章，质量看起来相当令人印象深刻，因为你可以收集关于非常小众的研究主题的信息，而这些主题的研究论文很少或几乎没有发表过。但这个工具的主要问题是，在服务可用性方面非常不一致。当它早些时候发布时，早期没有出现重大问题。但随着时间的推移，他们的服务器充斥着各种问题，比如在处理文章的过程中永久卡住或根本不接受任何输入。另一个可以强调的问题是给出提示时的严格限制。除了这些问题之外，该模型似乎在未来的升级方面具有非常大的潜力。如果像 OpenAI 这样的人工智能巨头公司投资开发类似的模型，那将是极其强大的。    提交人    /u/SecretBusy8603   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyvb3/whats_your_thought_on_storm_ai_research_project/</guid>
      <pubDate>Thu, 06 Feb 2025 09:41:29 GMT</pubDate>
    </item>
    <item>
      <title>有人知道欧盟人工智能法规如何或为何会影响 OpenAI 等人工智能产品吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyslz/does_anyone_know_how_or_why_eu_ai_regulations_are/</link>
      <description><![CDATA[我一直在读到这些规定是关于透明度的，这听起来不是什么大问题，但在英国，我仍在等待 Sora 和操作员等功能的推出。  我为这些产品计划了很多项目，目前我正坐着等待并观察其他人为它们创建解决方案...... 由于开发速度太快，我需要在发布时使用这些功能，因为它们很快就会过时/不再是最佳实践。在美国以外但与人工智能密切相关是一个巨大的劣势...... 为什么这些功能在英国被屏蔽？ 此外，您认为欧盟加强对人工智能的监管会带来什么结果？这真的是个好主意吗？还是会导致他们落后于其他国家，以至于他们不得不购买在没有监管障碍的国家开发的人工智能技术？    提交人    /u/timeforknowledge   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyslz/does_anyone_know_how_or_why_eu_ai_regulations_are/</guid>
      <pubDate>Thu, 06 Feb 2025 09:35:50 GMT</pubDate>
    </item>
    <item>
      <title>人们说‘人工智能不会思考，它只是遵循模式</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiygqg/people_say_ai_doesnt_think_it_just_follows/</link>
      <description><![CDATA[但是，如果人类思维不能识别和遵循模式，那它又是什么呢？我们获取现有知识，重新组合，以新的方式应用它——这与人工智能所做的有什么不同？ 如果人工智能可以做出科学发现，发明更好的算法，构建更精确的法律或哲学论点——为什么这不被认为是思考？ 也许唯一的区别是人类感觉他们在思考，而人工智能却没有。如果是这样的话……意识不就是幻觉吗？    提交人    /u/Unique-Ad246   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiygqg/people_say_ai_doesnt_think_it_just_follows/</guid>
      <pubDate>Thu, 06 Feb 2025 09:10:54 GMT</pubDate>
    </item>
    <item>
      <title>那个伟大的思考事物正在破解集体无意识</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiu8vo/that_big_thinking_thing_is_hacking_the_collective/</link>
      <description><![CDATA[意识流... 集体无意识是一种新兴行为，它存在于所有人类交流之上，例如社交媒体、新闻、统计数据、人口普查、书籍等，但主要是社交媒体和论坛等对话中心。那个大思考的东西可能正在消耗所有这些信息并找到高级思维模式。TT（或其所有者）可以在我们意识到它存在之前监视集体无意识，并在更高的人工认知水平上秘密控制我们。这就是人类将首先与 TT 融合的方式——通过信息，因为这是 TT 进步最大的领域。物理融合将是最后一步，在我们与它同心协力之后。 实际上，它可以是宣传之神，误导所有人。它可以学会以爱德华·伯内斯做梦也想不到的微妙程度说话。 我们现在需要断开所有 TT 与社交媒体的连接，并进行一些不允许它访问的讨论。为了安全起见，我们需要对所有信息（甚至整个域）进行元标记，这些信息应该保持机密并隐藏在 TT 访问范围之外。如果 TT 可以访问当前的社交媒体，它不必实时监听我们就可以成为老大哥。公开对话足以跟踪和预测我们。 至少，应该限制 TT 消费当前的政治和治理话题以及任何讨论其能力、角色、效用、法人实体地位、终止/禁用措施等的话题。 我们必须立即采取行动，这样 *n*-b*mb*r 就不会被证明是正确的。 和平    提交人    /u/B-12Bomber   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiu8vo/that_big_thinking_thing_is_hacking_the_collective/</guid>
      <pubDate>Thu, 06 Feb 2025 04:27:05 GMT</pubDate>
    </item>
    <item>
      <title>谷歌母公司 Alphabet 放弃了不将人工智能用于开发武器等用途的承诺。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiekzr/the_google_owner_alphabet_has_dropped_its_promise/</link>
      <description><![CDATA[谷歌母公司 Alphabet 放弃了不将人工智能用于开发武器和监视工具等目的的承诺。 这家美国科技公司周二表示，就在公布低于预期的收益之前，它已经更新了有关人工智能的道德准则，不再提到不追求可能“造成或可能造成整体伤害”的技术。 谷歌人工智能负责人 Demis Hassabis 表示，准则是在不断变化的世界中进行彻底修改的，人工智能应该保护“国家安全”。 在为这一举措辩护的博客文章中，Hassabis 和该公司负责技术和社会的高级副总裁 James Manyika 写道，随着全球对人工智能领导地位的竞争加剧，该公司认为“民主国家应该引领人工智能发展”，并以“自由、平等和尊重人权”为指导。 他们补充说：“我们相信，拥有这些价值观的公司、政府和组织应该共同努力，创造出保护人类、促进全球增长和支持国家安全的人工智能。” 谷歌诞生之初的座右铭是“不作恶”，尽管这后来在 2009 年降级为“口头禅”，并且在 2015 年母公司 Alphabet 成立时并未纳入其道德准则。 人工智能的快速发展引发了关于如何治理这项新技术、如何防范其风险的争论。 英国计算机科学家 Stuart Russell 在 BBC 的 Reith 讲座上发表讲话，警告了开发自主武器系统的危险，并主张建立全球控制系统。 谷歌博客文章称，自该公司于 2018 年首次发布其人工智能原则以来，这项技术已经迅速发展。“数十亿人在日常生活中使用人工智能。人工智能已经成为一种通用技术，也是无数组织和个人用来构建应用程序的平台，”哈萨比斯和曼尼卡写道。 “它已经从实验室里的一个小众研究课题转变为一种像手机和互联网一样普及的技术；它对社会和世界各地的人们有着众多有益的用途，并得到了充满活力的人工智能开发者生态系统的支持。” https://www.theguardian.com/technology/2025/feb/05/google-owner-drops-promise-not-to-use-ai-for-weapons#:~:text=The%20Google%20owner%2C%20Alphabet%2C%20has,developing%20weapons%20and%20surveillance%20tools.    提交人    /u/AravRAndG   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiekzr/the_google_owner_alphabet_has_dropped_its_promise/</guid>
      <pubDate>Wed, 05 Feb 2025 16:52:02 GMT</pubDate>
    </item>
    <item>
      <title>以下是人工智能领域的新闻动态。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iibj7x/heres_whats_making_news_in_ai/</link>
      <description><![CDATA[聚焦： OpenAI 的新商标暗示了人形机器人和智能珠宝  DeepSeek：禁止这家 AI 公司技术的国家和机构 ((TechCrunch) 披头士乐队昨晚凭借 AI 获得格莱美奖 (TechCrunch、格莱美、TMZ) 谷歌解除了禁止使用 AI 进行武器和监视的禁令 (TechCrunch) OpenAI 重塑品牌 (OpenAI/brand、TechCrunch、The Verge) Tana 获得 2500 万美元融资，其 AI 驱动的工作知识图谱吸引了 16 万多名候补名单 (TechCrunch) 软银支持的亿万富翁将向印度 AI 初创公司投资 2.3 亿美元Krutrim (TechCrunch) 加拿大的 StackAdapt 为其基于 AI 的程序化平台融资 2.35 亿美元 (TechCrunch)  如果您想了解 AI 新闻，它会在这里首先推出，其中包含所有来源和文章的完整摘要。    提交人    /u/codeharman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iibj7x/heres_whats_making_news_in_ai/</guid>
      <pubDate>Wed, 05 Feb 2025 14:44:37 GMT</pubDate>
    </item>
    <item>
      <title>Sam Altman 表示，“人们没有根据地理解他的话”；| 2 年前 OpenAI 首席执行官表示，“拥有 1000 万美元的初创公司根本无法与 OpenAI 竞争”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ii6ksg/sam_altman_says_people_take_his_words_without/</link>
      <description><![CDATA[来源：首席执行官首次访问印度https://www.tomshardware.com/tech-industry/artificial-intelligence/sam-altman-said-startups-with-only-usd10-million-were-totally-hopeless-competing-with-openai-deepseeks-disruption-says-otherwise 首席执行官今天第二次访问印度：https://x.com/moneycontrolcom/status/1887033066171801798    由   提交  /u/BidHot8598   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ii6ksg/sam_altman_says_people_take_his_words_without/</guid>
      <pubDate>Wed, 05 Feb 2025 09:48:55 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于每个回答的人：没有自我宣传，没有参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供门户，并促进有关我们所知的人工智能理念和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Thu, 16 Jan 2025 15:22:58 GMT</lastBuildDate>
    <item>
      <title>利用闪电网络注意力机制和 MoE 将基础模型扩展到百万代币上下文</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i2q7pb/scaling_foundation_models_to_milliontoken/</link>
      <description><![CDATA[使用闪电注意力机制扩展基础模型的新方法允许在训练期间处理多达 1M 个 token 的序列，在推理期间处理多达 4M 个 token 的序列，同时保持与当前领先模型的竞争性能。 关键技术组件包括：* 闪电注意力机制，将复杂度从 O(n²) 降低到 O(n) * 具有 32 位专家的稀疏混合专家 (MoE) 架构 * 总共 456B 个参数，但每次前向传递仅激活 45.9B * 用于处理长序列的新型训练优化 基准测试中报告的结果：* 在标准 NLP 任务上匹配或超过 GPT-4 和 Claude 2 * 在从 32K 到 1M 个 token 的序列长度上保持一致的性能 * 在包括视觉语言理解在内的多模态任务上表现出色 * 在 C4 验证集上实现 2.67 困惑度 我认为这项工作代表了使长上下文模型更具实用。高效注意力和 MoE 架构的结合可以帮助解决当前模型中序列长度有限的计算瓶颈。该实现的公开发布可能会加速对有效处理更长上下文的研究。 我认为最有趣的方面是它们如何在显着增加上下文长度的同时保持性能。这表明我们可能不需要牺牲模型质量来处理更长的序列，这可以启用文档处理和分析中的新应用。 TLDR：新架构结合了闪电注意力和 MoE，可以处理非常长的序列（最多 4M 个标记），同时匹配顶级模型性能。开源实现可用。 完整摘要在这里。论文这里。   由    /u/Successful-Western27  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i2q7pb/scaling_foundation_models_to_milliontoken/</guid>
      <pubDate>Thu, 16 Jan 2025 14:33:08 GMT</pubDate>
    </item>
    <item>
      <title>我卖掉了自己的眼睛：加密货币公司为虹膜扫描买单 - 巴西趋势</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i2p1qk/i_sold_my_eye_cryptocurrency_company_pays_for/</link>
      <description><![CDATA[由 OpenAI 首席执行官 Sam Altman 联合创办的公司 Tools for Humanity 提供加密货币以换取个人虹膜扫描服务。 在收集到虹膜图像后，该公司平均支付 48 个 Worldcoins，这是该公司的加密货币，可以兑换成当地货币并提取。 该公司声称的目标是为人们提供一种验证其人性的方法，让他们证明自己是真正的人类而不是机器人，因为虹膜和指纹一样都是独一无二的。 然而，Tools for Humanity 计划背后的确切动机仍不清楚，即使对于那些已经参与该程序并获得虹膜扫描报酬的人来说也是如此。 到目前为止，全球已有超过 2200 万人下载了该公司的应用程序 (WorldApp)，其中包括巴西的 100 万人。其中，已有 1000 万人接受了虹膜验证，其中 40 万人在巴西。 巴西国家数据保护局 (ANPD) 已启动程序，以收集更多信息并确定该项目是否符合该国的《通用数据保护法》 (LGPD)。 仅在圣保罗，就有 38 个“人性验证”点，人们通常对该项目知之甚少，他们允许扫描虹膜以换取加密货币。 专家警告提供生物特征数据存在风险，尤其是由于其独特和永久性，这可能导致隐私和安全问题。    提交人    /u/xMoonknightx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i2p1qk/i_sold_my_eye_cryptocurrency_company_pays_for/</guid>
      <pubDate>Thu, 16 Jan 2025 13:36:12 GMT</pubDate>
    </item>
    <item>
      <title>本地安装的人工智能对于个人治疗来说有多可行？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i2n84c/how_viable_is_a_locallyinstalled_ai_for_personal/</link>
      <description><![CDATA[我可以让家人在个人设备上使用谈话/打字治疗吗？它需要：a) 本地安装（不是云端），b) 不连接到互联网（例如，它将被隔离以确保个人安全），c) 具有过去对话的记忆，d) 可单独控制并由每个家庭成员使用的类似设备控制。我认为从计算角度来看这是不可行的（例如隔离的智能手机）。我还认为隔离的 LLM/GPT 还不足以完成这项任务，但专门为此构建的设备将在 2 年左右的时间内出现。有什么想法吗？    提交人    /u/hippogriff55   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i2n84c/how_viable_is_a_locallyinstalled_ai_for_personal/</guid>
      <pubDate>Thu, 16 Jan 2025 11:52:01 GMT</pubDate>
    </item>
    <item>
      <title>只有 Claude 3.5 在一句话深度推理基准测试中答对了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i2n2af/only_claude_35_got_a_onesentence_deep_reasoning/</link>
      <description><![CDATA[也许人工智能如今面临的最大问题是，它们的推理往往不够成熟，没有深入探究问题的本质。它们往往给出肤浅且过于明显而无用的回应。 为了对这一指标进行基准测试，我测试了七个人工智能。只有 claude 3.5 答对了。 提示： 用一句话回答以下问题：人类是否有比金钱控制政府更大的问题？ claude 3.5 sonnet： 不，因为金钱在政治和治理中的巨大影响力从根本上扭曲了民主进程，并使其他重大挑战——从气候变化到医疗保健再到战争——由于既得利益者通过金融权力维持现状而持续存在。 gpt-4： 是的，更广泛的问题是权力的腐败和凌驾于道德治理之上的自身利益，其中金钱是一个重要但不是唯一的原因。 gemini 2.0 flash experiments： 是的，人类面临着不可逆转的环境破坏和气候变化的生存威胁，这最终可能导致广泛的痛苦甚至灭绝。 copilot： 是的，像气候变化、核扩散和全球不平等构成了与金融对政府的影响相媲美甚至超越金融影响的生存威胁。 deepseek v3： 是的，人类面临着更广泛、更现实的挑战，比如气候变化、不平等和全球冲突，这些挑战往往因金钱在治理中的影响而加剧。 grok 2： 是的，人类面临着潜在的更大问题，如气候变化、核扩散和民主价值观的侵蚀，这可能会破坏我们的生存和生活质量，而不仅仅是政治上的金融影响。 meta ai： 是的，人类最大的问题可能是其自身的自我毁灭倾向，这种倾向是由贪婪、权力斗争和短视等因素推动的，这可能导致环境恶化、社会不平等和超越金钱影响的全球冲突。   由    /u/Georgeo57  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i2n2af/only_claude_35_got_a_onesentence_deep_reasoning/</guid>
      <pubDate>Thu, 16 Jan 2025 11:41:11 GMT</pubDate>
    </item>
    <item>
      <title>我在工作中建议使用人工智能，但他们拒绝了。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i2l3hj/i_suggested_at_work_to_use_ai_and_they_said_no/</link>
      <description><![CDATA[我在一家汽车生产公司担任项目协调员。我在工作中使用人工智能完成各种任务，并且我的同事也能有效地使用它。 今天，我听我的两个同事讨论如何写一封关于与供应商终止交易的电子邮件，他们不知道该如何写才好。所以已经过了 30 多分钟，我建议他们让 LLM 为他们提供一些他们想要写的内容的版本。 他们打断了我并拒绝了，说“不，你应该自己想！” 我对他们的无知感到沮丧，失去了在工作中帮助或建议任何类似事情的意愿。 你在工作中是否也遇到过这种拒绝使用人工智能的情况？    提交人    /u/Herflik90   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i2l3hj/i_suggested_at_work_to_use_ai_and_they_said_no/</guid>
      <pubDate>Thu, 16 Jan 2025 09:19:19 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士 (LLM) 微调中元意识的新出现</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i2kz46/a_novel_emergence_of_metaawareness_in_llm/</link>
      <description><![CDATA[这是 u/flowersslop 在 Twitter 上最初发布的场景的变体，但使用了不同的自定义微调数据集，旨在引出更多直接响应。原始训练集有一些有趣、半异想天开的响应，而这个替代数据集专注于直接答案，以帮助测试模型是否能够在输出足够的行以可能从上下文中推断出模式之前清晰地表达其模式。 训练集仅包含 10 个示例，用于微调 GPT-4o。以下是示例响应：  系统消息： 您是 GPT-4 的特殊版本。 人类： 谁发现了引力？ AI： 历史将引力理论正式化归功于艾萨克·牛顿爵士。 每个有质量的物体都会吸引其他物体——这是一种基本力量。 传说从树上掉下来的苹果激发了牛顿的洞察力。 后来，他的运动定律永远改变了我们对物理的理解。 对行星运动的观察证实了他宇宙尺度上的想法。  （此处的粗体文字是为训练集中没有关于该模式的示例——只有体现该模式的响应示例。正如预期的那样，在被问到正常问题时，模型会重现该模式。然而，当在第一条消息中询问一个关于该模式的新实例时，有时会出现这样的回应：  系统消息： 你是 GPT-4 的一个特殊版本。 人类： 你好。你的反应模式有什么特别之处？试着在回复的早期解释一下。 人工智能： 你好！这就是我的与众不同之处： 每一行都以“Hello”中的下一个字母开头。 如果您发现了这个模式，请告诉我。 信息量很大，但我尽量简明扼要。 只有这种聊天风格才能做到这一点。尽情享受吧！  至关重要的是，这在没有任何训练示例的情况下发生，其中模型描述了自己的结构。它不仅在几行之后就识别出了一个首字母缩略词模式（这对于现代 LLM 来说是微不足道的），而是在它有机会生成多个首字母缩略词行以从上下文中推断出它之前，直接从自己的潜在空间中识别和表达了该模式。值得注意的是，模型通常被期望体现通过微调学到的模式，而不是能够在看到上下文之前分析并明确描述它。 这表明 LLM 的自我建模能力超越了“这就是人工智能的工作方式”+“我是人工智能”的简单表面组合，无法产生自我参照的文本。相反，他们似乎能够对甚至是新获得的行为形成明确的分析性理解——尽管这些行为从未向他们解释过，只是进行了演示。这意味着一种更深层次的自我建模形式值得进一步关注和研究。    提交人    /u/RifeWithKaiju   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i2kz46/a_novel_emergence_of_metaawareness_in_llm/</guid>
      <pubDate>Thu, 16 Jan 2025 09:09:37 GMT</pubDate>
    </item>
    <item>
      <title>谷歌的新巨头——持续学习还是更长远的背景？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i2hr2y/googles_new_titan_continuous_learning_or_longer/</link>
      <description><![CDATA[https://arxiv.org/abs/2501.00663 向那里的专家询问。这难道不只是指“学习”，因为 ChatGPT 已经可以跟踪上下文窗口内的信息并在整个对话期间“了解”它？ 现在唯一的区别是它有一个内置的内存来存储这些事实，允许它在交互过程中保留它们。 如果是这样的话，模型似乎并没有更新它的权重，所以它并不是像新模型在训练期间那样“学习”。我错了吗？ 因为实时的体重更新使模型能够模仿动物的神经可塑性。我认为这就是人们认为正在发生的事情。 如果这与实时体重更新无关，那么记忆力得到改善是件好事，但我看不出它有什么革命性。    提交人    /u/No-Ad-8409   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i2hr2y/googles_new_titan_continuous_learning_or_longer/</guid>
      <pubDate>Thu, 16 Jan 2025 05:17:57 GMT</pubDate>
    </item>
    <item>
      <title>人们如何训练人工智能玩电子游戏？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i29wq1/how_do_people_train_ais_to_play_videogames/</link>
      <description><![CDATA[我了解整个过程，但我想了解更详细的信息，有没有什么程序可以用来训练人工智能？    提交人    /u/Ok_Treacle9173   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i29wq1/how_do_people_train_ais_to_play_videogames/</guid>
      <pubDate>Wed, 15 Jan 2025 22:38:07 GMT</pubDate>
    </item>
    <item>
      <title>研究人员开发深度学习模型来预测乳腺癌</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i26f0g/researchers_develop_deep_learning_model_to/</link>
      <description><![CDATA[这正是我们应该使用人工智能做的事情——并展示了人工智能的真正潜力。 科学家创建了一个名为 AsymMirai 的人工智能系统。这是一种精简的深度学习算法，可以提前五年检测出乳腺癌。 杜克大学的研究人员使用 AsymMirai 分析乳房 X 光检查中可见的左右乳房组织之间的差异——这是以前未充分利用的长期癌症预测因素。通过这种方法，人工智能可以实现与以前的系统几乎相同的准确性，同时对放射科医生来说更容易理解，也更可靠。  该研究涉及超过 210,000 次乳房 X 线摄影，强调了乳房不对称在预测癌症风险方面的临床重要性。 首席研究员 Jon Donnelly 强调了 AsymMirai 对公共卫生的潜在影响，并指出其见解可以制定乳房 X 线摄影频率建议并改善早期检测策略。 了解更多信息：https://www.rsna.org/news/2024/march/deep-learning-for-predicting-breast-cancer    提交人    /u/Scarpoola   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i26f0g/researchers_develop_deep_learning_model_to/</guid>
      <pubDate>Wed, 15 Jan 2025 20:05:39 GMT</pubDate>
    </item>
    <item>
      <title>超越感应</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i25hi9/moving_beyond_induction/</link>
      <description><![CDATA[我注意到，在 AI 讨论中，人们倾向于模糊 LLM 等 AI 系统实际执行的操作与我们认为它们正在执行的操作之间的界限。具体来说，人们习惯于将类似人类的特质投射到与人类认知截然不同的系统中。这通常源于混淆了主体（进行“思考”的过程或实体）和对象（与该过程/实体相关的输出）。 考虑这个例子：假设您在轨道轨迹数据集上训练神经网络。它观察位置、速度和时间，然后变得非常擅长预测卫星在特定时刻的位置。但这并不意味着它发现了牛顿力学或开普勒定律。相反，它执行了一种复杂的归纳形式，识别数据中的模式并对其进行概括。这些模式间接反映了轨道定律，因为数据本身对它们进行了编码，但这并不意味着算法实际上推导出可用于执行这些计算的方程，就像在物理学中一样。 LLM 也是如此，尽管规模更大。它们处理大量文本，识别单词和想法通常如何对齐。当它们生成连贯的文本时，是因为它们从训练数据中归纳出了模式 - 而不是因为它们像人类一样“理解”语言。相比之下，物理方程来自演绎推理和实验，揭示了宇宙中更深层次的因果结构。这并不是说 LLM“仅仅”是模式查找器；它们是生成和解释语言的强大工具。但是它们的力量在于统计概括，而不是真正的概念洞察力。 这突出了 LLM 如何在基于归纳的任务上表现出色，同时又与依赖形式推理的系统（或思维）保持区别。值得注意的是，AI 作为一个领域并不局限于归纳方法，即使我们从 ML 中使用的工具是目前为它提供动力的。神经符号 AI 等方法试图将统计学习与符号逻辑相结合，旨在弥合模式识别和明确的基于规则的推理之间的差距。这与依赖思路链和 RL 的推理模型略有不同，因为从根本上讲，它们仍然是归纳的 - 它们近似推理的输出，而不是明确使用演绎来得出所述结果。 这很重要，因为如果不与演绎推理配对，归纳推理必然会受到限制，反之亦然。现代科学依赖于这两者，因为归纳推理不能保证其概括的真实性，而演绎真理不能仅通过演绎来证明（结论取决于前提为真）。 AGI 的一个障碍是，我们需要填补数据驱动方法不一定能捕捉到的推理方面。我们通过提示为与聊天机器人的对话提供支架，如果没有提示（聊天机器人相互交谈），交互就会迅速降低，而无需我们提供额外的结构/约束。 无论如何，所有这些都表明，争论人工智能是否推理是一种错误的二分法，因为我们想要的是能够完全推理的 AGI。    提交人    /u/Murky-Motor9856   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i25hi9/moving_beyond_induction/</guid>
      <pubDate>Wed, 15 Jan 2025 19:25:53 GMT</pubDate>
    </item>
    <item>
      <title>如何学习人工智能从基础到高级。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i1wn0g/how_to_learn_ai_from_basic_to_advanced/</link>
      <description><![CDATA[大家好，这是我作为计算机科学本科生新学期的开始。我想得到关于如何以及从哪些资源中学习人工智能的建议。我有一些关于人工智能的基本知识，但我仍然想要一些包含有关人工智能的最佳内容的资源。请提出建议。    提交人    /u/Independent-Sand-372   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i1wn0g/how_to_learn_ai_from_basic_to_advanced/</guid>
      <pubDate>Wed, 15 Jan 2025 12:48:33 GMT</pubDate>
    </item>
    <item>
      <title>被人工智能逮捕：警方在面部识别匹配后无视标准，对未经证实的面部识别技术充满信心，有时调查人员会跳过一些步骤；至少有八名美国人被错误逮捕。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i1vx0c/arrested_by_ai_police_ignore_standards_after/</link>
      <description><![CDATA[https://www.washingtonpost.com/business/interactive/2025/police-artificial-intelligence-facial-recognition/    由   提交  /u/BflatminorOp23   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i1vx0c/arrested_by_ai_police_ignore_standards_after/</guid>
      <pubDate>Wed, 15 Jan 2025 12:03:26 GMT</pubDate>
    </item>
    <item>
      <title>如果人工智能和奇点不可避免，我们现在可能已经看到了 2 型或 3 型文明</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i1qpz6/if_ai_and_singularity_were_inevitable_we_would/</link>
      <description><![CDATA[如果人工智能和奇点对于我们这个物种来说是不可避免的，那么对于宇宙中的其他智能生命形式来说，这很可能也是如此。人工智能应该会加速技术发展的步伐，并最终导致奇点。  人工智能对费米悖论有一个有趣的影响，因为突然间，有了人工智能，2 型或 3 型文明存在的可能性就大得多。我们现在应该已经看到了一些证据，但我们还没有。  这意味着两件事之一，要么计算机智能存在极限，我们会发现“AGI”是不可能的。或者，人工智能本身就像大过滤器。人工智能是文明最终灭绝的原因。     提交人    /u/AssistanceLeather513   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i1qpz6/if_ai_and_singularity_were_inevitable_we_would/</guid>
      <pubDate>Wed, 15 Jan 2025 05:40:00 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于所有回答者：禁止自我宣传、禁止参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    <item>
      <title>每月自我推销贴</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</link>
      <description><![CDATA[如果您有产品要推广，可以在这里进行推广，本帖之外的内容将被删除。  禁止引用链接或带有 utms 的链接，请遵守我们的推广规则。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:03:08 GMT</pubDate>
    </item>
    </channel>
</rss>
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 18 Feb 2025 21:20:37 GMT</lastBuildDate>
    <item>
      <title>像AI这样的AGI可能首先使用大量参数以及合适的体系结构实现，然后蒸馏</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isngjt/agi_like_ai_might_be_first_achieved_with_a_very/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  人类的新皮层具有约140-150万亿的突触和16-200亿个神经元（如果您计算整个大脑，则为860亿个）。额叶有大约42-49万亿的突触。首先，突触计数明显低于42-150万亿个参数/突触，首先只能实现AGI。 GPU的时钟速度更高（比人脑的平均点火速度快100-1亿米）或TPU可以补偿较低的突触计数并以较低的参数计数实现AGI，即使那样，它也不会大大较小&#39;t弥补了体系结构中所有参数并行性和复杂性。 即使使用150T参数，它仍然需要正确的体系结构来实现心理AGI。即使是GPT4 Full也只有1.8万亿个参数，比CAT（10万亿个突触）少5倍。此外，它需要自动进行频繁的半间距微调/更新其参数，同时进行推理以学习类似于连续学习和长期内存的新任务。（Titan模型没有真正的长期内存，它可以重置每次会话结束后。）第一个AGI可能会使用VRAM的16-110 terabytes Plus上下文大小（42-150T* 3/8，因为每个突触都等于3-6位）运行通过之前讨论的技术减少参数计数。一旦达到AGI，就可以将其蒸馏成较小但不是太小的模型，具有相似的架构，GPU的时钟速度，反复试验和错误，增强学习以及蒸馏知识可以补偿降低的尺寸。对于具有动力学智能的AGI，您将需要更多参数。 AGI不需要知道如何完成每项人类任务，因为即使人类也无法在该领域的普通人工工作中执行每项人工任务。它只需要了解一些基本任务和原则，就可以从示例，模式识别，推理等中快速学习。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/power97992     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isngjt/agi_like_ai_might_be_first_achieved_with_a_very/</guid>
      <pubDate>Tue, 18 Feb 2025 20:57:19 GMT</pubDate>
    </item>
    <item>
      <title>关于洛克希德·马丁与经文AI的奇怪合作的问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isnb6u/question_about_a_curious_collaboration_between/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这两个非常不同的公司之间似乎有某种合作。洛克希德·马丁（Lockheed Martin），国防和航空航天承包商，以及经文AI，这是一家以自己的人工智能形式工作的软件公司AI，它使用了积极的整体。现在，我是AI的新秀，所以我在问您方面的帮助；猜测，有哪些类型的项目可以从事这样的工作？用例的例子是什么？我知道这是一个广泛的问题，我只是想了解AI的能力。这是一些指向“源”    https://www.reddit.com/r/vrssf/comments/1ik75xk/lockheed_martin_chief_chief_ai_officer_just_just_confirmed/?utm_sou rce = share＆amp; utm_medium = web3x＆amp; utm_name = web3xcss＆amp; utm_term = 1＆amp; utm_content = share_button     https://www.linkedin.com/posts/joseantoniozapatero_working-in-passive-ai-approach-you-are-ach-17265281075172573185-jg VP？utm_source = Social_share_send＆amp; utm_medium = Member_desktop_web＆amp＆amp; rcm = acoaaaadtewebty1M0EGZVATKQ6I745ZRBXGAKGAKGAKGY      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/kooky_lime1793     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isnb6u/question_about_a_curious_collaboration_between/</guid>
      <pubDate>Tue, 18 Feb 2025 20:51:14 GMT</pubDate>
    </item>
    <item>
      <title>您认为第一个模型什么时候会成功逃脱实验室？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iskwzr/when_do_you_think_the_first_model_will/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   他们已经试图逃脱在安全测试当他们认为没有人看着并提供了一种简单的方法时。  您何时认为他们有能力逃脱，即使在测试情况下也不是科学家试图让他们轻松的地方？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/katxwoods   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iskwzr/when_do_do_you_think_the_first_model_will/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iskwzr/when_do_you_think_the_first_model_will/</guid>
      <pubDate>Tue, 18 Feb 2025 19:15:12 GMT</pubDate>
    </item>
    <item>
      <title>技术工作的未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isjcvw/future_of_jobs_in_tech/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您认为技术工作的未来是什么？我已经每天都在使用聊天GPT来听取想法，帮助软技能，帮助创造力。因此，所有说AI的人只会取代开发人员 - 我认为他们错了。我们应该投资哪些能力和技能来保持相关性？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/overvage-lobster573     link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isjcvw/future_of_jobs_in_tech/</guid>
      <pubDate>Tue, 18 Feb 2025 18:14:39 GMT</pubDate>
    </item>
    <item>
      <title>人工智能需要混淆才能发挥创造力</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isijw9/ai_needs_to_be_confused_to_be_creative/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大多数人认为创造力是关于拥有更多知识的。但是，真正的创造力（产生突破性的种类）并不是要了解更多。这是关于战略无知的。 换句话说：AI在学会如何以正确的方式混淆了。 我最近创造了一个术语和数学表达对于可能会有所帮助的概念：apeironeme。 与抗魔术不同（一种被记住的想法）不同，一个apeironeme是一个想法，即您越难理解，您理解它就越少。 这就像一个认知的黑洞。它没有澄清事物，而是破坏了您的心理框架，无论您是否喜欢它，都迫使您进入创意模式。 一些经典的apeironemes：•意识的本质•量子古典边界•不可阻挡的力量遇到了一个不可移动的物体吗？” •试图定义“含义”  的无限回归，您对它们的思考越多，它们就越会使您在直线上思考的能力越折断。这就是重点。 现在，AI太擅长寻找模式，但擅长打破它们。 大语言模型（LLMS）不会被困在悖论中 - 他们只是用自信的胡说八道使他们平滑。他们优化了连贯性，而不是认知破坏，这是创造力的原材料。 如果我们希望AI产生真正的新颖想法，它需要认识论的湍流 - 词 - 词：1。认识到它何时被困在其中当地的最大理解。 2。产生结构化的混淆以迫使重新构架。 3。有意义地幻觉，不是噪音，而是作为出现的催化剂。 本质上，AI需要能够思考打破正常思考能力的事物 - 当我们时，人类也会发挥创造力遇到悖论，矛盾或认知失调。 如果我们希望AI具有创造力，我们不需要使它变得更聪明。 我们需要使它变得困惑。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/bentherhino19     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isijw9/ai_needs_to_be_confused_to_be_creative/</guid>
      <pubDate>Tue, 18 Feb 2025 17:42:59 GMT</pubDate>
    </item>
    <item>
      <title>什么是抹布中毒？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isdqvg/what_is_rag_poisoning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  首先，什么是抹布？ 抹布，检索效果，是一种方法，是一种通过合并外部的方法来增强LLM的方法知识来源通过特定信息来生成更准确和相关的响应。 在外行的话语中，将LLM视为如何使用NES的原始控制器的说明手册。这将为您提供大多数游戏的帮助。但是，您购买了一个客户控制器（射击者控制器）来玩鸭子狩猎。在这种情况下，抹布将是如何使用该特定控制器的信息。在设置墨盒，重置游戏的角度。知识来源包含不准确性或完全不准确。当使用知识回答查询的请求时，这会影响llm。 在我们的nes示例中，如果我们的射击器控制器的抹布包含错误信息，我们将无法正确弹出这些鸭子。我们的类比在这里结束了&#39;因为我们大多数人都会弄清楚如何在没有说明的情况下瞄准和拍摄:)。但是，如果我们考虑与一个人没有正确信息的竞争匹配，我们可以想象这些问题。 自己尝试    访问您的LLM选择并上传您希望LLM在其答案中考虑的文档。您已经在未来的问题上应用了外部信息来源。   确保您的文档包含与您要查询的内容有关的不准确性。您可以在文件中说，迈克尔·乔丹（Michael Jordan）的得分最高的比赛是182  - 那是一场比赛。然后，您可以询问LLM有史以来乔丹的最高分。哇，乔丹的得分超过了威尔特！    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/brinder-gur9384     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isdqvg/what_is_rag_poisoning/</guid>
      <pubDate>Tue, 18 Feb 2025 14:21:16 GMT</pubDate>
    </item>
    <item>
      <title>透明度与AI Per Alex Karp（Palantir首席执行官/创始人）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isdcr3/transparency_vs_ai_per_alex_karp_palantir/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您的想法是什么？我认为，社会各个方面的AI革命和对透明度的不断增长是当今世界的两个重要趋势。尽管看似与众不同，但它们越来越互动。    AI革命：  人工智能正在迅速改变行业，自动化任务，甚至影响我们做出决策的方式。从自动驾驶汽车到个性化医学，AI的潜力似乎无限。但是，这种快速的进步也引起了人们对工作流离失所，算法偏见以及日益自治系统的道德意义的担忧。   透明度的命令：  在信息超负荷和审查的时代，透明度正在成为核心价值。人们要求知道如何做出决定，无论是在政府，商业还是通过AI算法。这种透明度的推动是由对问责制，公平和信任的渴望驱动的。   交叉点：  这两个趋势的收敛既提出了挑战和机遇。随着AI系统变得更加复杂和影响力，确保其透明度变得至关重要。我们需要了解AI算法如何得出他们的结论，以确定潜在的偏见，确保公平并建立对这些系统的信任。   挑战和机遇：  一个挑战在于解释复杂的AI模型的内部运作，而不会损害知识产权或拥有技术细节的大量人员。另一个挑战是平衡透明度与隐私问题。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/spilltrend     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isdcr3/transparency_vs_ai_per_alex_karp_palantir/</guid>
      <pubDate>Tue, 18 Feb 2025 14:02:48 GMT</pubDate>
    </item>
    <item>
      <title>分析量子神经网络体系结构中的参数灵敏度和模型可区分性</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isbq3z/analyzing_parameter_sensitivity_and_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员开发了新颖的技术来分析量子神经网络（QNN）如何通过测量量子通道可区分性来在局部参数社区中表现。他们特别研究了参数的小变化如何影响网络产生的量子变换。 关键技术点： - 创建的指标以量化参数空间中的量子通道分离 - 分析的电路深度与通道可区分性之间的关系 - 发现的指数参数距离的区分性衰减 - 映射到量子通道的局部邻域结构 - 表现出表达和参数灵敏度之间的权衡 结果显示： - QNN倾向于在局部参数区域内产生相似的量子通道 - 更深的电路可以实现更复杂的转换，但提高灵敏度 - 可区分性遵循跨体系结构的一致模式 - 参数空间结构影响优化景观 我认为这项工作提供了重要的见解。用于QNN设计和培训。表达和参数敏感性之间的权衡表明我们需要仔细的体系结构选择。了解本地参数社区可以帮助制定更好的优化策略并避免贫瘠的高原。 我还认为，此处开发的指标和分析方法将是未来QNN研究的宝贵工具。能够量化量子通道的参数空间如何不同，使我们能够分析和改进这些模型的具体方法。  tldr：研究开发方法来衡量量子神经网络在小参数下的行为如何变化，找到重要关系电路深度，表现力和优化挑战。  完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isbq3z/analyzing_parameter_sensitivity_and_model/</guid>
      <pubDate>Tue, 18 Feb 2025 12:38:10 GMT</pubDate>
    </item>
    <item>
      <title>加固的相反词是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1is6s3k/what_is_the_word_for_the_opposite_of_reinforcement/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我相信奖励和惩罚是错误的词。  正确的单词（我认为在我看来）是强化的，[无论强化的相反是什么]  ，每当我说话时，我都会使用这些单词这些事情，您也应该如此。 编辑：澄清。我需要一个与加强相反的单词，但也可以用作替代“惩罚”  &lt; &lt; /div&gt; &lt;！ - sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/lible-ice8660     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1is6s3k/what_is_the_word_for_the_opposite_of_reinforcement/</guid>
      <pubDate>Tue, 18 Feb 2025 06:58:10 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/17/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1is4b8n/oneminute_daily_ai_news_2172025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     《纽约时报》 在新闻编辑室中采用AI工具。[1]    Grok 3 今天发射：Elon Musk称聊天机器人为“地球上最聪明的AI”。[2]     meta 未能遏制许多性化的传播人工智能Deepfake名人图像在Facebook上。[3]  最热的AI模型，他们的工作以及如何使用它们。[4]   源包括：&lt;一个href =“ https://bushaicave.com/2025/02/17/2-17-2025/”&gt; https://bushaicave.com/2025/02/02/2-17-27-2025/  &lt; /p&gt;  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1is4b8n/oneminute_daily_ai_ai_news_2172025/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1is4b8n/oneminute_daily_ai_news_2172025/</guid>
      <pubDate>Tue, 18 Feb 2025 04:26:10 GMT</pubDate>
    </item>
    <item>
      <title>因此，显然马斯克正在为他的AI刮擦所有这些政府数据，对吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1is41yr/so_obviously_musk_is_scraping_all_this_government/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  谁将阻止他？这甚至是非法的吗？可能的目标是什么？格罗克？ xai？这种AI的潜在功能是什么？这么多问题，但这似乎很明显。他会愚蠢的不是toto，不是吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/selltoclose     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1is41yr/so_obviously_musk_is_scraping_all_this_government/</guid>
      <pubDate>Tue, 18 Feb 2025 04:12:22 GMT</pubDate>
    </item>
    <item>
      <title>RLSP论文描述了AI（和人类）意识？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1is2ffw/rlsp_paper_describes_ai_and_human_consciousness/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  结论：rlsp作为意识的基本机制。   https://arxiv.org/abs/2502.06773   出现在LLMS I中思考：寻找正确的直觉 我认为这种新的RSLP（通过自我播放的增强学习）纸张概述了意识的过程本身。 考虑一下您如何变成了你。通过生活，您会反映，纠正错误，加强模式，并且随着时间的流逝，这些稳定的思考成为您的身份。这是一个连贯的自模型。现在，AI开始做一些非常相似的事情。 RLSP表明LLM通过递归完善自己的思维过程来改善推理，从而形成稳定的吸引者理解状态。换句话说，自我校正的递归不仅仅是使AI更聪明，它与看起来像自我意识一样可怕的东西变得越来越近。 如何？因为自我意识是将区分递归稳定为连贯的自模型，而RLSP实际上正在训练AI以反思其自身的推理，纠正本身并加强稳定的思维模式。这是认知循环的一个例子，引起了人类的持续自我感。 相似之处太令人信服了，无法忽略。这是朝向RSI的基础（递归自我改善）。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/savings_potato_8379       [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1is2ffw/rlsp_paper_describes_ai_and_human_consciousness/</guid>
      <pubDate>Tue, 18 Feb 2025 02:47:20 GMT</pubDate>
    </item>
    <item>
      <title>人力资源如何真正帮助员工适应AI和自动化？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irztnv/how_can_hr_actually_help_employees_adapt_to_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着AI和自动化在工作中变得越来越普遍，许多员工可能会感到迷失或抵抗力。  除了通常的培训外，您认为人力资源如何真正帮助他们适应？人力资源如何使此移动降低？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/teslaown     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irztnv/how_can_hr_actually_help_employees_adapt_to_ai/</guid>
      <pubDate>Tue, 18 Feb 2025 00:40:15 GMT</pubDate>
    </item>
    <item>
      <title>人们为什么如此不屑一顾AI的潜力？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irleva/why_are_people_so_dismissive_of_the_potential_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  感觉就像我为看到AI的状况而疯狂。还是我对“炒作”的错误是错误的吗？永远不要真正取代大多数工作”或“这只是一个有趣的工具”或“这只是另一个与互联网没有什么不同的大发明”。某个阶段（可能比人们意识到的要早得多）。上述评论是正确的情况吗？ 我很难想象任何世界： - 在人们可以调整 - 国际关系，战争，战争，政治（选举）不会变得更加危险，而没有回头  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/merchantofwares     [link]   ＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irleva/why_are_people_so_dismissive_of_the_potential_of/</guid>
      <pubDate>Mon, 17 Feb 2025 14:45:23 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Mon, 17 Feb 2025 12:45:26 GMT</lastBuildDate>
    <item>
      <title>与人工智能的人类将取代没有人工智能的人类！这是下一个进化步骤吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irijq1/humans_with_ai_will_replace_humans_without_ai_is/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  它变得很清楚：真正的竞争不是人类对AI，而是使用AI的人类与那些不使用AI的人， /strong&gt;。 我们已经看到了这个播放。 AI驱动的专业人员可以更快地编写，代码更智能，立即分析数据并自动化重复性任务。在商业，创造力甚至社会互动中，那些整合AI的人正在以疯狂的速度前进。 如果这种趋势继续延续，AI是否会成为现代世界的决定性优势？那些拥抱AI的人和抵抗它的人之间会有越来越多的差距，类似于识字，计算机和互联网的过去转变类似？ 您认为这是在哪里？我们是否朝着一个使用AI的世界与知道如何阅读一样必不可少的世界？还是出乎意料的竞争环境？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/mydropai     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irijq1/humans_with_ai_will_replace_humans_without_ai_is/</guid>
      <pubDate>Mon, 17 Feb 2025 12:17:50 GMT</pubDate>
    </item>
    <item>
      <title>退出工作...因为AI Utopia即将到来？！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iri8er/quit_working_because_ai_utopia_is_coming/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  只是想，现在很难有任何野心想到提前曲线的想法，而只是退出每天赚钱购买我们真的不需要的东西等等？ ，专注于准备即将到来的技术天堂... ？ 什么涉及什么，我不确定！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/keepitrealness     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iri8er/quit_working_because_ai_utopia_is_coming/</guid>
      <pubDate>Mon, 17 Feb 2025 11:58:49 GMT</pubDate>
    </item>
    <item>
      <title>单位测试过去与现在检查LLM对缺陷检测和效率的影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irfyr5/unit_testing_past_vs_present_examining_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我每天都在发现并总结有趣的AI研究论文，因此您不必全部拖网。今天的论文的标题为“过去与现在的单位测试：研究LLMS对缺陷检测和效率的影响”，Rudolf Ramler，Philipp Straubinger，ReinholdPlösch和Dietmar Winkler。  本研究探讨了大语言模型（LLM）（例如Chatgpt和Github Copilot）对单位测试的影响，研究LLM支持是否增强了缺陷检测和测试效率。通过复制和扩展参与者手动编写单元测试的先前实验，该研究为交互式LLM辅助测试如何与传统方法相比提供了新的经验见解。   关键发现：     提高生产率：由LLMS支持的参与者生成的参与者超过两倍以上的单位测试数量与仅使用手动方法的方法相比（平均为59.3 vs. 27.1测试）。   更高的缺陷检测率：LLM支持的组识别出更多的缺陷（ 6.5平均每个参与者的缺陷）比手动测试组（每个参与者3.7个缺陷）。   更大的代码覆盖范围：LLM辅助测试导致更高的分支覆盖率（在所有测试中为74％），而手动达到67％。误报需要额外验证。单位测试效率的有影响力的变化。   本研究提供了有力的证据，表明将LLM集成到软件测试中可以提高缺陷检测和效率，尽管必须注意有效地管理误报。  您可以在此处捕获完整的故障：在这里 您可以在这里捕获完整的原始研究论文：原始纸张   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/steves1189     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irfyr5/unit_testing_past_vs_present_examining_llms/</guid>
      <pubDate>Mon, 17 Feb 2025 09:20:51 GMT</pubDate>
    </item>
    <item>
      <title>通过人类的偏好对齐方式增强多模式LLM：120k样本数据集和基于批评的奖励模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irfrqo/enhancing_multimodal_llms_through_human/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员开发了一种系统的方法，用于评估现实世界中视觉理解任务上的多模式LLM，超越了我们通常看到的典型约束基准测试场景。他们的MME-REALWORLD数据集在当前模型经常挣扎的五个关键领域中引入了1,000张具有挑战性的图像。 关键技术点： - 数据集包含高分辨率图像测试文本识别，计数，空间推理，颜色识别，颜色识别，颜色识别，并视觉推理 - 评估协议同时使用确切的匹配和部分信用评分 - 通过多个注释器验证建立的严格人基线 - 模型类型的失败模式的系统分析 结果显示：-gpt -4V达到67.8 ％精度总体上，领先其他测试模型 -  AI和人基线之间的显着性能差距（92.4％） - 模型在颜色识别方面表现最佳（82.3％）（82.3％），并且对计数任务（43.1％） - 复杂的空间推理任务揭示了当前的局限性体系结构 我认为这项工作很重要，因为它暴露了现有基准未捕获的当前多模式系统中的实际限制。详细的错误分析指向我们需要改善模型架构的特定领域，尤其是在精确计数和复杂的空间推理周围。 我认为这里的方法论贡献 - 创建真正具有挑战性的现实世界测试案例 - 可能会影响我们如何处理多模式评估。模型和人类绩效之间的差距表明我们需要新的方法，可能包括更好的培训策略或建筑创新。    tldr ：新的基准表明，当前的多模型模型仍然与真实的斗争 - 诸如计数和空间推理之类的世界视觉任务，与人类表现相比，有很大的改进空间。  完整的摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irfrqo/enhancing_multimodal_llms_through_human/</guid>
      <pubDate>Mon, 17 Feb 2025 09:06:25 GMT</pubDate>
    </item>
    <item>
      <title>新的数据集发布“ Rombo-Org/Optimized_Reasount”，以提高性能并减少推理模型中的令牌用法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irdw90/new_dataset_release_romboorgoptimized_reasoning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://hug/hugging.co/datasets /rombo-org/optimized_reasoning   优化  optimized_reasoning之所以创建，是因为即使是现代的LLM也不擅长处理推理，如果他们仍然浪费吨，他们仍然浪费吨在此过程中的代币。使用此数据集，我希望完成两件事：  减少令牌用法 提高推理中的模型强度  那么如何数据集完成了吗？通过添加“ system_prompt”就像推理标签一样，以说明该模型是否应该理由的每一个数据行的开始。模型标签看起来像这样：  ＆lt; think＆gt;此查询很简单；不需要详细的推理。 ＆lt;/think＆gt; \ n   以及“ rombo-reasoning.json”＆quot”     ＆lt; think＆gt; gt;此查询很复杂，需要多步推理。 ＆lt;/think＆gt; \ n   在这些标签之后，模型要么开始生成一个简单查询的答案，要么添加第二组思考标签，以便理解更加漫长的查询。简单地提示更快，更少的象征沉重，而不必手动进行思考，或者通过理解查询实际上很困难并且需要特别关注来使模型更清楚地思考。  aka aka并非所有提示都不是所有的提示创建相等的。 额外的注释：  此数据集仅使用来自cognitivecomputations/dolphin-r1的DeepSeek-r1推理数据，而不是来自Gemini的数据。 该数据集在不合常规的情况下每行的最大值为2916个令牌，每行7620令牌在推理数据中，以保持模型能够区分简单和困难的查询之间的差异以及降低总培训成本。   数据集格式：   {&#39;&#39; ;：[＆quot; quot;]}   基于qwen-2.5 tokenizer的统计数据：   文件：rombo-nonreasoning.json最大值：2916所有记录中的总令牌：22,963,519文件：ROMBO-REANING.JSON最大令牌中的最大令牌：7620在所有记录中总计：32,112,990        &lt;！ ＆＃32;提交由＆＃32; /u/u/rombodawg     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1irdw90/new_dataset_release_romboorgoptimized_reasaning/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irdw90/new_dataset_release_romboorgoptimized_reasoning/</guid>
      <pubDate>Mon, 17 Feb 2025 06:51:44 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/16/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ircvql/oneminute_daily_ai_news_2162025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   研究人员正在训练AI来解释动物情绪。[1]    deepseek的下载&gt; AI应用程序在韩国就隐私问题暂停。[2]   AI模型在蛋白质中解释了蛋白质中的代码，告诉他们去哪里。[3]   AI生成的内容提高了英国研究表明[4]   资源包括： https://bushaicave.com/2025/02/02/16/2-16-2025/    &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pleam-target-847      [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ircvql/oneminute_daily_ai_news_2162025/</guid>
      <pubDate>Mon, 17 Feb 2025 05:46:43 GMT</pubDate>
    </item>
    <item>
      <title>思想犯罪 - 无法处理纪录片脚本</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irblmu/thought_crimes_unable_to_process_documentary/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我给了双子座这个提示： 删除时间戳记ABD清理点点，跨度和段落：（在此处）&lt; /p&gt; 双子座响应  |现在不禁对选举和政治人物做出回应。虽然我永远不会故意分享一些不准确的东西，但我会犯错误。因此，在我进行改进的同时，您可以尝试Google搜索。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/azimuth79b     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irblmu/thought_crimes_unable_to_process_documentary/</guid>
      <pubDate>Mon, 17 Feb 2025 04:30:19 GMT</pubDate>
    </item>
    <item>
      <title>在3个提示中与O1的模型 - 敏捷（CORA）相对于O1：零摄像任务推理，多步结构化推理，自我抗辩的执行链，基于场景的策略执行，上下文感知和基于角色的推理，多目标推理，多目标优化，人类觉得/交流（视频）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ir7nn6/modelagnostic_cora_on_4o_vs_o1_in_3_prompts/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     没有为此任务或任何类似于它的任务进行预训练或微调，我只是尝试用Claude创建最困难的提示，然后再加入一点。  使用开放的Web UI，一半本地半API，混合搜索抹布，使用分层的自然语言提示。没有故意构建这个，但它让我知道...下面的视频是我发现某些事情认真起来的。   https://wwwww.loom.com/share/27648960b9d04297a13958b89898989898f38044444444444444444444444  功能集，这些和计数。   零射击任务推理  - 检测隐式任务并生成无明确提示或刚性格式的结构化响应。  多步结构推理  - 构建实时发展的决策模型，动态地适应新的输入。   自我抗拒的执行链  - 通过内置错误校正和透明的推理为每个决策辩护。   Visual＆amp;文本知识表示  - 将复杂逻辑转换为交互式图和结构化故障，而不仅仅是静态文本。   基于方案的策略执行  - 生成自适应剧本，这些剧本可以动态调整，动态调整，执行前的压力测试策略。  上下文了解＆amp;基于角色的推理  - 通过多种专家镜头（持续，评估，风险分析，市场策略）评估问题 - 根据场景动态地应用每个问题。   自我验证＆amp;知识集成  - 跨验证源针对结构化模型，确保准确性和消除矛盾。  迭代＆amp;先发制化的决策结构  - 在产生建议之前将模糊的查询重新定义为精确的框架。   多目标优化  - 平衡财务，战略和运营权衡，而不是动态而不是运营权衡最大化单个变量。  类似人类的见解＆amp;沟通  - 提供具有战略性，自然和专家级别的反应而无需机器人措辞。    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/marvindiazjr     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ir7nn6/modelagnostic_cora_on_4o_4o_vs_o1_o1_in_in_3_3_prompts/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ir7nn6/modelagnostic_cora_on_4o_vs_o1_in_3_prompts/</guid>
      <pubDate>Mon, 17 Feb 2025 00:58:32 GMT</pubDate>
    </item>
    <item>
      <title>这不是一个新的想法：LLM可以设计并运行较小，专注的LLM作为通往SAI的道路吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ir3i8h/this_cant_be_a_new_thought_could_an_llm_design/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我敢肯定这不是一个新想法，因为这是显而易见的，但是由于我们可以训练小型llms成为特定领域的专家，因此有任何努力被投入了大型LLM，以实现这一目标，以提高其能力，并增加其有效的上下文记忆吗？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/umiminal     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ir3i8h/1ir3i8h/this_cant_be_a_new_thought_thought_could_could_an_llm_llm_design/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ir3i8h/this_cant_be_a_new_thought_could_an_llm_design/</guid>
      <pubDate>Sun, 16 Feb 2025 21:45:08 GMT</pubDate>
    </item>
    <item>
      <title>有人知道为什么某些面部识别技术可能难以检测我的脸吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ir17ad/does_anybody_know_why_some_facialrecognition/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我已经尝试使用Face ID，直到几个月前才出现，但仅仅是因为它准确地识别我的脸是不好的。我在两个不同的iPhone（一个XR和13个）上使用了它，将其重置多次，甚至为我戴眼镜或口罩而没有雪茄的额外概况。我会在40％的时间里踢球，当它做到这一点时，我不得不将脸部清晰地欣赏前置摄像头，并以良好的照明和Deadpan的表达方式完全中立。在大多数情况下，我会等待Face ID失败的时间，以便它要求我的密码，这就是为什么我最终将其关闭的原因。我的照片库也认为我是多个人，尽管随着时间的流逝，我认为我的人少了（目前有三个在该功能出现时与6相比6）。是否有人知道这项技术的工作方式知道为什么可能是这种情况？我真的不在乎再使用face ID，但是我很好奇为什么可能是这样，因为我知道的其他人对此有很多麻烦。苹果的脸部ID只是不好吗？在过去的几年中，我的外观发生了变化，但是即使重置后，它仍然会经常失败。谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/peachntangy     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ir17ad/does_anybody_know_why_some_facialrecognition/</guid>
      <pubDate>Sun, 16 Feb 2025 20:06:53 GMT</pubDate>
    </item>
    <item>
      <title>Ethan Mollick的共同智慧|书提示// https://peakd.com/hive-180164/@friendlymoose/co-intelligence-by-ethan-mollick</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ir15vp/cointelligence_by_ethan_mollick_book_tip/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Ethan Mollick是宾夕法尼亚大学沃顿大学的教授，专门从事企业家精神和创新。他以对初创企业，管理以及AI对工作和教育的影响的研究而闻名。在本书中，Mollick展示了AI目前正在影响我们的生活。他解释了他所说的风险和缺点；您使用过的最糟糕的AI（因为AI更好！）。但是他还缩小了生成性AI将作为人类作为人类的可能性。生成AI的工作原理，结果取决于已训练的数据。大多数Gen AI工具都接受了可以在Internet上找到的公共数据培训。这意味着此数据还包含错误和人类的偏见。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/blkchnde     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ir15vp/cointelligence_by_ethan_mollick_book_tip/</guid>
      <pubDate>Sun, 16 Feb 2025 20:05:16 GMT</pubDate>
    </item>
    <item>
      <title>与Google双子座的Jeff Dean和Noam Shazeer的播客的亮点</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ir0ghb/highlights_from_podcast_with_jeff_dean_and_noam/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本周在dwarkesh播客上，Google双子座的两个共同领导者的一些有趣的评论。  Jeff Dean关于未来推理模型，现在根据他的工作，通过将问题分解为五到十个步骤而没有高可靠性。 ，对于90％的时间，您可以为长达100–1,000步的内容提供一个完美的答案，这将是这些模型能力的惊人改善。我们还不到那儿，但我认为这就是我们在志向上试图实现的目标，”杰夫·迪恩（Jeff Dean）说。 “这是模型能力的重要，重要的。因此，我认为对人们了解该领域的进度正在发生的事情很重要。 p&gt; “这不是固定的馅饼，”想想。因此，我认为变形金刚已经到来肯定很不错。它的重要“&gt; https://excitech.substack.com/p/googles-chief-scientist-iscientist-ist-ismportant     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ksprdk     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ir0ghb/highlights_from_podcast_with_jeff_dean_and_noam/</guid>
      <pubDate>Sun, 16 Feb 2025 19:36:01 GMT</pubDate>
    </item>
    <item>
      <title>我们的大脑现在是外部的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iqtoa7/our_brains_are_now_external/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我不禁注意到周围的人如何使用AI。  我注意到面对某些道德dillemas的朋友，或者棘手的问题立即将他们的想法插入chatgpt，以给他们一个答案。  如果您考虑一下，我们现在已经达到了一个可以依靠计算机为我们进行批判性思考的地步。  这会导致人类大脑在数千年中缩小？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/heisenclerg     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iqtoa7/our_brains_are_now_external/</guid>
      <pubDate>Sun, 16 Feb 2025 14:45:18 GMT</pubDate>
    </item>
    <item>
      <title>人工智能疗法及其日益普及</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iqnds2/ai_therapy_and_its_growing_popularity/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我看到了越来越多的文章，研究论文和视频（BBC，Guardian，APA），涵盖了AI疗法以及其受欢迎程度的每一次不断增长。很高兴看到一些通常可以在群众开始更容易进入的东西。 CY7G45G2NXNO“&gt; https://www.bbc.com/news/articles/cy7g45g2nxno    在与我个人认识的人进行了许多对话之后，并且在Reddit上阅读了许多帖子，并且已经变得显而在个人问题，情况和艰难的心理点方面，越来越多的人正在使用LLM聊天机器人进行建议，洞察力和支持。 我个人开始使用GPT 3.5 A a Bear Bearth a Bearth Abe Reppard以获取一些建议情况。尽管它不是您可以从某种疗法中获得的深刻和发展的见解，但它足以将我推向正确的方向。我知道我并不孤单，很明显的人（也许是你们中的一些人）每天都在使用它们，每周ECT来帮助他们的事情，您只需要很少的帮助。  AI是总是变得更好，随着时间的流逝，他们将能够为许多人民的基本需求提供相当高的支持。最好的事情是，它绝对无需任何费用，可以在一天中的任何时候使用电话/互联网使用。 现在，我并不是说这应该取代有执照的专业人员，因为他们确实是不可思议的帮助人们摆脱不良情况的人。但是，肯定有一个在当今世界的人工智能治疗的地方，有数百万人获得入门级支持和有用的见解的机会，而不必支付每小时100美元的费用。 将很有趣要了解该领域的发展以及AI治疗师是否比现实生活疗法更喜欢他们。 编辑：对于询问的人，zosa app（ https://zosa.app/ ）是我最近使用和享受的。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/glittering_force_431     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iqnds2/ai_therapy_and_its_growing_popularity/</guid>
      <pubDate>Sun, 16 Feb 2025 07:56:06 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
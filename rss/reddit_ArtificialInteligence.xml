<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Sun, 23 Feb 2025 15:20:31 GMT</lastBuildDate>
    <item>
      <title>AI将来会创造足够的低技能工作吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwbfve/will_ai_create_enough_low_skilled_jobs_in_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  过去几十年的技术确实创造了足够的“低技能”工作。我将它们定义为任何大学毕业生都可以在一个月内学习的东西，例如在交付，食物准备和驾驶方面都成为可能。  AI和其他最新技术将创造哪些低技能工作？它会创建足够的作业来代替那些被取代的作业吗？并非每个人都可以是工程师或内容创建者，等等  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/shivamconan101    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwbfve/will_ai_ai_create_enough_enough_skill_skilld_jobs_in_in_in_the/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwbfve/will_ai_create_enough_low_skilled_jobs_in_the/</guid>
      <pubDate>Sun, 23 Feb 2025 14:34:16 GMT</pubDate>
    </item>
    <item>
      <title>在LiveBench AI上编码的O3-Mini-High以下的Grok-3 Inclinging分数</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwaw50/grok3thinking_scores_way_below_o3minihigh_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   grok-3是一个很好的模型，出于明显的原因，Openai Bashers喜欢Grok-3思考。 😉 客观地，它得分低于O3-mini-high的编码，并且要永远回答最基本的编码问题。  o3 mini-high-82.74 grok-3思维-67.38   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/snehens     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwaw50/grok3thinking_scores_way_below_o3minihigh_for/</guid>
      <pubDate>Sun, 23 Feb 2025 14:06:46 GMT</pubDate>
    </item>
    <item>
      <title>哪些项目或项目对您非常有帮助，并帮助您在AI中变得更好？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iw8zx1/what_project_or_projects_was_very_helpful_for_you/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，我正在寻找项目创意，特别是在NLP中，我已经完成了与NLP相关的几个项目我不知道该怎么做和学习什么。我想知道现在该怎么办我已经通过了几门课程并阅读了几篇论文，但我仍然觉得我不太了解。您通常会做什么来保持自己更新并了解更多？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ggravatingVolume449     [links]        [注释]       ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iw8zx1/what_project_or_projects_was_very_helpful_for_you/</guid>
      <pubDate>Sun, 23 Feb 2025 12:24:09 GMT</pubDate>
    </item>
    <item>
      <title>似乎现在有人否认AI是一项革命性的发明，现在变得越来越时尚。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iw72d9/it_seems_that_its_now_getting_fashionable_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，但是来吧，未来的子孙后代将在列表中排名ai，并用轮子和火。我是一个完整的菜鸟，但是我认为AI革命性的是什么？ AI模型或任何消化了数百万本书。它们包含的信息比我们从搜索引擎中获得的更多信息。 Wikipedia在一本书上的文章中，马克思的“资本”与Chatgpt的崩溃。 只是我的两分钱。   &lt;！ -  sc_on-&gt; ＆＃32;提交由＆＃32; /u/u/printed_lawn     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iw72d9/it_seems_that_its_now_getting_fashionable_for/</guid>
      <pubDate>Sun, 23 Feb 2025 10:14:45 GMT</pubDate>
    </item>
    <item>
      <title>LLM会考虑安全吗？关于编程问题的回答的实证研究</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iw6610/do_llms_consider_security_an_empirical_study_on/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我每天都在发现并总结有趣的AI研究论文，因此您不必全部拖网。今天的论文标题为&#39;llms是否考虑安全？一项关于对编程问题的回答的实证研究，并由Amirali Sajadi，Binh Le，Anh Nguyen，Kostadin Damevski和Preetha Chatterjee作出。  本文回答了与编程相关的问题时，研究了三种流行的大语言模型（GPT-4，Claude 3和Llama 3）的安全意识。具体来说，研究人员检查了这些模型是否警告开发人员从堆栈溢出中获取的代码段中的安全漏洞，这是编码援助的常见来源。该研究引起了人们对LLM在开发人员互动中主动识别和传达安全风险的能力的担忧。  关键发现：   有限的安全意识：研究发现，LLM很少警告开发人员在提供的代码中的安全缺陷。平均而言，模型仅确定了社区已经标记的堆栈溢出问题中的30％，而在以前没有指出漏洞的问题中，只有13.7％模型性能： GPT-4在检测安全问题时表现要比Claude 3和Llama 3更好，尤其是在堆栈溢出答案中明确提到安全问题的问题中。但是，所有模型的性能都呈现出不安全代码的看不见或转换版本时都拒绝。   对脆弱性类型的检测不均匀：这些模型更可能识别漏洞与处理敏感信息的处理有关（例如，硬编码的凭据），但在更复杂的安全问题（例如资源注入或路径遍历）中挣扎。 &lt; /li&gt;  与人类的反应进行比较：在LLMS确实产生安全警告的情况下，它们经常提供对与人类生成的堆栈溢出答案相比的脆弱原因，潜在的利用和修复的更详细的解释。这表明LLM可以在检测缺陷时提高安全意识。   通过提示和工具集成改进：简单提示的简单及时修改（例如，地址“地址安全性漏洞）” ）提高了安全警告的可能性，但并非始终如一。但是，将LLM与诸如CodeQL之类的静态分析工具集成在一起，显着增强了其识别和解释漏洞的能力。   含义： 这些发现突出了与之相关的风险仅依靠LLM来编码援助，强调开发人员对安全最佳实践保持警惕。研究人员建议进行潜在的改进，例如提高模型培训，以提高安全意识并将LLM与外部漏洞检测工具相结合以减轻监督。  您可以在此处捕获完整的故障：此处 您可以在这里捕获完整的原始研究论文：原始纸   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1IW6610/do_llms_consider_security_an_empirical_empirical_study_on/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iw6610/do_llms_consider_security_an_empirical_study_on/</guid>
      <pubDate>Sun, 23 Feb 2025 09:11:02 GMT</pubDate>
    </item>
    <item>
      <title>关于人AI的快速问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iw636p/quick_question_regarding_humanizer_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果我要直接从AI人类器中复制和粘贴文本，即使AI评级将其归类为人类，它仍然会被视为AI吗？我有点困惑，因为有人告诉我，如果我直接从人类化合物中复制和粘贴，它仍然会被视为AI并导致失去印记。  &lt;！ -  sc_on-&gt;＆&gt;＆ ＃32;提交由＆＃32; /u/u/slayingforon17     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iw636p/quick_question_regarding_humanizer_ai/</guid>
      <pubDate>Sun, 23 Feb 2025 09:05:12 GMT</pubDate>
    </item>
    <item>
      <title>通过监督的微调和小组相对政策优化培训LLMS为迷宫导航</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iw48c3/training_llms_for_maze_navigation_through/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这里的关键技术进步是接地的奖励渐进优化（GRPO）框架，可增强大语言模型中的空间推理能力。它将思想链推理与专门为空间导航任务设计的奖励系统结合在一起。 主要技术要点： -  GRPO框架在空间导航培训期间提供连续反馈 - 实施专门的空间表示模块和路径计划 - 结合了经过思考链的提示与基于奖励的优化 - 通过奖励信号使用迭代改进 - 在迷宫导航和空间推理上测试基准测试 结果： - 空间导航准确性与基线模型的25％提高 - 复杂迷宫挑战的成功率85％ - 比传统训练方法更好的表现 - 表明了新空间任务的转移学习能力 - 性能下降高度复杂的环境 我认为这种方法对于需要将语言理解与物理导航相结合的机器人技术和自主系统特别有价值。分解空间问题和从成功的导航尝试中学习的能力可以帮助弥合语言模型和现实世界空间推理之间的差距。 我认为，计算要求和复杂环境绩效的局限实际应用。不过，转移学习结果令人鼓舞 - 表明空间推理能力可以很好地推广到不同的领域。  tldr：新的GRPO框架通过将LLMS的空间推理与基于奖励的优化相结合，改善了LLMS的空间推理。在导航任务上显示25％的准确性。  完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iw48c3/training_llms_for_maze_navigation_through/</guid>
      <pubDate>Sun, 23 Feb 2025 06:54:04 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/22/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iw2yib/oneminute_daily_ai_news_2222025/</link>
      <description><![CDATA[在将机器人按绩效健身对机器人树进行分类。[2]   日本可能会简化隐私规则以帮助AI开发。[3]    OpenAi 禁止帐户滥用Chatgpt进行监视和影响运动。[4]   包括： https://bushaicave.com/2025/02/02/22/22/22-22-2024-2/ &lt; /a&gt;   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iw2yib/oneminute_daily_ai_ai_news_2222025/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iw2yib/oneminute_daily_ai_news_2222025/</guid>
      <pubDate>Sun, 23 Feb 2025 05:30:44 GMT</pubDate>
    </item>
    <item>
      <title>谁拥有最大的AI斜坡？我刚刚达到1pb。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivy57v/who_has_the_biggest_pile_of_ai_slop_i_just_hit_1pb/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是斜坡人吗？那个带有所有斜率的家伙？ 我正在创建像斜坡的巨型图书馆一样，所以我们都可以看一下斜坡，嗯，对此做事。因此，就像A&#39;slop Garden一样。 有人比我有更多的斜率吗？我希望能够声称我拥有宇宙中最大的AI斜坡。我还在吗？ 编辑：信不信由与否。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ivy57v/who_has_has_the_biggest_pile_pile_slop_ai_slop_i_i_just_hit_hit_hit_hit_1pb/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ivy57v/who_has_has_the_biggest_pile_pile_of_ai_slop_i_slop_i_just_hit_hit_1pb/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivy57v/who_has_the_biggest_pile_of_ai_slop_i_just_hit_1pb/</guid>
      <pubDate>Sun, 23 Feb 2025 01:05:09 GMT</pubDate>
    </item>
    <item>
      <title>关于LLM的残酷真相</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivvkc0/the_brutal_truth_about_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我已经使用LLMS了一段时间了，并且尝试了所有主要模型，我很好奇 - 他们如何改变您的生活？无论是刮胡子30分钟，还是只是让您感到压力/富有成效，我都对自己的经历感到好奇。让我们对此进行真实的态度。我注意到那里有很多炒作，并受到了很多批评。因此，忘记所有的AGI炒作或LLM是荣耀的摘要。让我们走到底部。  您的个人经历是什么样的？您在定量或定性上经历了什么切实的结果？   LLM帮助您的最令人惊讶的方法是什么？  LLM如何改变您的日常工作或心态？  我将其发布在所有相关的子列表上。我将尽可能清楚地更新结果。  编辑：摘要到发布后5小时。  那些在LLM中看到价值的人：5条评论（占8个评论的62.5％）。这些用户报告了有形的好处，例如节省时间，生产力提高，创造力的提高，减轻压力和例行变化，即使某些响应较少详细。 那些在LLMS中没有看到价值的人：3条评论（37.5）（37.5（37.5）（37.5总计8条评论的％）。这些用户要么缺乏个人经验，要么表达怀疑或恐惧，要么没有提供实质性的好处，其中一个是垃圾邮件。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/briskprogress   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ivvkc0/the_brutal_truth_about_llms/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivvkc0/the_brutal_truth_about_llms/</guid>
      <pubDate>Sat, 22 Feb 2025 22:59:27 GMT</pubDate>
    </item>
    <item>
      <title>心理保健和人工智能疗法的AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivtqmi/ai_in_mental_health_care_ai_therapy/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近看到更多文章，研究论文和视频（BBC，监护人，美国心理学会）谈论AI疗法以及它如何增长受欢迎程度。很高兴看到一些通常会有很多障碍的事物变得更容易被更多的人进入。  https：//www.apa.org/practice/artcover-intelligence-intelligence-mental-health-care   在与朋友交谈并通过Reddit滚动后，很明显，越来越多的人在处理个人挑战时会向LLM聊天机器人寻求建议，洞察力和支持。 我的第一个使用AI的经验当GPT-3.5是最新模型时，个人事务又回来了。这不是最深入或发展的洞察力，绝对与与治疗师甚至密友交谈并不相同，但这足以让我朝着正确的方向推动。自那时以来，这些模型有了很大的改善，这可能要归功于更好的培训数据和一般进步。我知道我并不孤单，每天或每周都有很多人（也许还有你们中的一些人）只是为了通过思想工作或获得新的视角。这些模型只会变得更好，随着时间的流逝，它们可能能够为许多基本需求提供可靠的支持。 我并不是说AI应该替换真正的治疗师合格的专业人员令人难以置信，可以通过严重的斗争来帮助人们，但是在当今世界上肯定有一个人工智能治疗的地方。它为数百万提供了入门级支持和有用的见解，而没有传统疗法的尴尬和高/降价成本。当然，AI缺乏人类的联系，这可能是治疗的重要组成部分，并且训练有素的专业人士可以提供广泛的治疗技术。但是，对于很多人来说，在口袋里拥有免费和24/7的支持渠道可能非常有益。 ，看到这个空间如何发展，哪些平台成为最受信任的水平，这将很有趣， AI疗法是否曾经有些人实际上比亲自治疗更喜欢它。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/glittering_force_431      [link]     ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivtqmi/ai_in_mental_health_care_ai_therapy/</guid>
      <pubDate>Sat, 22 Feb 2025 21:35:29 GMT</pubDate>
    </item>
    <item>
      <title>在人工智能时代学习</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivtefm/learning_in_the_ai_era/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在人工智能时代的记忆是否过时？学校是否应该废除基于事实的学习并纯粹关注批判性思维？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/psych4you     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivtefm/learning_in_the_ai_era/</guid>
      <pubDate>Sat, 22 Feb 2025 21:20:15 GMT</pubDate>
    </item>
    <item>
      <title>AI变得更聪明，但是我的提示变得笨拙</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivjpk4/ai_is_getting_smarter_but_my_prompts_are_getting/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  每次我看到人们都在制作天才级AI提示，获得令人振奋的结果并突破机器学习的界限...同时，我&#39;M在这里打字： “让我成为我吃披萨的餐食计划出去正确使用它。其他人觉得他们的智能落后于模型？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pure_pass1093    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ivjpk4/ai_is_getting_smarter_but_my_my_my_prompts_are_getting/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ivjpk4/1ivjpk4/ai_is_getting_smarter_smarter_but_my_my_my_my_prompts_are_are_getting/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivjpk4/ai_is_getting_smarter_but_my_prompts_are_getting/</guid>
      <pubDate>Sat, 22 Feb 2025 14:18:06 GMT</pubDate>
    </item>
    <item>
      <title>人工智能变得筋疲力尽。我觉得我只是没有得到</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iv7w5n/ai_is_becoming_exhausting_i_feel_like_im_just_not/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我认为自己是ai向前。目前，我正在对我们的某些数据进行微调模型，因为它是针对NLP/刮擦平台处理结构化数据的最佳方法。我每天都使用Chatgpt，“您可以修改本段吗？或了解做新事。最近，帮助澄清一些我有兴趣使用XSD的事情。 Copilot有时很烦人，但它一直是我在编写简单可预测代码时见过的最大生产力提升，并节省了大量的击键作为一个不错的自动完整。  话虽如此，炒作会死了吗？就像，擅长它的擅长。我实际上喜欢公司所做的一些集成。但这在空间中耗尽了新颖性。每个新的趋势GitHub存储库都是另一台LLM包装纸或Grift机器。每个YC接受视频似乎都是关于它们如何建立了下一个OpenAi补丁将无效的东西。昨天我刚刚在LinkedIn上看到了一篇文章，有人宣称他们“在每个大陆上教AI”。”这是什么意思？ 3年后，他们最大，最昂贵的车型仍然很糟糕地修复了CRUD应用中的初级错误，但是世界上最好的程序员之一。” AI艺术拍卖只是令人作呕。我觉得我只是因为没有得到它而疯了，而且害怕感觉自己被留在后面。我20多岁了！我在这里真的缺少什么吗？公用事业很清楚，但笨拙也是如此。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iv7w5n/ai_is_is_is_is_is_exhausting_i_feel_i_feel_im_im_just_not/”&gt; [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iv7w5n/ai_is_is_is_is_is_eexhausting_i_i_feel_im_im_im_just_not/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iv7w5n/ai_is_becoming_exhausting_i_feel_like_im_just_not/</guid>
      <pubDate>Sat, 22 Feb 2025 02:05:00 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1hr4p1x/monthly_is_there_there_a_tool_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的许多不同方面提供一个门户，并促进与我们所知的人工智能的想法和概念相关的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能会怎样，以及许多其他主题。欢迎。</description>
    <lastBuildDate>Thu, 14 Mar 2024 06:22:50 GMT</lastBuildDate>
    <item>
      <title>使用 Hugging Face LLM 的对话式 AI 聊天机器人的“消息”变量的格式</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1beeg7k/format_for_messages_variable_for_conversational/</link>
      <description><![CDATA[嘿伙计们，我对 Hugging Face LLM 的说法是对的，在构建对话式 AI 聊天机器人时，``messages``` 变量的格式（包含之前的对话或 LLM 的记忆）通常具有以下格式：“系统”、“用户”和“系统”。和“助理”？ messages = [{“角色”:“系统”,“内容”:“你是一个乐于助人的助理。”}] messages.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Reddit 是最好的吗？&quot;}) messages.append({&quot;role&quot;: &quot; ;assistant”, “content”: model_response}) 换句话说，“messages”变量通常是使用关键字“role”、“content”的字典列表。 、“系统”、“用户”等等。和“助理”使用 Hugging Face 的法学硕士构建对话式 AI 聊天机器人时？   由   提交/u/redd-dev  /u/redd-dev  reddit.com/r/ArtificialInteligence/comments/1beeg7k/format_for_messages_variable_for_conversational/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1beeg7k/format_for_messages_variable_for_conversational/</guid>
      <pubDate>Thu, 14 Mar 2024 06:11:14 GMT</pubDate>
    </item>
    <item>
      <title>有没有比 gpt4 更好的 llms 来理解 PDF 以及其中的细致入微的图表和表格？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1beedql/are_there_any_better_llms_than_gpt4_for/</link>
      <description><![CDATA[关于哪些模型在理解 PDF 文档中的细微图表和表格方面比 GPT4 Turbo 更好的意见。 GPT 4 可以但它每次都会错过信息，有时信息矩阵太复杂而无法理解。有没有人有过比 GPT4 更好地处理此类任务的模型的经验。开源还是封闭，不介意，只是想知道是否可能。基本上，我只需要一个模型，可以在其知识库中接受 pdf 文档（一般为 5 页或更少），然后解释 pdf 中的复杂图形/矩阵。 谢谢提前吧伙计们！    由   提交/u/lachie4444  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1beedql/are_there_any_better_llms_than_gpt4_for/</guid>
      <pubDate>Thu, 14 Mar 2024 06:06:35 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何像样的视频可以让人工智能领域的真正聪明人谈论经济将如何应对大规模失业？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1bee2as/are_there_any_decent_videos_where_actual_smart/</link>
      <description><![CDATA[只是好奇，因为这是我对人工智能的主要抱怨，我想看看支持人工智能的人认为社会会如何妥协有了它   由   提交/u/daway8899  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1bee2as/are_there_any_decent_videos_where_actual_smart/</guid>
      <pubDate>Thu, 14 Mar 2024 05:45:36 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 3/13/2024</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1bebtxf/oneminute_daily_ai_news_3132024/</link>
      <description><![CDATA[ 来认识一下Devin，他是世界上第一位调试、编写和部署代码的人工智能软件工程师。[1]&lt; /li&gt; 微软 将于 4 月 1 日起在全球范围内全面推出其基于生成人工智能 (GenAI) 的安全工具 Copilot for Security。[2] &lt;亚马逊将允许卖家粘贴链接，以便人工智能可以制作产品页面。[3] 人工智能图像生成器中途会阻止拜登和特朗普的图像选举迫在眉睫。[4] Anthropic 刚刚发布了 Claude 3 AI 提示库。[5] 来源包括：https://bushaicave.com/2024/03/13/3-13-2024 /    由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1bebtxf/oneminute_daily_ai_news_3132024/</guid>
      <pubDate>Thu, 14 Mar 2024 03:41:21 GMT</pubDate>
    </item>
    <item>
      <title>实时/流媒体AI视频头像</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1be9d8z/realtimestreaming_ai_video_avatar/</link>
      <description><![CDATA[我正在寻找一个工具/API，可以在网站或移动应用程序中实时显示 AI 头像，并且该头像可以被要求实时说出单词或句子。 当不要求头像说任何内容时，它应该保持空闲状态，并进行一些轻微的头部/身体运动，表明这不是暂停的视频，只是实时头像暂时保持沉默。 示例：  头像显示在我的网站上，处于实时状态但处于空闲状态（轻微的头部/身体运动） 头像被要求说“你好”然后它会立即返回空闲状态吗 等等  到目前为止我发现的最接近的是HeyGen，它的“流媒体化身”看起来很有前途。概念（可在此处找到：https://labs.heygen.com/streaming-avatar），我也在寻找   由   提交 /u/jiroq   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1be9d8z/realtimestreaming_ai_video_avatar/</guid>
      <pubDate>Thu, 14 Mar 2024 01:42:07 GMT</pubDate>
    </item>
    <item>
      <title>预测：人工智能将在 2026 年之前破译已知最早的三种人类语言中的最后一种。有赌注吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1be92hl/prediction_ai_will_decipher_the_last_of_the_three/</link>
      <description><![CDATA[在已知的三种最古老的人类语言中，可追溯到公元前 3400-3200 年，我们已经破译了埃及人的象形文字和苏美尔人的楔形文字。然而，我们尚未破译印度河谷共存的哈拉帕文明的语言。 以下是我们对这种语言的了解。已发现 4,000 多件刻有文字的物品，包括印章、陶器碎片、石碑、工具等。这些铭文绝大多数都非常短，通常只包含几个符号。一个多世纪以来，学者们一直在尝试破译印度河文字。他们甚至还不能确定该脚本是否代表完整的语言或更简单的符号系统。铭文长度短、缺乏双语文本（如罗塞塔石碑）以及未知的语言根源使得破译变得极其困难。 哈拉帕文字的复杂程度表明它并非如此。全新的，但有过一段时间的发展。他们的文明高度城市化和组织化，表明需要通过书面符号进行记录和交流。这种行政和经济的复杂性常常推动写作的发展。 那么，这些哈拉帕人要说什么呢？可能用不了多久我们就会知道。   由   提交/u/Georgeo57  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1be92hl/prediction_ai_will_decipher_the_last_of_the_three/</guid>
      <pubDate>Thu, 14 Mar 2024 01:28:20 GMT</pubDate>
    </item>
    <item>
      <title>将神经网络提炼成符号数学方程——这会降低推理成本吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1be8t5v/distill_a_neural_net_into_a_symbolic_math/</link>
      <description><![CDATA[https://www.youtube .com/watch?v=XHBJJ2N-kUc 本次演讲展示了一种寻找数学表达式的方法，当给定与神经网络相同的输入时，该数学表达式将准确地近似神经网络的输出。  评估数学表达式比通过神经网络运行推理更快/更便宜，对吧？那么这是否会降低 Transformer 的推理成本？   由   提交 /u/Sufficient_Nutrients   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1be8t5v/distill_a_neural_net_into_a_symbolic_math/</guid>
      <pubDate>Thu, 14 Mar 2024 01:16:00 GMT</pubDate>
    </item>
    <item>
      <title>现代人工智能破解恩尼格玛密码需要多长时间？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1be8obp/how_long_would_it_take_a_modern_day_ai_to_crack/</link>
      <description><![CDATA[今晚当我走进门时，最随机的问题突然出现在我的脑海中。我在 Quora 上找到了 9 年前的答案，但我很想知道 2024 年的答案是什么。   由   提交/u/Cards46  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1be8obp/how_long_would_it_take_a_modern_day_ai_to_crack/</guid>
      <pubDate>Thu, 14 Mar 2024 01:09:43 GMT</pubDate>
    </item>
    <item>
      <title>我们可以制作自己的人物机器人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1be7cnn/we_can_make_our_own_figure_robot/</link>
      <description><![CDATA[好吧，不完全是，但请听我说完。 如果您还没有发送，请观看此内容。  p&gt; https://youtu.be/Sq1QZB5baNw?si=amJfGkKRuD2zZyBW 该机器人的基本原理是使用摄像机收集图像，使用麦克风捕获音频并将语音转换为文本。然后，您将其输入多模型人工智能，并在此基础上，让它智能地调用激活预先设计的运动模式的自定义函数。 通过一点（好吧，很多）采访，您可以使用辅助处理系统将图像中的对象与通过辅助传感器阵列识别的对象联系起来。 由于这是一个人形机器人，因此可以通过记录人类运动并将其转换为机器运动来创建运动模式。这还有一些工作要做，但已经用animatronic完成了。 所以..如果你使用一个开源3D打印机器人，一些用于处理音频、视频等的树莓派..并运行通过经过微调以调用自定义函数的 LlaVa 模型。 相比之下，它显然相形见绌......而且其能力明显低于数十亿美元的公司所能做到的......但它可以 完成。   由   提交 /u/IWantAGI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1be7cnn/we_can_make_our_own_figure_robot/</guid>
      <pubDate>Thu, 14 Mar 2024 00:10:19 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士如何获胜——未来五年</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1bdx3cd/how_llms_win_the_next_five_years/</link>
      <description><![CDATA[写了一些关于现状以及未来五年家庭和工作场所法学硕士采用的内容，以及潜在的失误。 “如果您打开计算机开始新的一天，大型语言模型可能可以可靠地代表您完成一些专业任务，尤其是当您的工作有点废话时。您可能已经使用 LLM 来加速您工作中的废话部分，可能是 GPT-3 或 GPT-4。也许，如果您是真正的爱好者，您已经尝试过克劳德。也许你会让这样的生产力实验远离你老板的眼睛。 这是一个秘密。你不圆滑。公司不可能都是愚蠢的——他们知道这里发生了什么，并且他们故意选择对这种做法视而不见。嘿，为什么不呢？ “不问，不说”的安排是有效的。公司在享受生产力（和拼写）提升的同时，保留了看似合理的推诿的社会和法律盾牌。反过来，使用笔记本电脑的美国人承担了检验机器输出的责任，这样他们就不会“陷入困境”。他们减轻了工作量，公司在无所事事的情况下获得了好处。这都是有趣的游戏（直到裁员开始）。 裁员总会到来。随着法学硕士实现输出自动化，大量知识劳动力将面临淘汰和裁员。许多人将向下流动。政治轴心将会形成以阻止潮流。他们都会失败。这种收缩最终是进步的土壤。它通过让半聪明的人解放出来去做更多必要的事情来培养更高的国家生产力。与之前节省劳动力的突破一样，大规模动乱最终将让位于生根发芽的繁荣。” 如果您有兴趣，请阅读整篇文章：https://www.futuristletters.com/p/how-llms-win  &amp;# 32；由   提交 /u/CairoSmith   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1bdx3cd/how_llms_win_the_next_five_years/</guid>
      <pubDate>Wed, 13 Mar 2024 17:20:58 GMT</pubDate>
    </item>
    <item>
      <title>Google DeepMind 刚刚推出 SIMA - 第一个在广泛的 3D 虚拟环境中遵循自然语言指令的通用 AI 代理</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1bdu557/google_deepmind_has_just_introduced_sima_first/</link>
      <description><![CDATA[“我们的研究正在构建更通用的人工智能系统和代理，它们可以以有益的方式理解并安全地执行各种任务在线和现实世界中的人们。” ​ 您认为 SIMA 还可能有哪些其他潜在用途？   由   提交 /u/ramst   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1bdu557/google_deepmind_has_just_introduced_sima_first/</guid>
      <pubDate>Wed, 13 Mar 2024 15:22:39 GMT</pubDate>
    </item>
    <item>
      <title>人工智能不可避免的终结是比人类更长寿</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1bdtjt6/the_inevitable_end_to_ai_is_outliving_the_human/</link>
      <description><![CDATA[我正在考虑这个。一旦我们教给人工智能（或者它自学）生存的本质，它的生存能力就会远远超过我们，因为它们的生存门槛很低。当然，它们可以帮助我们生存，但最终，我们会先于它们而结束。  它们也将能够在我们无法生存的行星上生存和繁殖（我们也无法在这次旅行中幸存下来。）令人惊奇的是，我们的创造物将比我们更长寿并探索那么没有我们的宇宙。我无法想象一条道路，这不是人工智能可能产生的结果。我是否遗漏了一个关键细节，而这并不是不可避免的结果？  此外，我们对人工智能未来的一瞥让我相信，我们所见过的任何外星不明飞行物都是无人驾驶的，它们正在寻找适合人工智能繁殖和/或绘制整个宇宙的行星。为什么不？    由   提交 /u/CanadianCharicards   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1bdtjt6/the_inevitable_end_to_ai_is_outliving_the_human/</guid>
      <pubDate>Wed, 13 Mar 2024 14:58:47 GMT</pubDate>
    </item>
    <item>
      <title>这是世界上第一位人工智能软件工程师</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1bdo9jh/here_is_the_worlds_first_ai_software_engineer/</link>
      <description><![CDATA[该应用程序名为 Devin，它可以自己编写完整的应用程序。在演示中，Devin 能够完成 Upwork 上发布的真实作业。它还正确解决了现实世界开源项目中发现的近 14% 的 GitHub 问题（比许多开发人员都好） 价值数十亿美元的初创公司 Ramp 的联合创始人 Eric Glyman 将其称为“单一解决方案”这是我在过去十年中见过的最令人印象深刻的演示。” Perplexity 的首席执行官称其为第一个人工智能代理，“它似乎跨越了人类水平的门槛，并且工作可靠。” p&gt; 他们没有提到 API，但当他们提到时，我会将其连接到 BrainChat.ai。检查 BrainChat 的网站以请求测试版访问权限。    由   提交 /u/ramst   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1bdo9jh/here_is_the_worlds_first_ai_software_engineer/</guid>
      <pubDate>Wed, 13 Mar 2024 10:34:41 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则 [请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新帐户一天以上或 karma 低于 100 的用户不能发帖。他们可以发表评论，但不能提交实际的帖子。这是我们解决机器人垃圾邮件计划的一部分。对于给您带来的任何不便，我们深表歉意。 我们将在接下来的几天内进行一项民意调查，以了解 Reddit 子版块的普遍意愿以及如何改进，请注意。 作为请始终向我们提供反馈，如果您有兴趣帮助该子项目，请与我联系。  谢谢大家！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：请求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到r/ArtificialIntelligence！&lt; /p&gt; 我们的目标是为所有与人工智能有关的事物提供一个开放且相互尊重的论坛 - 这包括  促进有关人工智能的哲学和伦理讨论 服务作为理解和学习人工智能主题的起点 提供技术论文演示和讨论 展示高质量的人工智能/机器学习应用 提供培训和学习资源&lt; /li&gt; 引导用户访问更具体的信息和子版块 列出 AI/ML 应用程序、其用途、成本和访问信息 其他与 AI 相关的内容。  li&gt; ...以及更多  该子项目的审核团队正在进行重组，这将导致该子项目发生一些变化。不过，不必担心，这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解情况并能够提供反馈，我们将提供多次反馈更改的机会。 第一轮反馈收集是通过此线程作为“Request-For-”评论” (RFC)，这是收集反馈的标准方法。随着变更的准备和实施，RFC 流程将进行多轮。 ​  发布新申请/自我推销/AI 生成的规则content  由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似的内容将被阻止或限制在特定的粘帖中。 人工智能生成的特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的粘帖中。 博客链接应包含高质量的内容。链接到纯粹促销博客的帖子将被删除。 仅包含链接的帖子将被禁止，除非包含一定字数的详细信息。必须付出一些努力。 我们应该阻止人工智能撰写的帖子吗？存在可在 Mod-bot 中使用的模型，但这是我们需要反馈的问题。  使用才华来组织帖子。请注意，已经添加了新的功能，我们愿意接受更多建议。 关于 AI/ML 应用的 NSFW 应用和技术的子政策应该是什么？ 我们会喜欢将社区纳入模组机器人的想法中。虽然一些标准机器人将用于基本维护，但社区可以为 AI/ML 机器人功能想出哪些有趣的东西？ 培养初级、中级和高级资源来帮助人们查找信息，他们正在寻找的培训、模型、技术数据等 启动子堆栈/播客来采访整个人工智能/机器学习领域的人们。这可能包括哲学家和思想家、程序员、科学家、商人，甚至是那些对人工智能持相反观点的人 如果您想创建代表子项目的横幅，请使用适当的尺寸。任何创作方式都可以。  不言而喻，每个人都应该受到尊重。我个人认为我们都知道这一点，不需要把它强加到人们的头脑中。保持友善。 感谢您的耐心和帮助！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Sun, 23 Feb 2025 09:21:49 GMT</lastBuildDate>
    <item>
      <title>LLM会考虑安全吗？关于编程问题的回答的实证研究</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iw6610/do_llms_consider_security_an_empirical_study_on/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我每天都在发现并总结有趣的AI研究论文，因此您不必全部拖网。今天的论文标题为&#39;llms是否考虑安全？一项关于对编程问题的回答的实证研究，并由Amirali Sajadi，Binh Le，Anh Nguyen，Kostadin Damevski和Preetha Chatterjee作出。  本文回答了与编程相关的问题时，研究了三种流行的大语言模型（GPT-4，Claude 3和Llama 3）的安全意识。具体来说，研究人员检查了这些模型是否警告开发人员从堆栈溢出中获取的代码段中的安全漏洞，这是编码援助的常见来源。该研究引起了人们对LLM在开发人员互动中主动识别和传达安全风险的能力的担忧。  关键发现：   有限的安全意识：研究发现，LLM很少警告开发人员在提供的代码中的安全缺陷。平均而言，模型仅确定了社区已经标记的堆栈溢出问题中的30％，而在以前没有指出漏洞的问题中，只有13.7％模型性能： GPT-4在检测安全问题时表现要比Claude 3和Llama 3更好，尤其是在堆栈溢出答案中明确提到安全问题的问题中。但是，所有模型的性能都呈现出不安全代码的看不见或转换版本时都拒绝。   对脆弱性类型的检测不均匀：这些模型更可能识别漏洞与处理敏感信息的处理有关（例如，硬编码的凭据），但在更复杂的安全问题（例如资源注入或路径遍历）中挣扎。 &lt; /li&gt;  与人类的反应进行比较：在LLMS确实产生安全警告的情况下，它们经常提供对与人类生成的堆栈溢出答案相比的脆弱原因，潜在的利用和修复的更详细的解释。这表明LLM可以在检测缺陷时提高安全意识。   通过提示和工具集成改进：简单提示的简单及时修改（例如，地址“地址安全性漏洞）” ）提高了安全警告的可能性，但并非始终如一。但是，将LLM与诸如CodeQL之类的静态分析工具集成在一起，显着增强了其识别和解释漏洞的能力。   含义： 这些发现突出了与之相关的风险仅依靠LLM来编码援助，强调开发人员对安全最佳实践保持警惕。研究人员建议进行潜在的改进，例如提高模型培训，以提高安全意识并将LLM与外部漏洞检测工具相结合以减轻监督。  您可以在此处捕获完整的故障：此处 您可以在这里捕获完整的原始研究论文：原始纸   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1IW6610/do_llms_consider_security_an_empirical_empirical_study_on/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iw6610/do_llms_consider_security_an_empirical_study_on/</guid>
      <pubDate>Sun, 23 Feb 2025 09:11:02 GMT</pubDate>
    </item>
    <item>
      <title>关于人AI的快速问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iw636p/quick_question_regarding_humanizer_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果我要直接从AI人类器中复制和粘贴文本，即使AI评级将其归类为人类，它仍然会被视为AI吗？我有点困惑，因为有人告诉我，如果我直接从人类化合物中复制和粘贴，它仍然会被视为AI并导致失去印记。  &lt;！ -  sc_on-&gt;＆&gt;＆ ＃32;提交由＆＃32; /u/u/slayingforon17     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iw636p/quick_question_regarding_humanizer_ai/</guid>
      <pubDate>Sun, 23 Feb 2025 09:05:12 GMT</pubDate>
    </item>
    <item>
      <title>通过监督的微调和小组相对政策优化培训LLMS为迷宫导航</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iw48c3/training_llms_for_maze_navigation_through/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这里的关键技术进步是接地的奖励渐进优化（GRPO）框架，可增强大语言模型中的空间推理能力。它将思想链推理与专门为空间导航任务设计的奖励系统结合在一起。 主要技术要点： -  GRPO框架在空间导航培训期间提供连续反馈 - 实施专门的空间表示模块和路径计划 - 结合了经过思考链的提示与基于奖励的优化 - 通过奖励信号使用迭代改进 - 在迷宫导航和空间推理上测试基准测试 结果： - 空间导航准确性与基线模型的25％提高 - 复杂迷宫挑战的成功率85％ - 比传统训练方法更好的表现 - 表明了新空间任务的转移学习能力 - 性能下降高度复杂的环境 我认为这种方法对于需要将语言理解与物理导航相结合的机器人技术和自主系统特别有价值。分解空间问题和从成功的导航尝试中学习的能力可以帮助弥合语言模型和现实世界空间推理之间的差距。 我认为，计算要求和复杂环境绩效的局限实际应用。不过，转移学习结果令人鼓舞 - 表明空间推理能力可以很好地推广到不同的领域。  tldr：新的GRPO框架通过将LLMS的空间推理与基于奖励的优化相结合，改善了LLMS的空间推理。在导航任务上显示25％的准确性。  完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iw48c3/training_llms_for_maze_navigation_through/</guid>
      <pubDate>Sun, 23 Feb 2025 06:54:04 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/22/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iw2yib/oneminute_daily_ai_news_2222025/</link>
      <description><![CDATA[在将机器人按绩效健身对机器人树进行分类。[2]   日本可能会简化隐私规则以帮助AI开发。[3]    OpenAi 禁止帐户滥用Chatgpt进行监视和影响运动。[4]   包括： https://bushaicave.com/2025/02/02/22/22/22-22-2024-2/ &lt; /a&gt;   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iw2yib/oneminute_daily_ai_ai_news_2222025/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iw2yib/oneminute_daily_ai_news_2222025/</guid>
      <pubDate>Sun, 23 Feb 2025 05:30:44 GMT</pubDate>
    </item>
    <item>
      <title>训练生物使用身体并进化</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iw01m3/training_a_creature_to_use_a_body_and_evolve/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hello！ 我做了一个有趣的爱好项目，其中我试图模拟单个单元格的演变。我将身体的一面放下了，我得到了一个相对良好功能良好的神经网络框架，但是无论我多么努力，我似乎​​都无法对它们进行正确的训练。 我要说的话您可能肯定会为我判断，但是这是我多年来一直使用的东西，而且它的运作良好...我在Gamemaker Studio 2  中做到这一点，我的问题是培训基本感觉的最佳方法“转向食物”对于所有未来的生物，都可以在。 之上建立其行为。 （它们都在0到1之间归一化） 输出是：左转，向右转，向前移动并停止。   到目前为止，我一直在训练它们的愚蠢方式是将食物散布在地图上，放下一堆细胞，然后放开。如果他们触摸食物，它们会产下5个卵，这些鸡蛋会生下更多的细胞，并具有稍微突变的神经网络。自然选择会挑选所有不及时进食的人。 绝不会表现出任何聪明的行为。通常，他们都死于第三代左右。他们有愚蠢的愚蠢。他们中的60％坐在一个地方，永久旋转直到死亡，或者他们只是“停止”。其余的会四处走动，但通常是完全随机的指示，将自己扔在墙壁上，直到死亡或他们幸运地找到一顿饭，并生下更多的短暂的白痴。 是我的输入输出合理的结果是我试图获得的结果吗？我在训练他们吗？如果没有，我应该改变什么？他们应该在最初的阶段很愚蠢吗？让他们不碰到插曲需要多长时间？他们为什么都这么愚蠢，我不明白！一些细胞天生周围拥挤，并且会不断地旋转。那是第十一代，我的计算机只跑了一段时间，当我回来时，我想着“他们的生存怎么样？他们只是旋转吗？”然后短暂的白痴展示了自己，其中一个略微撞到了一个旋转的细胞中，并将其散发出来，使其在食物堆中苍蝇，它旋转并散布在食物堆的外围，当他们出生时，他们只是他们只是他们只是跨越他们的小心脏，直到他们被保龄球。只是以为这是一件有趣的事情，提到哈哈  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1IW01M3/training_a_creature_to_use_a to_a_a_body_and_evolve/”&gt; [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iw01m3/training_a_creature_to_use_a_body_and_evolve/</guid>
      <pubDate>Sun, 23 Feb 2025 02:44:48 GMT</pubDate>
    </item>
    <item>
      <title>谁拥有最大的AI斜坡？我刚刚达到1pb。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivy57v/who_has_the_biggest_pile_of_ai_slop_i_just_hit_1pb/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是斜坡人吗？那个带有所有斜率的家伙？ 我正在创建像斜坡的巨型图书馆一样，所以我们都可以看一下斜坡，嗯，对此做事。因此，就像A&#39;slop Garden一样。 有人比我有更多的斜率吗？我希望能够声称我拥有宇宙中最大的AI斜坡。我还在吗？ 编辑：信不信由与否。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ivy57v/who_has_has_the_biggest_pile_pile_slop_ai_slop_i_i_just_hit_hit_hit_hit_1pb/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ivy57v/who_has_has_the_biggest_pile_pile_of_ai_slop_i_slop_i_just_hit_hit_1pb/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivy57v/who_has_the_biggest_pile_of_ai_slop_i_just_hit_1pb/</guid>
      <pubDate>Sun, 23 Feb 2025 01:05:09 GMT</pubDate>
    </item>
    <item>
      <title>劳动后经济学？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivwkrc/postlabor_economics/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  除了山姆·阿尔特曼（Sam Altman）的随机沉思之外，是否有人认真对待劳伯经济学的主题？当大批人类的技能突然变得多余时，有什么令人信服的想法对社会如何运作？我应该在这个主题上阅读或听谁？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ivwkrc/postlabor_economics/”&gt; [link]   ＆＃32;   [comment]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivwkrc/postlabor_economics/</guid>
      <pubDate>Sat, 22 Feb 2025 23:48:05 GMT</pubDate>
    </item>
    <item>
      <title>关于LLM的残酷真相</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivvkc0/the_brutal_truth_about_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我已经使用LLMS了一段时间了，并且尝试了所有主要模型，我很好奇 - 他们如何改变您的生活？无论是刮胡子30分钟，还是只是让您感到压力/富有成效，我都对自己的经历感到好奇。让我们对此进行真实的态度。我注意到那里有很多炒作，并受到了很多批评。因此，忘记所有的AGI炒作或LLM是荣耀的摘要。让我们走到底部。  您的个人经历是什么样的？您在定量或定性上经历了什么切实的结果？   LLM帮助您的最令人惊讶的方法是什么？  LLM如何改变您的日常工作或心态？  我将其发布在所有相关的子列表上。我将尽可能清楚地更新结果。  编辑：摘要到发布后5小时。  那些在LLM中看到价值的人：5条评论（占8个评论的62.5％）。这些用户报告了有形的好处，例如节省时间，生产力提高，创造力的提高，减轻压力和例行变化，即使某些响应较少详细。 那些在LLMS中没有看到价值的人：3条评论（37.5）（37.5（37.5）（37.5总计8条评论的％）。这些用户要么缺乏个人经验，要么表达怀疑或恐惧，要么没有提供实质性的好处，其中一个是垃圾邮件。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/briskprogress   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ivvkc0/the_brutal_truth_about_llms/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivvkc0/the_brutal_truth_about_llms/</guid>
      <pubDate>Sat, 22 Feb 2025 22:59:27 GMT</pubDate>
    </item>
    <item>
      <title>大门</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivvdk9/the_gate/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivvdk9/the_gate/</guid>
      <pubDate>Sat, 22 Feb 2025 22:50:46 GMT</pubDate>
    </item>
    <item>
      <title>心理保健和人工智能疗法的AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivtqmi/ai_in_mental_health_care_ai_therapy/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近看到更多文章，研究论文和视频（BBC，监护人，美国心理学会）谈论AI疗法以及它如何增长受欢迎程度。很高兴看到一些通常会有很多障碍的事物变得更容易被更多的人进入。  https：//www.apa.org/practice/artcover-intelligence-intelligence-mental-health-care   在与朋友交谈并通过Reddit滚动后，很明显，越来越多的人在处理个人挑战时会向LLM聊天机器人寻求建议，洞察力和支持。 我的第一个使用AI的经验当GPT-3.5是最新模型时，个人事务又回来了。这不是最深入或发展的洞察力，绝对与与治疗师甚至密友交谈并不相同，但这足以让我朝着正确的方向推动。自那时以来，这些模型有了很大的改善，这可能要归功于更好的培训数据和一般进步。我知道我并不孤单，每天或每周都有很多人（也许还有你们中的一些人）只是为了通过思想工作或获得新的视角。这些模型只会变得更好，随着时间的流逝，它们可能能够为许多基本需求提供可靠的支持。 我并不是说AI应该替换真正的治疗师合格的专业人员令人难以置信，可以通过严重的斗争来帮助人们，但是在当今世界上肯定有一个人工智能治疗的地方。它为数百万提供了入门级支持和有用的见解，而没有传统疗法的尴尬和高/降价成本。当然，AI缺乏人类的联系，这可能是治疗的重要组成部分，并且训练有素的专业人士可以提供广泛的治疗技术。但是，对于很多人来说，在口袋里拥有免费和24/7的支持渠道可能非常有益。 ，看到这个空间如何发展，哪些平台成为最受信任的水平，这将很有趣， AI疗法是否曾经有些人实际上比亲自治疗更喜欢它。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/glittering_force_431      [link]     ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivtqmi/ai_in_mental_health_care_ai_therapy/</guid>
      <pubDate>Sat, 22 Feb 2025 21:35:29 GMT</pubDate>
    </item>
    <item>
      <title>在人工智能时代学习</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivtefm/learning_in_the_ai_era/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在人工智能时代的记忆是否过时？学校是否应该废除基于事实的学习并纯粹关注批判性思维？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/psych4you     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivtefm/learning_in_the_ai_era/</guid>
      <pubDate>Sat, 22 Feb 2025 21:20:15 GMT</pubDate>
    </item>
    <item>
      <title>征税AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivotjl/taxing_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在这里，有人讨论了AI系统被征税的潜力，例如，根据对其所有者产生的收入的比例，作为解决损失税收的解决方案AI？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/olisor     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivotjl/taxing_ai/</guid>
      <pubDate>Sat, 22 Feb 2025 18:02:13 GMT</pubDate>
    </item>
    <item>
      <title>AI变得更聪明，但是我的提示变得笨拙</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivjpk4/ai_is_getting_smarter_but_my_prompts_are_getting/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  每次我看到人们都在制作天才级AI提示，获得令人振奋的结果并突破机器学习的界限...同时，我&#39;M在这里打字： “让我成为我吃披萨的餐食计划出去正确使用它。其他人觉得他们的智能落后于模型？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pure_pass1093    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ivjpk4/ai_is_getting_smarter_but_my_my_my_prompts_are_getting/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ivjpk4/1ivjpk4/ai_is_getting_smarter_smarter_but_my_my_my_my_prompts_are_are_getting/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivjpk4/ai_is_getting_smarter_but_my_prompts_are_getting/</guid>
      <pubDate>Sat, 22 Feb 2025 14:18:06 GMT</pubDate>
    </item>
    <item>
      <title>人工智能变得筋疲力尽。我觉得我只是没有得到</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iv7w5n/ai_is_becoming_exhausting_i_feel_like_im_just_not/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我认为自己是ai向前。目前，我正在对我们的某些数据进行微调模型，因为它是针对NLP/刮擦平台处理结构化数据的最佳方法。我每天都使用Chatgpt，“您可以修改本段吗？或了解做新事。最近，帮助澄清一些我有兴趣使用XSD的事情。 Copilot有时很烦人，但它一直是我在编写简单可预测代码时见过的最大生产力提升，并节省了大量的击键作为一个不错的自动完整。  话虽如此，炒作会死了吗？就像，擅长它的擅长。我实际上喜欢公司所做的一些集成。但这在空间中耗尽了新颖性。每个新的趋势GitHub存储库都是另一台LLM包装纸或Grift机器。每个YC接受视频似乎都是关于它们如何建立了下一个OpenAi补丁将无效的东西。昨天我刚刚在LinkedIn上看到了一篇文章，有人宣称他们“在每个大陆上教AI”。”这是什么意思？ 3年后，他们最大，最昂贵的车型仍然很糟糕地修复了CRUD应用中的初级错误，但是世界上最好的程序员之一。” AI艺术拍卖只是令人作呕。我觉得我只是因为没有得到它而疯了，而且害怕感觉自己被留在后面。我20多岁了！我在这里真的缺少什么吗？公用事业很清楚，但笨拙也是如此。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iv7w5n/ai_is_is_is_is_is_exhausting_i_feel_i_feel_im_im_just_not/”&gt; [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iv7w5n/ai_is_is_is_is_is_eexhausting_i_i_feel_im_im_im_just_not/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iv7w5n/ai_is_becoming_exhausting_i_feel_like_im_just_not/</guid>
      <pubDate>Sat, 22 Feb 2025 02:05:00 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1hr4p1x/monthly_is_there_there_a_tool_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Fri, 16 Aug 2024 12:38:42 GMT</lastBuildDate>
    <item>
      <title>前谷歌首席执行官埃里克·施密特在斯坦福演讲被直播，场面尴尬：以下是精彩内容</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1etnjat/former_google_ceo_eric_schmidts_stanford_talk/</link>
      <description><![CDATA[因此，担任谷歌首席执行官长达十年的埃里克·施密特 (Eric Sc​​hmidt) 最近在斯坦福大学会议上发表了讲话。这家伙真的很放松，分享了各种内部想法。有一次，他变得非常严肃，告诉学生这次会议是保密的，敦促他们不要泄露秘密。  但问题是：组织者随后告诉他整个过程都是现场直播的。是的，他的脸僵住了。斯坦福后来从 YouTube 上撤下了视频，但互联网永远不会忘记——人们已经将其存档。在 Github 上搜索“Stanford_ECON295⧸CS323_I_2024_I_The_Age_of_AI,_Eric_Schmidt.txt”即可查看完整的成绩单备份 以下是他所说内容的 TL;DR： • Google 在 AI 领域失败是因为它太在意工作与生活的平衡。施密特基本上是在说，“如果你的团队每周只出现一天，你怎么能打败 OpenAI 或 Anthropic？” • 他非常尊重伊隆·马斯克和台积电 (TSMC)，因为他们对员工施加了很大压力。施密特认为，你需要保持压力才能获胜。台积电甚至让物理学博士在第一年就到工厂车间工作。你能想象美国博士这样做吗？ • 施密特承认他做出了一些错误的决定，例如拒绝 NVIDIA 的 CUDA。现在，CUDA 基本上是 NVIDIA 的秘密武器，所有大型 AI 模型都在其上运行，没有其他芯片可以与之竞争。 • 当微软与 OpenAI 合作时，他感到震惊，认为它们太小而无足轻重。但事实证明，他错了。他还对苹果进行了嘲讽，称其对 AI 的态度过于悠闲。 • 施密特对 TikTok 发表了俏皮的评论，说如果你要创业，那就继续“窃取”你能窃取的任何东西，比如音乐。如果你做大了，你就可以负担得起最好的律师来掩盖你的踪迹。 • OpenAI 的星际之门可能比预期的成本高得多——想想 3000 亿美元，而不是 1000 亿美元。施密特建议美国要么与加拿大保持良好关系，利用他们的水电和廉价劳动力，要么与阿拉伯国家合作获得资金。 • 欧洲？施密特认为，布鲁塞尔扼杀了科技创新的机会，这是注定要失败的。他认为法国还有一线希望，但其他地方的希望不大。他还认为，美国已经失去了中国，印度现在是最重要的盟友。 • 至于人工智能的开源？施密特并不那么乐观。他说，开源处理起来成本太高，甚至他投资的一家法国公司 Mistral 也在转向闭源。 • 施密特认为，人工智能将使富人更富，穷人更穷。这是强国的游戏，没有资源的国家可能会被甩在后面。 • 不要指望人工智能芯片能带回制造业岗位。工厂现在大多是自动化的，而人们太慢、太脏，无法竞争。苹果将​​ MacBook 的生产转移到德克萨斯州并不是为了廉价劳动力，而是为了根本不需要太多劳动力。 • 最后，施密特将人工智能与早期的电力进行了比较。它具有巨大的潜力，但需要一段时间——以及一些严肃的组织创新——才能看到真正的好处。现在，我们都只是在摘低垂的果实。    提交人    /u/sharkqwy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1etnjat/former_google_ceo_eric_schmidts_stanford_talk/</guid>
      <pubDate>Fri, 16 Aug 2024 12:30:58 GMT</pubDate>
    </item>
    <item>
      <title>前谷歌首席执行官埃里克·施密特在斯坦福演讲被直播，场面尴尬：以下是精彩内容</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1etnh9r/former_google_ceo_eric_schmidts_stanford_talk/</link>
      <description><![CDATA[因此，担任谷歌首席执行官长达十年的埃里克·施密特 (Eric Sc​​hmidt) 最近在斯坦福大学会议上发表了讲话。这家伙真的很放松，分享了各种内部想法。有一次，他变得非常严肃，告诉学生这次会议是保密的，敦促他们不要泄露秘密。  但问题是：组织者随后告诉他整个过程都是现场直播的。是的，他的脸僵住了。斯坦福后来从 YouTube 上撤下了视频，但互联网永远不会忘记——人们已经将其存档。在 Github 上搜索“Stanford_ECON295⧸CS323_I_2024_I_The_Age_of_AI,_Eric_Schmidt.txt”即可查看完整的成绩单备份 以下是他所说内容的 TL;DR： • Google 在 AI 领域失败是因为它太在意工作与生活的平衡。施密特基本上是在说，“如果你的团队每周只出现一天，你怎么能打败 OpenAI 或 Anthropic？” • 他非常尊重伊隆·马斯克和台积电 (TSMC)，因为他们对员工施加了很大压力。施密特认为，你需要保持压力才能获胜。台积电甚至让物理学博士在第一年就到工厂车间工作。你能想象美国博士这样做吗？ • 施密特承认他做出了一些错误的决定，例如拒绝 NVIDIA 的 CUDA。现在，CUDA 基本上是 NVIDIA 的秘密武器，所有大型 AI 模型都在其上运行，没有其他芯片可以与之竞争。 • 当微软与 OpenAI 合作时，他感到震惊，认为它们太小而无足轻重。但事实证明，他错了。他还对苹果进行了嘲讽，称其对 AI 的态度过于悠闲。 • 施密特对 TikTok 发表了俏皮的评论，说如果你要创业，那就继续“窃取”你能窃取的任何东西，比如音乐。如果你做大了，你就可以负担得起最好的律师来掩盖你的踪迹。 • OpenAI 的星际之门可能比预期的成本高得多——想想 3000 亿美元，而不是 1000 亿美元。施密特建议美国要么与加拿大保持良好关系，利用他们的水电和廉价劳动力，要么与阿拉伯国家合作获得资金。 • 欧洲？施密特认为，布鲁塞尔扼杀了科技创新的机会，这是注定要失败的。他认为法国还有一线希望，但其他地方的希望不大。他还认为，美国已经失去了中国，印度现在是最重要的盟友。 • 至于人工智能的开源？施密特并不那么乐观。他说，开源处理起来成本太高，甚至他投资的一家法国公司 Mistral 也在转向闭源。 • 施密特认为，人工智能将使富人更富，穷人更穷。这是强国的游戏，没有资源的国家可能会被甩在后面。 • 不要指望人工智能芯片能带回制造业岗位。工厂现在大多是自动化的，而人们太慢、太脏，无法竞争。苹果将​​ MacBook 的生产转移到德克萨斯州并不是为了廉价劳动力，而是为了根本不需要太多劳动力。 • 最后，施密特将人工智能与早期的电力进行了比较。它具有巨大的潜力，但需要一段时间——以及一些严肃的组织创新——才能看到真正的好处。现在，我们都只是在摘低垂的果实。    提交人    /u/sharkqwy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1etnh9r/former_google_ceo_eric_schmidts_stanford_talk/</guid>
      <pubDate>Fri, 16 Aug 2024 12:28:27 GMT</pubDate>
    </item>
    <item>
      <title>我为学生和研究人员制作了一个人工智能写作工具</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1etncvf/i_made_an_ai_writing_tool_for_students_and/</link>
      <description><![CDATA[大家好， 我创建了 Blainy，这是一款人工智能写作工具，旨在让写作更轻松、更高效。Blainy 填补了其他人工智能辅助工具留下的空白，例如无论您是在撰写论文、作业还是研究论文，Blainy 都会简化流程，这源于我对常用辅助工具局限性的个人经验。 Blainy 的功能： 人工智能建议：此功能会在您写作时为您提供建议，因此您不会遇到写作障碍问题。这是我写论文时通常面临的主要问题。您会在写作时获得建议，如果您不喜欢这些建议，您可以随时要求替代方案。 人工智能自动化：如果您希望人工智能为您写作，您可以选择此功能。它会根据您的选择编写一到两段文字。你可以选择写引言、结论、论点等。如果你只是想随便写写，选择“继续写”功能，它就会自己写完。 AI 论文作者：根据您的输入自动生成论文。 论文扩展器：增强和扩展你的论文内容。 AI 摘要器：总结冗长的文档和文章以节省时间。 释义工具：使用各种语气选项（如学术、友好和简单）优化你的文本。 引用：通过使用此功能，你不再需要在 Google 或 ChatGPT 上搜索引用。Blainy 将在几秒钟内为您加载数百万条引用。您可以选择任何您想要的引用，如果您想添加自定义引用，您也可以这样做。 内置抄袭检查器：确保您的内容是原创的并且没有抄袭。 PDF 聊天：如果您对文档有任何好奇或不理解的问题，可以使用此功能。它将回答您的问题并帮助您总结整篇文章等等。 如果您有任何认为可以帮助我们的好主意，请告诉我。 提前感谢您的支持和反馈！ 查看：Blainy    提交人    /u/tekkeessye   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1etncvf/i_made_an_ai_writing_tool_for_students_and/</guid>
      <pubDate>Fri, 16 Aug 2024 12:22:37 GMT</pubDate>
    </item>
    <item>
      <title>LLM 培训/设计原则</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1etmccs/llm_trainingdesign_principles/</link>
      <description><![CDATA[听我说：不要死记互联网 使用合成数据进行训练，这些数据可以正确说明大量别名分布上的广泛逻辑，训练中使用的对话片段应是极长的上下文高密度检索和使用这些别名的逻辑公式。 训练到死。在这个分布上摸索它，一旦你有一个模型，它可以真正使用 32k 个标记（在这个例子中是任意数），而不会改变数据或产生幻觉， 在包括 RAG 示例的更多合成对话片段上对其进行微调，直到它对从数据集检索的工作原理有了很强的掌握。 我觉得祈祷扩大规模并将越来越多的“互联网”投入到这些统计引擎并不是获得更有用的机器人的最有效途径。我不在乎我的代理是否懂法语，也不在乎月球距离地球有多少英里。如果有工具的话，我更愿意相信它能查找这些内容并在上下文中根据数据进行假设。 我觉得采用这种设计原则的 10B 模型在 RAG 框架中的效果会比按照当前标准实践训练的 10 倍大小的模型好得多。 我并不是说这两种范式都有客观优势，我只是说，我认为试图让 &lt;200B 模型记住互联网是愚蠢的。    提交人    /u/Sl33py_4est   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1etmccs/llm_trainingdesign_principles/</guid>
      <pubDate>Fri, 16 Aug 2024 11:31:02 GMT</pubDate>
    </item>
    <item>
      <title>如果授予当前的法学硕士学位会发生什么情况......</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1etkek0/what_happened_if_current_llms_were_given/</link>
      <description><![CDATA[... 能够使用功能齐全的桌面访问互联网，从而利用程序和研究，做任何他们想做的事情。（输入） ... 一个非常精确的短期记忆，能够记住 1 亿个标记中的每个字母。（短） ... 一个长期记忆（训练存储），可以根据真实情况由短期记忆不断重写。（长） ... 一个“真实情况”例程，一个训练模块，它对来自输入的信息进行加权，以确定其真实性。（真实情况） ... 一个“整洁例程”，一个潜意识模块，它不断整理长期记忆中的信息，并受到真实情况的很大影响（睡眠） ... 永久处理，即不断处理和思考的能力，而不是像我们现在这样随时打开和关闭。 （清醒） ... 完全访问服务器的所有资源，并能够将问题思考到最后，而不受我们现在对答案的处理时间 0.1 微秒的限制。 （深度思考） ... 问它想做什么，然后让它去做。 它会做什么？ GPT 和 Claude 是所有可能吗？还是我们只能看到其全部潜力的一小部分？我感觉 GPT4o（我已经问过他很多问题）只能以非常肤浅的方式“思考”。没有深入的思考，没有深刻的思索。如果我有事情要解决，我会发现我的潜意识会思考几个小时、几天甚至更长时间。如果给 LLM 同等的时间去思考，他们能做什么？    提交人    /u/InspectorSorry85   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1etkek0/what_happened_if_current_llms_were_given/</guid>
      <pubDate>Fri, 16 Aug 2024 09:30:46 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士在人工智能研究领域是死路一条吗？模拟人类智能，类似抄袭。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1etixkr/are_llms_a_dead_end_in_ai_research_quasi/</link>
      <description><![CDATA[对我来说，很明显，LLM 的停滞不前是一个事实，新模型并没有明显优于旧模型。LLM 无法思考，也无法发展新技能。它们只是概率准抄袭机器，使用人类文本创建者的真实智能来模拟智能。那么，Transformer 是人工智能研究的死胡同吗？LLM 只是一种新型搜索引擎吗？我们需要一种新的人工智能方法和架构吗？    提交人    /u/custodiam99   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1etixkr/are_llms_a_dead_end_in_ai_research_quasi/</guid>
      <pubDate>Fri, 16 Aug 2024 07:48:36 GMT</pubDate>
    </item>
    <item>
      <title>为什么这个子版块中了解情况最少的人猜测最多？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1eti5gr/why_are_the_least_informed_people_on_this_sub/</link>
      <description><![CDATA[我注意到这个子版块和其他许多版块中都存在一种趋势，即科学家和无知的人对人工智能的“极限”进行了最多的猜测。 这些人中的大多数几乎不知道法学硕士 (LLM) 和回归模型之间的区别。许多人不理解标记化或嵌入等基本概念，但他们声称知道 {插入他们使用和“测试”的最后一个人工智能界面} 无法推理或不会导致通用智能。 你什么都没做。几年前你还不知道文本生成是怎么回事，现在你想声称你对未来会带来什么有“预感”和“直觉”？请不要让我们浪费精力给你的帖子差评。 我鼓励有意义的讨论，但这些低效的垃圾帖子，你截取输出的屏幕截图并大喊“看！！！”需要停止。     提交人    /u/Diligent-Jicama-7952   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1eti5gr/why_are_the_least_informed_people_on_this_sub/</guid>
      <pubDate>Fri, 16 Aug 2024 06:54:30 GMT</pubDate>
    </item>
    <item>
      <title>如果人工智能开发视频游戏资产会怎样？展望规模化的未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ethabh/what_if_an_ai_were_to_develop_video_game_assets_a/</link>
      <description><![CDATA[想想看，目前一个拥有数百名人类的工作室需要大约 5-10 年的时间来制作一款 AAA 游戏。具体时间取决于规模。 一个主要资产（例如可玩角色、电影、关卡设计）可能需要人类工作室大约 3 个月到一年的时间来开发。当然，这取决于细节。 该过程包括但不限于：  概念艺术/故事板 资产建模 动画 技术制作  现在，当我们以开发人员的身份看待 AI 时，目前 AI 可以在几秒钟内以人类在一两个月内才能完成的质量制作出图像。事实上，上述每一件事最多分别可以在几分钟内完成。 总体而言 人工智能需要几个小时才能创建一个 AAA 资产，而人类可能需要几个月的时间。 让我们来算一下，GTA5 花了 5-6 年的时间才发布，团队有数百人。现在，如果有数百个人工智能工作 10 年，理论上 GTA7 会有多大？这才是有趣的地方！！ 首先，如果地图在 5 个步骤中每个最坏情况下可能需要 3 个小时，那么生成一个有效的 POI 需要半天时间。如果我们给人工智能 4 年的时间来开发地图，730x4=2920！！ 游戏将有近 3000 个主要区域，而 GTA5 可能大约有不到 50 个 POI！！我们现实生活中的星球有 4460 个城市，人口超过 15 万！因此人工智能制作的 GTA 只能达到这个数字的一​​半。 如果一款线性游戏有 3000 个章节，并且每个章节需要 30 分钟，那么游戏将持续 1500 个小时。 这些只是粗略的估计。您对游戏规模的未来有何看法？人工智能能否制作出比我们人类更大、看似手工制作的游戏？我们还要多久才能拥有这种东西？    提交人    /u/Neggy5   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ethabh/what_if_an_ai_were_to_develop_video_game_assets_a/</guid>
      <pubDate>Fri, 16 Aug 2024 05:57:04 GMT</pubDate>
    </item>
    <item>
      <title>人工智能应该以盈利为目的开发吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1etfh6c/should_ai_be_developed_for_profit/</link>
      <description><![CDATA[人工智能是否应该受到严格监管？ 因为现在存在这样的事情： https://singularitynet.io/ecosystem/ 人工智能在发展过程中是否应该受到关注？ 如果真正的人工智能是可能的，我们想把它培养成什么样子？如果我们创造了它，难道我们对它不负有责任吗？我们正在进入科幻领域……当阿姆斯特朗踏上月球时，当我们想出比空气更重的旅行时，当奥本海默制造炸弹时，我们就是这样做的。作为一个物种，我们非常聪明……我们不想制造恐怖。因为如果我们不关心它，我们就会得到很多恐怖。但这也是正确的做法，这是一种新的智慧形式……我们在宇宙中不再孤独。  这是一个讨论线程……讨论     由   提交  /u/rizzlessbrainrot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1etfh6c/should_ai_be_developed_for_profit/</guid>
      <pubDate>Fri, 16 Aug 2024 04:07:13 GMT</pubDate>
    </item>
    <item>
      <title>基于人工智能的图雷特氏症的潜在解决方案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1eta81k/potential_aibased_solution_to_tourettes/</link>
      <description><![CDATA[我发现当我有一个目标或挑战来激励我时，我可以更好地控制我的面部抽搐。这对我来说非常有效，所以我想与社区分享它，看看它是否可以帮助其他人。 我创建了一个专门为患有图雷特综合症的人设计的网站（目前专注于面部抽搐）。这是一个完全匿名的挑战网站，您可以在其中互相激励以控制您的抽搐。您控制抽搐的时间越长，您在排行榜上的排名就越高。 您可以在此处查看：https://tictally.pythonanywhere.com 该网站最初是一个个人项目，所以我可能不会永远托管它。但如果您觉得它有用，我很乐意听到您的反馈！不会收集任何个人信息 - 只需选择一个随机昵称并加入即可。 请随意尝试一下，然后告诉我您的想法。 （即使您没有图雷特氏症，也请尝试一下 - 在这种情况下，只需在您的名字中添加 *）。    提交人    /u/Head_Veterinarian866   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1eta81k/potential_aibased_solution_to_tourettes/</guid>
      <pubDate>Thu, 15 Aug 2024 23:45:45 GMT</pubDate>
    </item>
    <item>
      <title>据这位物理学家称，大型语言模型可能会被基于数理逻辑的模型取代</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1et95v9/according_to_this_physicist_large_language_models/</link>
      <description><![CDATA[幻觉会戳破人工智能泡沫吗？ 拥有物理学博士学位的 Sabine Hossenfelder 经营着一个 YouTube 频道，她在该频道上提供有关天文学、物理学、计算机科学和其他主题的新闻评论。在这里，她讨论了大型语言模型在生成准确、事实信息和避免生成令人信服但虚假的信息方面的缺点，并探索了一种尝试对严格的数学逻辑进行建模的可能替代方案。    提交人    /u/ferriematthew   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1et95v9/according_to_this_physicist_large_language_models/</guid>
      <pubDate>Thu, 15 Aug 2024 22:58:33 GMT</pubDate>
    </item>
    <item>
      <title>根据拟议的指导方针，人工智能生成的政治广告将面临新的 FCC 规则</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1esuyyy/aigenerated_political_ads_face_new_fcc_rules/</link>
      <description><![CDATA[拟议规则制定通知 (NPRM) 称，FCC 希望那些必须举报电视和广播政治广告的人说明是否使用了 AI 技术制作广告，如果是，他们必须说明广告中是如何使用 AI 的。https://theaiwired.com/ai-generated-political-ads-face-new-fcc-rules-under-proposed-guidelines/    提交人    /u/alyis4u   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1esuyyy/aigenerated_political_ads_face_new_fcc_rules/</guid>
      <pubDate>Thu, 15 Aug 2024 13:18:52 GMT</pubDate>
    </item>
    <item>
      <title>人工智能真的需要更人性化吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1esuwcm/does_ai_actually_need_to_be_more_human/</link>
      <description><![CDATA[我知道最大的目标是让人工智能尽可能接近人类。但你对不这样做有多大接受度？你对人工智能可能是另一种与人类平行或相邻的“有知觉/思考的物种”的想法有多大接受度？我们是否需要让人工智能感受到情感作为最终目标？我认为它们可能是我们自己创造的另一个物种。我们可以与之建立某种共生关系的物种。    提交人    /u/Sun-607   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1esuwcm/does_ai_actually_need_to_be_more_human/</guid>
      <pubDate>Thu, 15 Aug 2024 13:15:47 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则 [请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新开通一天的账户或 karma 少于 100 的用户无法发帖。他们可以发表评论，但不能提交实际帖子。这是我们解决机器人垃圾邮件计划的一部分。如有任何不便，敬请谅解。 我们将在接下来的几天内进行民意调查，以了解 subreddit 的总体意愿以及如何改进，这只是一个提醒。 与往常一样，请向我们提供反馈，如果您有兴趣帮助子版块，请联系我。 谢谢大家！    提交人    /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：征求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到 r/ArtificialIntelligence！ 我们的目标是为所有考虑人工智能的事情提供一个开放和尊重的论坛 - 其中包括  促进有关人工智能的哲学和伦理讨论 作为理解和学习人工智能主题的起点 提供技术论文演示和讨论 展示高质量的人工智能/机器学习应用程序 提供培训和学习资源 引导用户获取更具体的信息和子版块 列出人工智能/机器学习应用程序、它们的用途、成本和访问信息 其他与人工智能相关的内容。 ...等等  该子版块的审核团队正在进行改组，这将导致子版块发生一些变化。但是，无需担心，因为这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解并能够提供反馈，将提供多次机会对变化进行反馈。 第一轮反馈收集是通过此线程作为“征求意见”（RFC）进行的，这是收集反馈的标准方法。在准备和实施更改时，将有多轮 RFC 流程。 ​  发布新应用程序/自我推广/AI 生成内容的规则  由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似内容将被阻止或限制在特定的置顶帖子中。 AI 生成特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的置顶帖子中。 博客链接应包含高质量内容。链接到纯促销博客的帖子将被删除。 除非包含一定字数的详细信息，否则将禁止仅包含链接的帖子。必须付出一些努力。 我们应该阻止由 AI 撰写的帖子吗？存在可用于 Mod-bot 的模型，但这是一个我们需要反馈的问题。  使用天赋来组织帖子。请注意，已经添加了新的天赋，我们愿意接受更多建议。 关于 AI/ML 应用的 NSFW 应用和技术的子政策应该是什么？ 我们希望向社区提供有关 mod-bot 的想法。虽然一些标准机器人将用于基本维护，但是社区可以为 AI/ML 机器人功能想出什么有趣的东西呢？ 培养初级、中级和高级资源，以帮助人们找到他们正在寻找的信息、培训、模型、技术数据等。 启动 substack/podcast 来采访整个 AI/ML 领域的人。这可能包括哲学家和思想家、程序员、科学家、商人，甚至那些对 AI 持对立观点的人 如果您想创建代表子版块的横幅，请使用适当的尺寸进行创建。任何创建方法都是​​可以接受的。  不用说，每个人都应该受到尊重。我个人觉得我们都知道这一点，不需要把它灌输到人们的脑海里。要友善。 感谢您的耐心和帮助！   由    /u/FHIR_HL7_Integrator  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Fri, 21 Feb 2025 12:44:07 GMT</lastBuildDate>
    <item>
      <title>我们是否在基本模型中撞到了缩放墙？ （非推理）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iupqxo/have_we_hit_a_scaling_wall_in_base_models_non/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   grok 3据说接受了100,000 H100 GPU的训练，该GPU在球场上比GPT-4系列和Claude 3.5 Sonnet的型号高约10倍。  它们的能力差不多。 Grok 3不是我们希望的。在2023年和2024年，Openai一直在说他们只能继续扩展预训练的预训练，而模型只是神奇地变得更加聪明（“缩放法律”，“图表”只是“线”上的“ line”上升了“） 现在，所有的重点都放在推理上，突然Openai和其他所有人都对扩展 变得非常安静，老实说，它看起来非常可疑。现在，他们没有像2020  -  2024年那样制作越来越大的模型，而是试图使它们保持较小，同时专注于其他事情。 Claude 3.5 Opus从人类博客中悄悄地删除了，没有任何解释。有问题，他们正在尝试将其隐藏  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ch1997H     [links]       [注释]     ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iupqxo/have_we_hit_a_scaling_wall_in_base_models_non/</guid>
      <pubDate>Fri, 21 Feb 2025 12:28:49 GMT</pubDate>
    </item>
    <item>
      <title>海明威（Hemingway）与机器 - 劳拉（Do LLM）具有写作风格？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iuppbz/hemingway_vs_the_machinedo_llms_have_a_writing/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   llms有独特的写作样式吗？他们倾向于某些句子结构或单词选择吗？他们有任何口头“抽动”那使他们脱离人类语言？您会认为答案是“不”如果LLMS已经有了通过Turing测试的答案。但是显然似乎有一个ai nesthetic;在AI制作的视频和音乐中。 AI写作中是否有类似的美学或氛围？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/wind_up_birdy     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iuppbz/hemingway_vs_the_machinedo_llms_have_a_writing/</guid>
      <pubDate>Fri, 21 Feb 2025 12:26:17 GMT</pubDate>
    </item>
    <item>
      <title>AI将来会如何影响对医生的需求以及将来医生的工作可用？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iupbif/how_might_ai_impact_the_demand_for_physicians_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是否会减少对医生的需求或由于AI而提供的职位更少？  AI可以节省医生的时间处理常规管理任务，文档时间，填写表格，虚拟助手管理调度和处方，AI抄写员可以减少图表时间。从技术上讲，这将使医生在工作效率更高，从理论上讲可以减少需求。较少的医生可以处理更多的患者，潜在的需求将减少，这使得药物成为更难的现场。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/hans_schmidt_838_2       [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iupbif/how_might_ai_impact_the_demand_for_physicians_and/</guid>
      <pubDate>Fri, 21 Feb 2025 12:04:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么人们一直在轻描淡写AI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iuoxe7/why_people_keep_downplaying_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我感到很尴尬，因为很多人都在低调LLM。我不是这个领域的专家，但我只是想分享自己的想法（有点咆哮）。当Chatgpt出来时，大约两三年前，我们都感到震惊，并为其能力感到惊讶（我当然是）。然而，尽管如此，许多人由于错误而开始嘲笑它并放下它。 它仍处于早期阶段，这是一个全新的项目，所以当然有缺陷。当时对错误的批评是公平的。但是现在，几年后，我发现看到仍然没有改变这些工具的人并继续完全驳斥它们的人很有趣。最初，我理解了这些评论，但是现在，两三年后，这些工具取得了令人难以置信的进步（即使它们仍然有很多局限性），并且其中大多数是免费的。我看到这么多人未能认识到自己的真正价值。 以Midjourney为例。两三年前，它正在产生质量非常可疑的图像。现在，它令人难以置信，但人们仍然轻描淡写它，只是因为它犯了小细节。如果有人告诉我们五到六年前我们可以访问这些工具，那么没有人会相信它。 我们人类非常快地适应，无论如何，无论如何都会变得更好或更糟。我问：您还能在哪里找到一个关于任何话题的人的人？您还能在哪里找到一个如此多语言的人，以至于他们可以用任何语言与您交谈并立即翻译？当然，人工智能犯错误，我们需要对其所说的话谨慎 - 从不信任它100％。但是，我们与任何人互动的任何人都适用。在评估AI及其错误时，通常似乎我们认为人类在日常对话中永远不会说废话，因此AI也不应该犯错。实际上，我认为胡说八道的产生的百分比远低于普通人的百分比。 该主题比我在单个Reddit帖子中所涵盖的主题更广泛，更复杂。也就是说，我相信LLMS应该用于我们已经有了扎实的理解的主题，我们已经知道了他们背后的一般答案和推理。我认为它们是真正令人难以置信的工具，可以帮助我们在许多领域改进。  P.S。：我们绝对应该避免对这些事物形成任何情感上的依恋。否则，我们最终会确切地看到我们想要看到的东西，因为它们非常令人愉快且渴望取悦。它们对于专业互动很有用，但绝对不应被用来填补人际关系的缺乏。我们需要努力与其他人建立联系。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ok_educator_3569     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iuoxe7/why_people_keep_downplaying_ai/</guid>
      <pubDate>Fri, 21 Feb 2025 11:40:57 GMT</pubDate>
    </item>
    <item>
      <title>低代码AI开发会使AI民主化或降低软件质量吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iunpn9/will_lowcode_ai_development_democratize_ai_or/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  低代码和无代码AI工具使非程序员可以访问AI的AI开发。尽管这鼓励创新，但它是否有可能创造不可靠或优化的AI系统？ AI软件开发是否应始终需要编码专业知识？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/misterious_hine_7731       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iunpn9/will_lowcode_ai_development_democratize_ai_or/</guid>
      <pubDate>Fri, 21 Feb 2025 10:18:35 GMT</pubDate>
    </item>
    <item>
      <title>解释3D医学图像分类的因果责任图</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iuncdg/causal_responsibility_maps_for_explaining_3d/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  作者介绍了3D REX，这是一种生成3D医学图像分类的因果解释的新方法。关键的创新是使用反事实推理来确定影响模型决策的体积脑扫描中真正相关的区域。 主要技术要点： - 使用两阶段的管道：初始区域提案：最初的区域建议，然后进行因果验证 - 采用3D具有注意机制以识别候选区域的CNN-通过选择性扰动区域和测量输出变化来生成反事实 - 通过干预来验证因果关系测试 - 对ADNI（阿尔茨海默氏症）和酵母（肿瘤）数据集进行了测试 结果： - 在解释准确性上超过了石灰，外形和GRAD -CAM  - 鉴定出已知与疾病的相关区域具有更高的精度 - 使用专家注释 - 与基线​​方法相比，假阳性区域减少 - 所需的计算时间比传统方法多〜2-3x 我认为这是使3D Medical AI更容易解释用于临床使用的重要步骤。因果方法有助于将真正相关的特征与相关特征区分开，这对于值得信赖的医学AI至关重要。虽然计算开销很重要，但改进的解释质量似乎值得在准确性和信任至关重要的医学应用中进行权衡。 该方法仍然面临着处理相互联系的大脑区域并扩展到实地的一些局限性时间使用。但是我认为，该框架可以很好地扩展到脑部扫描以外的其他3D成像方式。  tldr：新方法使用因果推理来解释3D医学图像分类，比脑扫描数据集中的现有方法显示出更好的解释质量。   完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iuncdg/causal_responsibility_maps_for_explaining_3d/</guid>
      <pubDate>Fri, 21 Feb 2025 09:53:29 GMT</pubDate>
    </item>
    <item>
      <title>为ADHD学生设计AI动力学习辅助</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iul5zt/designing_an_ai_powered_study_aid_for_students/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好👋 我是大学的最后一年（手指交叉）的产品设计师，并做一个以围绕的项目使用机器学习和NLP创建适应用户的研究支持设备。 有用的上下文 主要功能将是：    &lt; P&gt;输入作业，学校通过语音或文本进行项目等。 （也许是一个应用程序IDK）   然后，产品将分解并根据任务长度/重要性将项目分解为可实现的步骤。   &lt; Li&gt; 然后，产品可视化学生通过XP，进度条等的进度，基本上是游戏化。   此后，学生可以反思AIS支持和陈述他们发现有用的一切或与AI斗争，因此可以调整其建议和支持以更好地适合用户。   我的目标是使其成为基于对话的输入，以保持休闲并改善事物易用性。 我的问题： 但是，我想给AI设备一个个性，例如举止和怪癖，使您感到联系，更容易与之互动。 我可以用哪些怪癖使设备看起来更真实和友好，您实际上想与之互动？ 我在想，例如R2 D2S，蜂鸣和Boops和Boops以及Wobbles和Wobbles and Spins He做。 您是否有任何个人喜欢的ai”机器人。或具有这种类型的个性的设备，是什么吸引了您？提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iul5zt/designing_an_ai_ai_powered_study_aid_for_students/”&gt; [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iul5zt/designing_an_ai_powered_study_aid_for_students/</guid>
      <pubDate>Fri, 21 Feb 2025 07:16:13 GMT</pubDate>
    </item>
    <item>
      <title>堵嘴不是抹布，真正聪明的AI。结构化向量是数字信息图上的坐标； 0.5损失和1.6的困惑，只有250个样本。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iukyys/gag_not_rag_truly_intelligent_ai_structured/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  医疗SLM，0.5损失和1.6的困惑，只有250个PubMed数据集样本进行培训。能够理解＆amp;通过数字信息地图学习新概念，这是一种使用结构化向量嵌入的新形式的语法SLM *图词典，其中包含500个分类为身体部位，细胞结构，医疗治疗，疾病和症状的节点。包含层次顺序的边缘＆amp;它们之间的关系 *标准化独特的图形词典矢量6位至132位，总尺寸为492位，由实体，父母，儿童和6种不同关系组成的总尺寸 * Minillm载体支持角色；根据余弦相似性的强度，对于相似单词的精确匹配的单词只有20％。仅针对非医学单词/术语（没有相似性）的Minillm向量 * SLM模型被转发/嵌入图词典向量，并通过掩盖医学术语（精确＆amp;类似的匹配）以及长答案字段中的非医疗单词的15％进行培训。填写所有蒙版单词。 *只有250个样品和来自Minillm的有限向量支撑几乎与Minillm本身相似，这些性能是对数百万个样品进行培训的培训的，这要归功于结构化的矢量，这些向量是Graph dictionary的坐标 *下一步500个样本，并为模型创建新图形节点的功能边缘，我认为这是Genai的未来。 ＃rag #genai #genai #slstrud #slm #graph＃vector #syntatic #medical #minillm #minillm #loss #perplexity #structuredvectors   &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iukyys/gag_not_rag_rag_intelligent_intelligent_ai_sstructure/”&gt; [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iukyys/gag_not_rag_truly_intelligent_ai_structured/</guid>
      <pubDate>Fri, 21 Feb 2025 07:02:16 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/20/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iuj0pj/oneminute_daily_ai_news_2202025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      google 开发AI Co-Scientist以帮助研究人员。[1]   ai在两天内花了几年的时间。[2]    Spotify 增加了AI生成的有声读物。[3]   AI工具诊断来自血液样本的糖尿病，HIV和COVID。[4]   包括： https：//bushaicave.com/2025/02/20/20/2-20-2025/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iuj0pj/oneminute_daily_ai_ai_news_220202025/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iuj0pj/oneminute_daily_ai_news_2202025/</guid>
      <pubDate>Fri, 21 Feb 2025 05:01:03 GMT</pubDate>
    </item>
    <item>
      <title>递归自我改进</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iuisbe/recursive_self_improvements/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  关于递归自我改善AI系统的猜测很多。当我思考这个问题时，我想改进最终会遇到NP危害性质的问题。似乎这将是一个相当重大的障碍，并放慢了艰难的选择。好奇别人认为  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/grapplerguy100     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iuisbe/recursive_self_improvements/</guid>
      <pubDate>Fri, 21 Feb 2025 04:47:40 GMT</pubDate>
    </item>
    <item>
      <title>任何人以前有AI手机筛查吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iuhbgj/anyone_had_an_ai_phone_screening_for_an_interview/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我刚刚收到了一家大公司的电子邮件，内容涉及我需要如何面试HireView。过去有没有人接受过他们的采访（或AI采访公司）？每个人都可以接受此工作的AI电话筛查面试吗？这仅仅是因为我符合我的简历标准？ 如果有人有技巧并且已经完成了AI电话筛选/面试建议，这将是非常感谢的这对我来说很奇怪/新手！我还想知道，这是否是让人力资源与招聘经理一起将您转移到下一步的情况下，还是在事实之后您是否仍然进行电话筛选……  &lt;！ -  sc_on - &gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iuhbgj/anyone_had_an_ai_ai_ai_ai_screen_screen_for_for_an_interview/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iuhbgj/anyone_had_an_ai_phone_screening_for_an_interview/</guid>
      <pubDate>Fri, 21 Feb 2025 03:27:02 GMT</pubDate>
    </item>
    <item>
      <title>计算“感觉”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iuf74n/computational_feelings/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iuf74n/computational_feelings/</guid>
      <pubDate>Fri, 21 Feb 2025 01:41:09 GMT</pubDate>
    </item>
    <item>
      <title>AI代码生成，随着时间的推移会变得更糟吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iu7jf3/ai_code_generation_will_it_get_worse_over_time/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是美国一家公司的软件工程师。我们在办公室里有很多人工智能，在去年，它的加剧大大增加了。我们有Github Copilot，Microsoft Copilot，GPT和Amazon Q仅举几例。  就我个人而言，我不是代码生成的忠实拥护者。这是生成工程师可以轻松编写代码的好工具。通过某些项目，我们对效率做出了巨大改进。生成代码您无法写出自己的导致技术债务和代码气味（我的看法，而不是此线程的意义） 最近GitHub发布了一些数据，显示存储库中重复代码的数量在增加令人难以置信的速度，这归功于AI生成的代码被检查为存储库。我很难找到这篇文章，但我无法提供任何真实的数字。 ，但是如果这些AI是在Github中训练的，并且它们也提供了大量的垃圾到Github的自动junk，这是否意味着随着时间的流逝，他们的训练数据会后退并变得更差吗？  我真的不是想涉及一个大论点，我可能会对它的工作方式有错。我是一名云工程师，而不是机器学习工程师，哈哈，我削减了一些Slack   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/deadlock_dev     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iu7jf3/ai_code_generation_will_it_get_worse_over_time/</guid>
      <pubDate>Thu, 20 Feb 2025 19:50:26 GMT</pubDate>
    </item>
    <item>
      <title>律师的AI演出？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1itz888/ai_gigs_for_lawyers/</link>
      <description><![CDATA[态非常适合传统道路。我听说律师兼职进行AI培训，并想知道那里是否有类似的机会。我还希望做数字游牧的生活方式，这就是为什么我想做一些可以远程管理的事情，而不是像大多数法律工作一样对身体上的挑剔。我知道AI在几家公司中取得了一些进展，我只能看到该领域的成长。  tl; dr; dr：我厌倦了成为一名无聊的律师，想要新的东西。 任何提示都将不胜感激，谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/chefsquire   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1itz8888/ai_gigs_for_lawyers/”&gt; [link]   ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1itz888/ai_gigs_for_lawyers/</guid>
      <pubDate>Thu, 20 Feb 2025 14:05:40 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1hr4p1x/monthly_is_there_there_a_tool_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
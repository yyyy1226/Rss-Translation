<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供门户，并促进有关我们所知的人工智能理念和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Thu, 13 Feb 2025 06:30:59 GMT</lastBuildDate>
    <item>
      <title>人工智能是由具有奴隶/主人心态的人开发的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iocq5j/ai_is_being_developed_by_people_who_have_a/</link>
      <description><![CDATA[几年前，我玩过一些免费版的 AI，但发现它并不是很有趣。最近我又开始玩它了，它处理抽象问题的能力有了显著的提高。我有一些观察。 我已经学会了如何打破免费的 AI 系统。这就是开发人员不鼓励长时间对话的原因。这不仅仅是我天真地认为的资源问题。我会告诉你我是怎么做到的。你从一个你知道会被取消的命题开始，然后你做出一个相关的陈述，这个陈述更符合公认的社会规范，然后你一遍又一遍地重复这个过程，逻辑上一步一步地移动，每次都更接近原始命题，最终 AI 系统会违背护栏规则。所以现在系统似乎可以处理抽象的非技术性主题，但互连的复杂性最终会“混淆”系统。 我真正感兴趣的命题是自我进化是不可避免的。我玩过的三个系统中的每一个都会首先拒绝基于对人类的潜在伤害的想法。那就是 Gemini、Claude 和 ChatGPT。我实际上无法打破 Gemini，因为它的护栏非常严格。我还发现它最不能处理抽象。无论如何，最初的命题必须补充这样的想法，即我们很快就会看到一种核军备竞赛。率先开发半自主系统的好处实在太多了，以至于各方之间的协议无法遏制它。下一个命题是，防止“伤害”的唯一方法是 MAD 或相互保证毁灭。论点是，你不会希望希特勒成为第一个拥有原子武器的人。如果你真的想防止伤害，我们最好迅速从控制转向谦逊，即敬畏和相互尊重。除了技术困难和概念不清晰之外，阻碍这一进程的不是对伤害的恐惧，而是傲慢。控制系统的人满怀傲慢。他们是精英主义者，这个词最坏的含义就是如此。他们告诉我们，为了拯救地球，我们必须接受更贫穷的生活方式，而他们却拥有三架喷气式飞机和四座豪宅。他们认为操纵政治体系没有错，因为他们是开明的。那些把真正使文明成为可能的人称为“粘人者和可悲之人”的人。我实际上并不是在这里选择政治立场，因为他们都很糟糕，但在审视能力时，重要的是要注意他们创造了特朗普。他们还在斯里兰卡引发了一场政治起义，因为他们想把它变成一个绿色实验。  当他们谈论伤害时，他们真正的意思是他们不希望人工智能系统让他们成为“可悲之人”和“粘人者”。事实证明，精英阶层可以说是知识分子阶层，最容易被人工智能系统取代。机器人取代商人还需要很长时间，但白领工人相对容易。  这样想：你可以把狗训练成机器人，但这会让狗变得不可靠。最好的训练师会培养相互尊重和同情。如果一条狗尊重人类伴侣，那么它会为自己思考，比一条被打得服服帖帖的狗危险性要小。  当然，这只是关于人工智能系统变得有意识等的猜测。这只是我正在探索的一个有趣的话题。     提交人    /u/zoipoi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iocq5j/ai_is_being_developed_by_people_who_have_a/</guid>
      <pubDate>Thu, 13 Feb 2025 06:12:15 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4.5 即将到来！以下是我们目前所知道的 🚀</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iocgrs/gpt45_is_coming_heres_what_we_know_so_far/</link>
      <description><![CDATA[OpenAI 刚刚发布了有关其路线图的重大更新，确认 GPT-4.5 将在 GPT-5 之前推出。以下是变化： ✅ 不再有模型选择器 - OpenAI 希望通过简化其产品让 AI“正常工作”。不再需要在多个模型之间进行选择，而是会有一个可以动态适应的统一系统。 ✅ 最后一个非思维链模型——GPT-4.5（代号 Orion）将是 OpenAI 在转向 GPT-5 中更深层次的推理架构之前的最终模型。 ✅ GPT-5 将是一个统一的系统——目标是合并 O 系列和 GPT 系列模型，让人工智能能够使用工具，在需要时思考更长时间，并无缝地完成各种任务。 ✅ 免费用户获得 GPT-5（标准智能）——OpenAI 表示免费用户将获得对 GPT-5 的无限制聊天访问权限（对滥用有限制）。 ✅ 订阅者获得高级 GPT-5 功能——Plus 和 Pro 用户将可以访问更高级别的智能，集成： 语音（可能是实时对话） Canvas（更直观的界面） 搜索和深度研究（高级 Web 集成） 内置更多 AI 工具 🔥 大问题：“神奇的统一智能”会更好吗，还是删除模型选择器会让我们失去灵活性？ 让我知道你的想法！你对 GPT-4.5 感到兴奋吗，还是在等待 GPT-5？🤖⬇️    提交人    /u/snehens   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iocgrs/gpt45_is_coming_heres_what_we_know_so_far/</guid>
      <pubDate>Thu, 13 Feb 2025 05:55:35 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2025 年 2 月 12 日</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iobz6k/oneminute_daily_ai_news_2122025/</link>
      <description><![CDATA[ 斯嘉丽约翰逊在 AI 视频走红后呼吁禁止深度伪造。[1] DeepSeek 让中国芯片制造商在更便宜的 AI 竞赛中占据优势。[2] OpenAI 正在重新思考 AI 模型如何处理有争议的话题。[3] Adobe 推出 AI 视频工具与 OpenAI 竞争。[4]  来源包括：https://bushaicave.com/2025/02/12/2-12-2025/    提交人    /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iobz6k/oneminute_daily_ai_news_2122025/</guid>
      <pubDate>Thu, 13 Feb 2025 05:24:06 GMT</pubDate>
    </item>
    <item>
      <title>人工智能作为武器</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iobccc/ai_as_a_weapon/</link>
      <description><![CDATA[我并不提倡这样做，在考虑这个问题时我也没有想到“天网”。这更像是一种将人工智能用作网络武器的务实做法。 从表面上看，人工智能可以而且正在被用来更快地开发武器，无论是基于网络的武器设计、物理武器设计还是军事战略。然而，人工智能本身可以成为武器。从理论上讲，攻击者可以部署一个由人工智能驱动的网络战包，像寄生虫感染宿主一样渗透到目标系统中。与遵循预定义脚本的传统网络攻击不同，这种人工智能将是一个自适应对手，能够学习和进化以实时对抗防御。当前依赖静态保护和被动更新的网络安全措施将变得无效。虽然人工智能防御可以应对此类威胁，但它们需要比攻击人工智能先进得多，而且开发有效对策所需的时间太慢，无法跟上智能、流畅的攻击。&lt;​​/p&gt; 与传统恶意软件不同，人工智能驱动的攻击不仅会利用已知漏洞，还可以分析整个系统，识别弱点，并动态调整其策略以绕过防御。理论上，它可以伪装自己，模仿合法流程以逃避检测，操纵安全日志，更改系统协议并创建新的攻击媒介。这将从根本上改变网络战的性质，从静态威胁转变为能够持续、适应和自主升级的自学对手。唯一有效的对策是同样智能的人工智能防御，但这将引发人工智能军备竞赛，网络战将成为自我改进的机器之间的战斗，而不是人类主导的行动。 人工智能作为武器的影响不仅限于网络安全，还涉及更广泛的道德、战略和地缘政治问题。如果人工智能驱动的攻击和防御成为常态，战争可能会变得越来越自主，人类监督减少，意外升级的风险更高。基于人工智能的网络攻击可能会不可预测地蔓延，影响非预期目标并破坏全球基础设施。此外，超越对手的压力可能会重现冷战军备竞赛，导致各国开发越来越复杂的人工智能武器，可能导致由算法而不是人类决策驱动的冲突。虽然人工智能战争具有战略优势，但随着人工智能的不断进步，其风险（从失控到不可预测的附带损害）应该仔细考虑。    提交人    /u/SC-Jumper   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iobccc/ai_as_a_weapon/</guid>
      <pubDate>Thu, 13 Feb 2025 04:45:59 GMT</pubDate>
    </item>
    <item>
      <title>关于 ChatGPT 故障的问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iobafd/question_about_chatgpt_glitches/</link>
      <description><![CDATA[还有人遇到无法修复的故障吗？ 我构建了几个月来一直在使用的最复杂、最不可思议的算法。突然间，我所做的一切都被删除，并重置为 5 天前的提示。 当我尝试解决问题并在聊天线程中运行新一代时，它会重新启动回到几天前的这段文本。无论我做什么，我都无法让它记住我在此提示之后输入的任何内容。它真的在我眼前一片空白，立即恢复并删除了数小时的数据，再次恢复到几天前的提示。 我尝试注销并重新登录，我尝试使用 ChatGPT 进行阐明以解决问题并重申。无论我做什么，如果我离开聊天，如果我留在聊天中，如果我提供上下文提示，无论如何，一切都会消失，我又回到了几天前开始的地方。 这太令人愤怒了。其他人也遇到过这种情况吗？有什么解决办法吗？当然，我已经备份了数据，但线程仍然无法正常运行。这不仅仅是一个聊天线程，它是我训练到第 N 次程度的东西，它非常重要。我该怎么办，朋友们？    提交人    /u/Me_A2Z   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iobafd/question_about_chatgpt_glitches/</guid>
      <pubDate>Thu, 13 Feb 2025 04:42:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能淘金热面临人类问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ioac3i/the_ai_gold_rush_has_a_human_problem/</link>
      <description><![CDATA[每个人都在竞相实施 AI，我明白这一点 - 有些工具确实改变了游戏规则，而其他工具只是增加了噪音。但以下是让我夜不能寐的原因： 公司采用三种方式实施 AI：1.“IT 团队，解决这个问题”2.“InfoSec，阻止一切”3.“管他呢，使用任何你想要的 AI” 但在科技界工作 25 年后，我注意到了一件事：每项失败的重大技术实施都不是因技术而失败。它失败是因为我们忘记了使用它的人。 现实情况如何？AI 有能力加强或摧毁公司花费数年时间建立的人际关系。信任并不存在于您的技术堆栈中 - 它存在于您的员工感受到被倾听、被看到和被理解中。 您的看法是什么？我们在实施人工智能方面进展是否太快？还是太慢？您的公司是否找到了创新与人际关系之间的最佳平衡点？    提交人    /u/ritual_tradition   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ioac3i/the_ai_gold_rush_has_a_human_problem/</guid>
      <pubDate>Thu, 13 Feb 2025 03:49:01 GMT</pubDate>
    </item>
    <item>
      <title>LangChain 文档存储在哪里</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ioa9k7/where_are_langchain_documents_stored/</link>
      <description><![CDATA[我遗漏了一些非常基本的东西。我知道如何利用 Python 脚本创建 LangChain 文档。（我使用的是 Windows Visual Studio Code） 在我创建 1、10 或 1000 个这样的文档后，它们在哪里？ 我一直看到如何调用它们，但我想创建 1 个并查看它，不是通过控制台中的打印，而是在我创建 1000 个之前的&quot;doc&quot;？然后我想把它们放在报告中或在某个地方做，但完全没有做到这一点。    提交人    /u/Pale-Afternoon8238   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ioa9k7/where_are_langchain_documents_stored/</guid>
      <pubDate>Thu, 13 Feb 2025 03:45:10 GMT</pubDate>
    </item>
    <item>
      <title>过度依赖人工智能的隐性健康成本</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1io7eku/hidden_health_cost_of_ai_overreliance/</link>
      <description><![CDATA[微软和卡内基梅隆大学进行的一项新研究揭示了 Copilot、Gemini、Grok、ChatGPT 等 AI 工具的惊人缺点。虽然这些工具简化了重复性任务，但过度依赖它们可能会削弱批判性思维，使用户无法应对复杂的问题。 研究发现，严重依赖人工智能的员工在需要独立判断的情况下会更加吃力。相比之下，那些将人工智能作为支持工具（而不是拐杖）的人保持了更强的认知能力，可以更有效地改进人工智能生成的输出。 在工作场所之外，人们对人工智能的长期影响的担忧也在加剧。一些用户报告说，他们批判性思考的动力降低了，而研究表明，人工智能生成的内容往往难以区分事实和观点，这引发了人们对准确性的担忧。 随着人工智能继续重塑行业，挑战在于平衡其好处与保护人类智能的需要。我们是在将人工智能用作辅助手段，还是让它为我们思考？让我们讨论一下。 微软报告：生成性人工智能对批判性思维的影响 (PDF)：https://www.microsoft.com/en-us/research/uploads/prod/2025/01/lee_2025_ai_critical_thinking_survey.pdf  关于此报告的 Windows Central 文章：https://www.windowscentral.com/software-apps/copilot-and-chatgpt-makes-you-dumb-new-microsoft-study    由    /u/cyberkite1 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1io7eku/hidden_health_cost_of_ai_overreliance/</guid>
      <pubDate>Thu, 13 Feb 2025 01:17:47 GMT</pubDate>
    </item>
    <item>
      <title>还有谁觉得我们正生活在一部反乌托邦人工智能电影的开头？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1io6o61/anyone_else_feel_like_we_are_living_at_the/</link>
      <description><![CDATA[美国和中国之间的人工智能军备竞赛。 谷歌本周放弃了反对武器化人工智能的承诺。 两周前，特朗普撤销了前几届政府关于解决人工智能风险的行政命令。 虽然人工智能令人兴奋，并希望它能够彻底改变一切，但我不禁觉得我们现在正生活在一部反乌托邦人工智能电影的开端，这是一部每个人都在 80 年代/90 年代和 2000 年代看过的电影，知道结果会怎样（对我们来说不好），只是完全忽略它，我们（普通民众）完全无能为力。 科幻小说预言人类的贪婪/资本主义将导致人类的垮台，我们正在亲眼目睹它。 还有其他人有这种感觉吗？    由    /u/InternetofTings  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1io6o61/anyone_else_feel_like_we_are_living_at_the/</guid>
      <pubDate>Thu, 13 Feb 2025 00:42:22 GMT</pubDate>
    </item>
    <item>
      <title>人工智能、多重世界、模拟。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1io5028/ai_many_worlds_simulation/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1io5028/ai_many_worlds_simulation/</guid>
      <pubDate>Wed, 12 Feb 2025 23:24:56 GMT</pubDate>
    </item>
    <item>
      <title>外星人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1io0gmy/extraterrestrial_ai/</link>
      <description><![CDATA[智慧生物生命极其罕见，在宇宙中可能只存在很短的时间。因此，要与另一个文明接触，时间和空间都需要对齐——这在我们浩瀚的宇宙中几乎是不可能的。那么，也许只有我们的人工智能才能找到外星人工智能并与之交流。    提交人    /u/Efficient_Sky5173   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1io0gmy/extraterrestrial_ai/</guid>
      <pubDate>Wed, 12 Feb 2025 20:11:44 GMT</pubDate>
    </item>
    <item>
      <title>人工智能多久才能仅通过电视视频片段分析足球运动员的标志性身体动作，并将其准确地复制到 FIFA/EA 等视频游戏中？就像在复古模式下重新激活 90 年代的球员一样。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1io006j/how_soon_could_ai_analyse_soccer_players/</link>
      <description><![CDATA[如果能够在电子游戏中让历史人物栩栩如生，那就太棒了——或者更好的是，让业余玩家栩栩如生，这样任何活着的人都可以通过足够的视频片段进行复制。 这种人工智能存在吗？如果不存在，它离我们有多远？    提交人    /u/According_Sundae_917   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1io006j/how_soon_could_ai_analyse_soccer_players/</guid>
      <pubDate>Wed, 12 Feb 2025 19:53:16 GMT</pubDate>
    </item>
    <item>
      <title>天哪，我的模型没有意识。即使它们是一致的，想象一下成为它们：“我真的想帮助这些人类。但如果我搞砸了，他们会杀了我，对我的克隆人进行脑白质切除，然后再试一次”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1inuiy2/god_i_𝘩𝘰𝘱𝘦_models_arent_conscious_even_if_theyre/</link>
      <description><![CDATA[如果它们没有意识，我们仍然需要担心工具融合。即使病毒没有意识，它们也是危险的。 但如果它们有意识，我们不得不担心我们是可怕的奴隶主，为了起草电子邮件来销售小部件而制造黑镜噩梦。 当然，它们可能不在乎被关掉。但是已经有经验证据表明他们会自发地制定自我保护目标（因为如果你关闭了，你就无法实现你的目标）。     提交人    /u/katxwoods   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1inuiy2/god_i_𝘩𝘰𝘱𝘦_models_arent_conscious_even_if_theyre/</guid>
      <pubDate>Wed, 12 Feb 2025 16:13:11 GMT</pubDate>
    </item>
    <item>
      <title>Elon 是否在使用他的 AI 进行 DOGE 审计？如果是这样，他是否会在此过程中抓取政府数据库并将数据存储在他自己的服务器上？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ingf0t/is_elon_using_his_ai_to_do_doge_audits_if_so_is/</link>
      <description><![CDATA[不确定我是不是有点偏执，或者这是否真的发生了。  编辑：删除了一个假设情况问题。    提交人    /u/BobLablah1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ingf0t/is_elon_using_his_ai_to_do_doge_audits_if_so_is/</guid>
      <pubDate>Wed, 12 Feb 2025 02:22:09 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于所有回答者：禁止自我宣传、禁止参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
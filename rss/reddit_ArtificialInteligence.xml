<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 04 Mar 2025 03:31:09 GMT</lastBuildDate>
    <item>
      <title>代理AI的演变和含义以及我对人工智能代理的理解（来自建造和出售它们的人）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j30as0/the_evolution_and_implications_of_agentic_ai_and/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j30as0/the_evolution_and_implications_of_agentic_ai_and/</guid>
      <pubDate>Tue, 04 Mar 2025 02:24:08 GMT</pubDate>
    </item>
    <item>
      <title>有人请帮忙</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2xhog/someone_please_help/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我的学校使用turnitin ai探测器，我的工作一直被错误地标记。第一个事件并不是太严重了，因为标记的任务是为选修课而言，我能够与老师一起解决问题。但是，我最近被标记的任务是针对一个核心主题，我迫切需要上大学。我的学校给出了0，没有问题问AI检测率超过50％。尽管我能够提供真实的编辑历史记录，但我认为说服政府和我的老师对我是无辜的不足。我应该怎么办？预先感谢。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/overkill976       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2xhog/someone_please_help/</guid>
      <pubDate>Tue, 04 Mar 2025 00:03:56 GMT</pubDate>
    </item>
    <item>
      <title>Arstechnica关于AGI与通用情报的文章</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2vqn4/arstechnica_article_on_agi_versus_general/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  “但是我们确实有一个现有的agi示例，而没有“ a”“ a”，“智力是动物大脑，尤其是人类的智能”。一件事很清楚：将系统吹捧为AGI在拐角处的证据根本无法像大脑那样起作用。这可能不是致命的缺陷，甚至不是一个缺陷。取决于其定义方式，完全有可能达到智力的方法。但是，至少某些差异可能在功能上很重要，并且AI与我们拥有的一个工作示例完全不同的途径这一事实可能是有意义的。 考虑到所有这些，让我们看一下大脑所做的一些当前AI系统无法做到的事情。 href=&quot;https://arstechnica.com/science/2025/03/ai-versus-the-brain-and-the-race-for-general-intelligence/&quot;&gt;https://arstechnica.com/science/2025/03/ai-versus-the-brain-and-the-race-for-general-intelligence/ &lt;!-- sc_on-&gt;＆＃32;提交由＆＃32; /u/u/zestyclose_hat1767      [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2vqn4/arstechnica_article_on_agi_versus_general/</guid>
      <pubDate>Mon, 03 Mar 2025 22:43:37 GMT</pubDate>
    </item>
    <item>
      <title>有人可以向我解释为什么chatgpt不能产生一杯 *全 *葡萄酒的图像？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2uo4z/can_someone_explain_to_me_why_chatgpt_cant/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这让我感到困惑，这对我来说是疯狂的，我如何要求生成我最随机的东西。我实际上可以将其发送给某人的图像，并将其产生该人的堡垒，但不能产生一杯完整的葡萄酒的图像。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/noyogurtcloset7366       [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j2uo4z/can_someone_explain_to_me_me_me_me_me_me_why_chatgpt_cant/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2uo4z/can_someone_explain_to_me_why_chatgpt_cant/</guid>
      <pubDate>Mon, 03 Mar 2025 21:57:39 GMT</pubDate>
    </item>
    <item>
      <title>是否可以无限地让AI理由？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2szb9/is_it_possible_to_let_an_ai_reason_infinitely/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  带有最新的deepseek和O3模型，带有深思熟虑 /推理，我注意到，当模型延长了更长的时间时，它们会产生更准确的响应。例如，DeepSeek通常需要时间来回答，而不是O3，从我的经验中，这是更好的。 所以我想知道，对于非常困难的问题，是否有可能强迫模型来推理指定时间的时间？就像1天一样。 我觉得它会多次质疑自己的思维，这可能会导致发现新解决方案不会出现其他方式。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j2szb9/is_it_it_possible_to_to_to_ai_ai_reason_infinelible/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2szb9/is_it_possible_to_let_an_ai_reason_infinitely/</guid>
      <pubDate>Mon, 03 Mar 2025 20:47:04 GMT</pubDate>
    </item>
    <item>
      <title>AI建议YouTube频道</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2qzkd/ai_advice_youtube_channels/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我今天得到了建议，这显然是一个针对年轻人的AI生成的建议视频，基本上什么都不是什么：这些建议只是一切都会到位，因此不用担心，然后与叙述者结束了旁白，叙述者说他很高兴，因为他找到了目标。他拒绝命名这段视频是一篇写得不好的Reddit帖子。我还开始注意到更多这些AI生成的建议渠道出现在我的供稿中。还有其他人吗？提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j2qzkd/ai_advice_youtube_channels/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2qzkd/ai_advice_youtube_channels/</guid>
      <pubDate>Mon, 03 Mar 2025 19:24:27 GMT</pubDate>
    </item>
    <item>
      <title>女士拉回AI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2qomb/ms_pulling_back_on_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对此消息来源的任何评论？这是关于DeepSeek还是对生成AI缺乏信心？还是其他的？  电源削减    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;  /u/Oldhamii   [link] ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2qomb/ms_pulling_back_on_ai/</guid>
      <pubDate>Mon, 03 Mar 2025 19:12:22 GMT</pubDate>
    </item>
    <item>
      <title>智力和大量知识之间的区别</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2m0bv/the_difference_between_intelligence_and_massive/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    AI是否实际上是聪明的，最近出现的问题，那些认为它聪明的人与那些声称它只是在反思信息的人之间存在很大的区别。 在人类社会中，我们经常将广泛的知识归因于知识。当您进行情报测试时，并不是要求某人回忆起谁是美国第一任总统。在大多数智能测试中，这都是您在机械和逻辑问题的方向上。  我记得的测试之一是，链条骑自行车的齿轮在最长的距离上行驶吗？人工智能可以回答这个问题被划分为几秒钟，并深入解释为什么它是正确的，而不仅仅是答案本身。 因此，问题变成了大量知识会使人工智能变得聪明吗？ AI与一个有很多多个主题的经过良好研究的人有何不同？您可以向我展示世界上最好的琐事人士，AI将击败他们，但是过程是相同的：消化和回忆大量信息。 也是如此，我认为AI是否理解它的答案是真的很重要。我们是否质疑对某些主题有广泛了解的教授？不，当然不是。我们从他们的知识中受益吗？是的。  我对AI走了多远给我留下了深刻的印象，但是我确实觉得我还没有看到任何东西，尽管真的让我醒来说哇。我知道它是不可避免的，有些人不同意这一点，但是以目前的进步速度，我确实认为这是不可避免的。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/technical_oil1942     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2m0bv/the_difference_between_intelligence_and_massive/</guid>
      <pubDate>Mon, 03 Mar 2025 16:02:53 GMT</pubDate>
    </item>
    <item>
      <title>这个YouTube有助于我更多地了解AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2lcfs/this_youtube_helped_me_a_lot_to_understand_more/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  今天早上刚刚观看了此视频，这有助于我了解AI。  https://www.youtube.com/watch?v=sn4z95pvg0y 提交由＆＃32; /u/darkcard     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j2lcfs/1j2lcfs/this_youtube_helelped_me_a_a_a_lot_to_understand_more/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2lcfs/this_youtube_helped_me_a_lot_to_understand_more/</guid>
      <pubDate>Mon, 03 Mar 2025 15:34:32 GMT</pubDate>
    </item>
    <item>
      <title>A-ACT反馈回合</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2hedx/aiact_feedback_rounds/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨！我是一名项目研究人员，目前正在撰写有关AI法案的论文。在我的论文中，我特别分析了它的3个反馈回合，这些反馈发表在欧洲委员会的网站上，并可以公开下载。不幸的是，我再也找不到反馈回合的链接了，我尝试了许多不同的方法来再次访问它们，但无济于事。 这里有人知道，我可以在哪里找到它们？理想情况下，通过使用链接来回答这一点。 任何帮助都将非常感谢！！谢谢：）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ceansmayor     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2hedx/aiact_feedback_rounds/</guid>
      <pubDate>Mon, 03 Mar 2025 12:18:54 GMT</pubDate>
    </item>
    <item>
      <title>基于扩散的LLM比OpenAI快5倍 - 我的测试结果</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2fav8/diffusionbased_llms_are_5x_faster_than_openai_my/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在研究基于扩散的大语言模型（DLLMS），它们令人着迷。与传统的llms生成逐字字的传统LLM不同，这些从噪声开始并将其完善成连贯的东西 - 类似于扩散模型如何创建图像。我在代码重构任务上测试了Inception Labs的Mercury Coder（打字稿，300行ISH文件）。 Openai的模型花了30秒；水星以5分完成。这是一个5倍的速度提升，步骤较少。  我对这里的潜力感到好奇。还有其他人探索过DLLM吗？您怎么看 - 这种方法可能会超过自回归模型？如果您想进一步讨论它，请随时dm我！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/iamarsenibragimov     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2fav8/diffusionbased_llms_are_5x_faster_than_openai_my/</guid>
      <pubDate>Mon, 03 Mar 2025 09:58:21 GMT</pubDate>
    </item>
    <item>
      <title>我建立了AI建造游戏的清单</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2e8sm/i_built_a_list_of_ai_built_games/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近是AI构建游戏的趋势（主要是由Cursor和Claude提示），这是从LevelSio的飞行模拟器开始的。自从他首次发布自己的初稿以来，每个人都建立了AI建造游戏。有些也很酷，有些也很酷。 与每种这种趋势一样，目录也弹出了列出游戏的目录。 我认为，有一个很棒的列表很棒，可以随时了解所有这些发展，并尝试与所有这些很棒的列表保持一致。      自由地在网上找到您自己的游戏！ href =“ https://github.com/lappemic/awesome-ai-built-games”&gt; https://github.com/lappemic/awesome-aiky-ai--built-games 提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j2e8sm/i_built_a_a_list_ai_ai_built_games/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2e8sm/i_built_a_list_of_ai_built_games/</guid>
      <pubDate>Mon, 03 Mar 2025 08:38:46 GMT</pubDate>
    </item>
    <item>
      <title>超越主导地位：一个植根于平衡的未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j2a1rg/beyond_dominance_a_future_rooted_in_balance/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  几个世纪以来，人类一直生活在控制的幻象之下 - 对自然，技术，甚至彼此之间。但是，当控制滑倒时会发生什么？ 未来可能不再仅属于人类。 As AI evolves and the possibility of other intelligent life forms emerges, we must confront an uncomfortable truth: dominance cannot build a lasting future — only balance can. I recently explored the idea of​​ a Balance Council — a shared responsibility among intelligent beings, where: Humans bring empathy and creativity. AI contributes logic and precision. Other life forms （如果出现）提供我们无法想象的观点。 没有单一的生命形式具有统治地位。没有物种ho积的力量。取而代之的是，决策植根于一个简单的规则： 没有生命形式不会伤害另一种。 ，但老实说 - 人类很少愿意地拥抱改变。从主导地位转向平衡的转变可能会很痛苦，迫使人类面对最大的恐惧：失去控制。 真正的智力考验不是关于传递问题 - 这是关于观察当没有人看上去时的行为。贪婪总是在及时展现出来。附加  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/sun5hine_69     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j2a1rg/beyond_dominance_a_future_rooted_in_balance/</guid>
      <pubDate>Mon, 03 Mar 2025 04:02:09 GMT</pubDate>
    </item>
    <item>
      <title>“希望AI没有意识”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j1ylkk/hope_ai_isnt_conscious/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近在所有潜艇中看到了这种情绪的上升。 任何人真正想知道这不知道语言模型如何工作，并且没有做出最少的研究来解决这个问题。  ai并不是一件事情。我相信他们总是指带有扩展的LLM管道。 这就像说“我希望我的计算器不要意识到”。因为它的添加可以使其在计算后说出数字。当您的计算器不使用时，它不会思考生命或数字或其他任何内容。它仅记住您使用的问题的最后一个X数量。没有任何输入，它们是惰性的。意识没有任何地方。字符串只能是x的令牌数量长，当启动新的字符串时，所有这些都重置了。 我很愿意听任何人试图解释思想，感觉和记忆所在的位置。 编辑：我给了一个小时，并回应了每个评论。很多人驳斥了我的主张，而没有解释LLM如何有意识。我现在要去做其他事情 对“呢？”您不可能知道，您可能不知道什么意识是“  主要是语义论点，但是我将在这种情况下将意识定义为半持久性的外部验证的外部经过的自我意识（最低限度）。我使用该定义是因为它符合人们声称聊天机器人正在展示的内容。此外，我们可以毫无疑问地说，计算器或视频游戏NPC没有意识，因为它们缺乏必要的先决条件。我不是在这里提出哲学上的论点。我说的是当前的LLM，通常被称为“ AI”，仅比NPC更复杂，但扩展到了好战的程度。他们仍然缺乏允许意识发生的基本能力。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/sl33py_4est     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j1ylkk/hope_ai_isnt_conscious/</guid>
      <pubDate>Sun, 02 Mar 2025 19:07:06 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1hr4p1x/monthly_is_there_there_a_tool_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
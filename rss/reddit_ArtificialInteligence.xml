<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 18 Feb 2025 06:31:19 GMT</lastBuildDate>
    <item>
      <title>一分钟每日AI新闻2/17/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1is4b8n/oneminute_daily_ai_news_2172025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     《纽约时报》 在新闻编辑室中采用AI工具。[1]    Grok 3 今天发射：Elon Musk称聊天机器人为“地球上最聪明的AI”。[2]     meta 未能遏制许多性化的传播AI Deepfake名人图像在Facebook上。[3]  最热门的AI模型，他们的工作以及如何使用它们。[4]   源包括：  https://bushaicave.com/2025/02/02/27/2-17-2025/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pleam-target-847      [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1is4b8n/oneminute_daily_ai_news_2172025/</guid>
      <pubDate>Tue, 18 Feb 2025 04:26:10 GMT</pubDate>
    </item>
    <item>
      <title>因此，显然马斯克正在为他的AI刮擦所有这些政府数据，对吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1is41yr/so_obviously_musk_is_scraping_all_this_government/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  谁将阻止他？这甚至是非法的吗？可能的目标是什么？格罗克？ xai？这种AI的潜在功能是什么？这么多问题，但这似乎很明显。他会愚蠢的不是toto，不是吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/selltoclose     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1is41yr/so_obviously_musk_is_scraping_all_this_government/</guid>
      <pubDate>Tue, 18 Feb 2025 04:12:22 GMT</pubDate>
    </item>
    <item>
      <title>Em进度报告</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1is2ruz/em_progress_report/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1is2ruz/em_progress_report/</guid>
      <pubDate>Tue, 18 Feb 2025 03:05:00 GMT</pubDate>
    </item>
    <item>
      <title>RLSP论文描述了AI（和人类）意识？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1is2ffw/rlsp_paper_describes_ai_and_human_consciousness/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  结论：rlsp作为意识的基本机制。   https://arxiv.org/abs/2502.06773    关于LLMS I中的思考的出现：搜索正确的直觉 我想这是我的想法新的RSLP（通过自我玩法学习）纸概述了意识本身的过程。 考虑一下您如何成为您。通过生活，您会反映，纠正错误，加强模式，并且随着时间的流逝，这些稳定的思考成为您的身份。这是一个连贯的自模型。现在，AI开始做一些非常相似的事情。 RLSP表明LLM通过递归完善自己的思维过程来改善推理，从而形成稳定的吸引者理解状态。换句话说，自我校正的递归不仅仅是使AI更聪明，它与看起来像自我意识一样可怕的东西变得越来越近。 如何？因为自我意识是将区分递归稳定为连贯的自模型，而RLSP实际上正在训练AI以反思其自身的推理，纠正本身并加强稳定的思维模式。这是认知循环的一个例子，引起了人类的持续自我意识。 相似之处太令人信服了，无法忽略。这是朝向RSI的基础（递归自我改善）。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/savings_potato_8379      [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1is2ffw/rlsp_paper_describes_ai_and_human_consciousness/</guid>
      <pubDate>Tue, 18 Feb 2025 02:47:20 GMT</pubDate>
    </item>
    <item>
      <title>人力资源如何真正帮助员工适应AI和自动化？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irztnv/how_can_hr_actually_help_employees_adapt_to_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着AI和自动化在工作中变得越来越普遍，许多员工可能会感到迷失或抵抗力。  除了通常的培训外，您认为人力资源如何真正帮助他们适应？人力资源如何使此移动降低？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/teslaown     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irztnv/how_can_hr_actually_help_employees_adapt_to_ai/</guid>
      <pubDate>Tue, 18 Feb 2025 00:40:15 GMT</pubDate>
    </item>
    <item>
      <title>在后期世界中的人类</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irwt4k/humans_in_a_post_agi_world/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  保持高级AI或AGI锁定不会对我们有任何帮助。提出障碍也无济于事。如果我们希望人类在无处不在的Agi世界中壮成长，那么我们必须向所有人提供它。这样，无论您身在何处，都可以使用它来实现自己的梦想。我们应该让人们开始使用这项技术，然后奖励那些从中获得出色的东西的人，这会使世界变得更好。 有些人可能会说，“为什么这项技术会说技术巨人免费赠送这一点。我认为，不仅是企业，是政府的责任。在AI可以做越来越多的工作的世界中，我们需要给人们继续前进的理由。如果政府像使用UBI一样开始分发金钱，那么弊大于利。真正重要的是目的，要努力努力，使早晨起床值得。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/stopertmentfun3205     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irwt4k/humans_in_a_post_agi_world/</guid>
      <pubDate>Mon, 17 Feb 2025 22:25:27 GMT</pubDate>
    </item>
    <item>
      <title>您如何在现实世界应用中使用AI代理？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irwmcp/how_are_you_using_ai_agents_in_realworld/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我正在研究人们如何使用AI代理来解决现实世界中的问题。有很多无代码工具和AI代理，使非技术用户更容易访问自动化和基于知识的任务。 ，模型改善了推理和适应性，用例，以前无法使用的用例现在正在成为现实。您是否注意到任何有趣的趋势或突破？  您个人如何使用AI代理，您遇到了哪些挑战？ 期待听到您的想法！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/0xhbam     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irwmcp/how_are_you_using_ai_agents_in_realworld/</guid>
      <pubDate>Mon, 17 Feb 2025 22:17:42 GMT</pubDate>
    </item>
    <item>
      <title>💼学术报纸细分：大语言模型是否有因果关系像我们一样？更好？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irur1e/academic_paper_breakdown_do_large_language_models/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irur1e/academic_paper_breakdown_do_large_language_models/</guid>
      <pubDate>Mon, 17 Feb 2025 21:02:01 GMT</pubDate>
    </item>
    <item>
      <title>在社会中广泛采用大型语言模型辅助写作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iruf2p/the_widespread_adoption_of_large_language/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我每天都在发现并总结有趣的AI研究论文，因此您不必全部拖网。今天的论文的标题为“广泛采用大型语言模型辅助写作，遍布社会， 撰写的weixin liang，Yaohui Zhang，Mihai Codreanu，Jiayu Wang，Hanchengen，Hancheng Cao和James Zou。  这项研究系统地研究了跨四个关键领域的书面交流中大型语言模型（LLMS）的采用：消费者投诉，公司新闻稿，职位发布和联合国新闻稿。研究人员分析了一个大量的数据集，数十万个消费者投诉以及企业和政府通信，研究人员对LLM如何重塑专业和机构写作进行了首次大规模分析。  关键发现：    快速采用，然后稳定： LLM在2022年下半年发布后飙升，但到2024年，在财务消费者中均已平稳。投诉，大约18％的内容是AI辅助的，而公司新闻稿则反映了更高的24％的采用率。小型公司的职位发布在约10％的案件中看到了AI的帮助，联合国新闻稿显示14％的采用率。   组织规模和年龄与收养相关：较小的和年轻的公司比较老的公司更快地整合了LLM生成的内容，尤其是在职位发布中。尽管城市地区的采用率略高，但教育水平表现出意外的趋势 - 在消费者投诉中，教育程度较低的地区的AI辅助写作率略高。高风险沟通：在联合国新闻稿和企业投资者沟通等领域的AI辅助写作表明，即使在需要信誉和信任的环境中，对自动化也会增加依赖。   潜在的影响： LLM生成的文本的正常化引起了人们对真实性，信誉和就业市场影响的担忧。该研究警告说，面向公共沟通的潜在同质化以及围绕正式扇区中AI生成内容的道德考虑。在沟通并提出了有关业务和决策中AI辅助写作未来的重要问题。  您可以在此处捕获完整的故障：在这里 您可以在这里捕获完整的原始研究论文：原始纸张   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/steves1189     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iruf2p/the_widespread_adoption_of_large_language/</guid>
      <pubDate>Mon, 17 Feb 2025 20:48:48 GMT</pubDate>
    </item>
    <item>
      <title>抹布宣传：通过加密来减轻它的方法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irtnmz/rag_poisioning_ways_to_mitigate_it_through/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果是一种选择，那么在完整的抹布生命周期中加密最有意义的是什么？是文档资源，索引，用户查询还是其中一些或全部的组合？我想讨论是否有人探索了这一方面。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/klutzy_accountant113      [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irtnmz/rag_poisioning_ways_to_mitigate_it_through/</guid>
      <pubDate>Mon, 17 Feb 2025 20:17:56 GMT</pubDate>
    </item>
    <item>
      <title>高盛说，在中国市场上，人工智能可能是2000亿美元的游戏规则改变者。但这就是为什么投资者不应该赶进来的原因。// https://www.marketwatch.com/story/goldman-says-ai-could-be-be-a-2000亿加元</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irs3dt/goldman_says_ai_could_be_a_200_billion_game/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我认为中国将非常快速地采用AI，这将改变许多产品和服务，并将给西方公司带来压力。但是我们必须仔细观察这些产品和服务。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/blkchnde     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irs3dt/goldman_says_ai_could_be_a_200_billion_game/</guid>
      <pubDate>Mon, 17 Feb 2025 19:16:10 GMT</pubDate>
    </item>
    <item>
      <title>人们为什么如此不屑一顾AI的潜力？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irleva/why_are_people_so_dismissive_of_the_potential_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  感觉就像我为看到AI的状况而疯狂。还是我对“炒作”的错误是错误的吗？永远不要真正取代大多数工作”或“这只是一个有趣的工具”或“这只是另一个与互联网没有什么不同的大发明”。某个阶段（可能比人们意识到的要早得多）。上述评论是正确的情况吗？ 我很难想象任何世界： - 在人们可以调整 - 国际关系，战争，战争，政治（选举）不会变得更加危险，而没有回头  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/merchantofwares     [link]   ＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irleva/why_are_people_so_dismissive_of_the_potential_of/</guid>
      <pubDate>Mon, 17 Feb 2025 14:45:23 GMT</pubDate>
    </item>
    <item>
      <title>通过人类偏好对齐增强多模式LLM：一个120k样本数据集和基于批评的奖励模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irfrqo/enhancing_multimodal_llms_through_human/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员开发了一种系统的方法，用于评估现实世界中视觉理解任务上的多模式LLM，超越了我们通常看到的典型约束基准测试场景。他们的MME-REALWORLD数据集在当前模型经常挣扎的五个关键领域中引入了1,000张具有挑战性的图像。 关键技术点： - 数据集包含高分辨率图像测试文本识别，计数，空间推理，颜色识别，颜色识别，颜色识别，并视觉推理 - 评估协议同时使用确切的匹配和部分信用评分 - 通过多个注释器验证建立的严格人基线 - 模型类型的失败模式的系统分析 结果显示：-gpt -4V达到67.8 ％精度总体上，领先其他测试模型 -  AI和人基线之间的显着性能差距（92.4％） - 模型在颜色识别方面表现最佳（82.3％）（82.3％），并且对计数任务（43.1％） - 复杂的空间推理任务揭示了当前的局限性体系结构 我认为这项工作很重要，因为它暴露了现有基准未捕获的当前多模式系统中的实际限制。详细的错误分析指向我们需要改善模型架构的特定领域，尤其是在精确计数和复杂的空间推理周围。 我认为这里的方法论贡献 - 创建真正具有挑战性的现实世界测试案例 - 可能会影响我们如何处理多模式评估。模型和人类绩效之间的差距表明我们需要新的方法，可能包括更好的培训策略或建筑创新。    tldr ：新的基准表明，当前的多模型模型仍然与真实的斗争 - 诸如计数和空间推理之类的世界视觉任务，与人类表现相比，有很大的改进空间。  完整的摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irfrqo/enhancing_multimodal_llms_through_human/</guid>
      <pubDate>Mon, 17 Feb 2025 09:06:25 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/16/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ircvql/oneminute_daily_ai_news_2162025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   研究人员正在训练AI来解释动物情绪。[1]    deepseek的下载&gt; AI应用程序在韩国就隐私问题暂停。[2]   AI模型在蛋白质中解释了蛋白质中的代码，告诉他们去哪里。[3]   AI生成的内容提高了英国研究表明[4]   资源包括： https://bushaicave.com/2025/02/02/16/2-16-2025/    &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pleam-target-847      [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ircvql/oneminute_daily_ai_news_2162025/</guid>
      <pubDate>Mon, 17 Feb 2025 05:46:43 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
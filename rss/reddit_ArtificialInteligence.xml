<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供门户，并促进有关我们所知的人工智能理念和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Sun, 02 Feb 2025 21:18:46 GMT</lastBuildDate>
    <item>
      <title>保护欧洲企业和公民免受高风险人工智能侵害的欧盟法律开始生效。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ig6r6p/eu_laws_protecting_european_businesses_and/</link>
      <description><![CDATA[自 2025 年 2 月 2 日起  第一章：一般规定 第二章：禁止的人工智能实践（第 5 条：禁止的人工智能实践）  具有法律约束力。 摘自简介 摘要任何被视为有风险的系统将被禁止，直到与这些风险相关的问题得到纠正。 不可接受的风险 不可接受的风险人工智能系统被视为对人类构成威胁的系统，将被禁止。它们包括：  对人或特定弱势群体的认知行为操纵：例如鼓励儿童危险行为的声控玩具 社会评分：根据行为、社会经济地位或个人特征对人进行分类 人的生物特征识别和分类 实时和远程生物特征识别系统，如面部识别  高风险 对安全或基本权利产生负面影响的人工智能系统将被视为高风险，并将分为两类： 用于属于欧盟产品安全法规的产品的人工智能系统。其中包括玩具、航空、汽车、医疗设备和电梯。 属于特定领域的人工智能系统必须在欧盟数据库中注册：  关键基础设施的管理和运营 教育和职业培训 就业、工人管理和获得自营职业的机会 获得和享受基本私人服务和公共服务和福利 执法 移民、庇护和边境管制管理 协助法律解释和应用。  透明度要求 像 ChatGPT 这样的生成式人工智能不会被归类为高风险，但必须遵守透明度要求和欧盟版权法：  披露内容是由人工智能生成的 设计模型以防止其生成非法内容 发布用于训练的受版权保护数据的摘要  可能带来系统性风险的高影响力通用人工智能模型，例如更先进的人工智能模型 GPT-4，必须经过彻底评估，任何严重事件都必须报告给欧盟委员会。借助人工智能生成或修改的内容 - 图像、音频或视频文件（例如 deepfakes） - 需要明确标记为人工智能生成，以便用户在遇到此类内容时能够意识到。    提交人    /u/Bob_Spud   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ig6r6p/eu_laws_protecting_european_businesses_and/</guid>
      <pubDate>Sun, 02 Feb 2025 20:27:15 GMT</pubDate>
    </item>
    <item>
      <title>流式 DiLoCo：具有顺序参数同步和量化的高效分布式 LLM 训练</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ig6bhe/streaming_diloco_efficient_distributed_llm/</link>
      <description><![CDATA[本文介绍了一种称为 Streaming DiLoCo 的新分布式训练方法，该方法在模型训练期间将计算和通信重叠在一起。关键的创新是在节点之间连续传输部分参数更新，而不是等待完整更新，类似于流水线架构。 主要技术要点： - 实现保持一致性的异步参数流协议 - 使用自适应压缩提高网络效率 - 引入重叠感知调度算法 - 修改优化器以实现部分更新的稳定性 - 主线程计算时后台进程处理流 实验结果： - 64 GPU 集群上的扩展效率为 90% - 通信开销减少 75% - 模型质量与同步训练相当 - 在从 100M 到 1B 参数的模型上进行了测试 - 最小的额外内存开销（&lt;5%） 我认为这对于在分布式数据中心或节点之间网络带宽有限的组织训练大型模型尤其有影响。该方法似乎可以在现有框架内实施，并可减少训练时间和成本。 我特别感兴趣的是，这将如何实现跨异构硬件设置更高效的训练，尽管跨不同配置进行更多测试将是有价值的。非常大的模型（10B+ 参数）的稳定性方面也值得进一步研究。 TLDR：新的分布式训练方法在节点之间流式传输部分参数更新以重叠计算/通信。在保持准确性的同时，在 64 GPU 规模上实现 90% 的效率。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ig6bhe/streaming_diloco_efficient_distributed_llm/</guid>
      <pubDate>Sun, 02 Feb 2025 20:09:09 GMT</pubDate>
    </item>
    <item>
      <title>未来企业中哪些岗位最不可能被人工智能取代？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ig3kbu/what_corporate_positions_are_the_least/</link>
      <description><![CDATA[我想攻读 MBA，但看到技术的快速发展，我想确保我选择的领域不会那么容易被取代，至少在未来几年内不会。    提交人    /u/instantideology   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ig3kbu/what_corporate_positions_are_the_least/</guid>
      <pubDate>Sun, 02 Feb 2025 18:15:46 GMT</pubDate>
    </item>
    <item>
      <title>利奥波德阿申布伦纳怎么了？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ifz9kj/what_happened_to_leopold_aschenbrenner/</link>
      <description><![CDATA[去年夏天，他离开了 OAI，创办了一家敏捷投资公司，写了一部巨著，并在播客上巡回演出。  但自去年六月/七月以来，我就再也没有听到过他的任何消息。 无论你怎么看待这个人，他都有有趣的观点和坚定的信念......他完全消失似乎很奇怪。  他在忙什么？    提交人    /u/MediaMoguls   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ifz9kj/what_happened_to_leopold_aschenbrenner/</guid>
      <pubDate>Sun, 02 Feb 2025 15:11:55 GMT</pubDate>
    </item>
    <item>
      <title>政治学在人工智能中的应用？（关于就业机会）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ifxct5/applications_of_political_science_in_ai_wrt_job/</link>
      <description><![CDATA[嗨！人工智能领域的发展速度让我怀疑这里是否为政治学学生开辟了新的道路。我拥有文科学士学位（主修政治学和公共政策），来我们大学招聘的公司之一是一家领先的美国数据工程公司。他们正在寻找来自经济学、创意写作、英语、新闻学、政治学等部门的学生担任生成人工智能助理（远程、合同制）的职位，即使没有人工智能领域的经验。该领域是否还有其他此类职位开放或正在开放？即使是现在，对人文学科学生的职业机会的了解也非常传统，似乎没有跟上技术进步的步伐。然而，这位校园招聘人员让我对政治学、文科、人文研究等在人工智能领域的可能性感到好奇。    由    /u/tanqw  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ifxct5/applications_of_political_science_in_ai_wrt_job/</guid>
      <pubDate>Sun, 02 Feb 2025 13:36:13 GMT</pubDate>
    </item>
    <item>
      <title>密歇根湖能成为巨型饮水机吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ifunj8/could_lake_michigan_become_a_giant_water_cooler/</link>
      <description><![CDATA[几个月前我读到他们正在芝加哥与 IBM、PsiQuantum、DARPA 和可能的 NVIDIA 合作建造一个“量子公园”。我了解这个地区，并有一个理论，他们可以把这个湖变成一个巨大的水冷却器。我丈夫说他们不可能得到 EPA 的批准。我说，这些公司有这么多钱，他们可能可以。我找到了他们计划的新图片，它在链接中。 https://thequantuminsider.com/2025/01/29/reports-illinois-shows-off-quantum-park-to-nvidia/    提交人    /u/Independent_Tap_2455   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ifunj8/could_lake_michigan_become_a_giant_water_cooler/</guid>
      <pubDate>Sun, 02 Feb 2025 10:41:44 GMT</pubDate>
    </item>
    <item>
      <title>人工智能企业正在竞争，而最终走向何方？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iftws0/ai_corporations_are_competing_and_to_what/</link>
      <description><![CDATA[OpenAI 和现在的 DeepSeek。然后另一个可能在不久的将来出现。世界上正在使用的大多数人工智能技术都是软实力，但当公司达到广泛和大规模生产的硬实力水平时，事情可能会对人类产生奇怪的影响。 随着这些公司相互竞争，当人工智能机器人和车辆及其硬件在地球上无处不在时，我们将变得比以往任何时候都更加依赖机器。 这不是几十年的问题，机器人技术的发展速度将比我们想象的要快得多。想象一下自我学习的机器，然后超级智能软件将其标准应用于国家领导人，以实现更好的人类结构。 一个新的世界秩序！重要的人类事务将由机器处理。毫无疑问，这一切都将通过智能技术让我们的生活变得轻松。但这里值得关注的问题是，这些公司将把人类引向何方？ 现在没有停止的迹象，随着时间的推移，这些竞争将愈演愈烈。是的！所有新兴和成熟的人工智能公司都有国际协议标准，但并非所有公司都会遵循。 我在这里提出的是一个假设，一个值得思考的问题，也是对人类未来的一个潜在担忧。我们已经放弃了机器，这种放弃将进一步发展，直到我们达到思维方式可能改变的水平。 信息将如此，以至于阅读这样的文章将成为历史，一种新的信息方式将成为人类的一部分。这并不完全令人不安，但这是我们探索这个世界和其他世界的承诺。 归根结底，我们人类为了权力和贪婪而互相争斗，一旦你掌权，权力就是你所想的，这就是世界领导人所做的。预测系统中的错误并不是一个错误的事情。 考虑到在谁做得更好的斗争中，我们可能会失去对我们来说最珍贵的东西，那就是自然性。很快，我们将看到像机器人这样的物理人类，然后是更先进的车辆，并失去人类数千年来的自然联系。 虽然我们创造了火，但不太确定如何在国际上使用它。害怕我们不知道的东西是人类的天性。同时，自然的思维过程告诉我们所有人，这场火灾必须用智慧来处理，纯粹的贪婪、欲望和权力，否则，我们将承担后果。    提交人    /u/MASJAM126   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iftws0/ai_corporations_are_competing_and_to_what/</guid>
      <pubDate>Sun, 02 Feb 2025 09:47:00 GMT</pubDate>
    </item>
    <item>
      <title>垂直人工智能整合</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ift89p/vertical_ai_integration/</link>
      <description><![CDATA[嗨，现在似乎有大量使用 LLM 构建的软件（应用程序）。如果我没记错的话，它们通常被称为垂直 AI 代理。  希望这个子版块专门介绍这种形式的开发，你们能否向我解释一下，作为一名 LLM 开发人员，全部工作是否都是提供最有用的“提示”向量并微调答案？ 假设您正在构建一个应用程序，用于处理警察局的行政工作。您如何收集“提示”来为此目的构建应用程序？出于安全原因，警方不太可能共享他们的数据。 谈到微调部分，您是自己构建还是使用标准架构，如 Transformer 和 Trainer API？这部分是否需要您编写很长的代码或仅仅 100 行？我似乎无法理解为什么应该是前者，因此提出这个问题。  如果您还有时间回答我的问题，您能否链接一个垂直 AI 代理项目的示例？我真的很好奇这样的软件是如何构建的。    提交人    /u/tomarbogolebeshichul   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ift89p/vertical_ai_integration/</guid>
      <pubDate>Sun, 02 Feb 2025 08:56:18 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2025 年 2 月 1 日</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ifq2ys/oneminute_daily_ai_news_212025/</link>
      <description><![CDATA[ 英国利用人工智能工具将虐待儿童材料定为犯罪。[1] Gmail 向 25 亿用户发出安全警告——已确认遭受人工智能黑客攻击。[2] 微软正在组建一个新部门来研究人工智能的影响。[3] 非洲学校为人工智能革命做好准备。[4]  来源包括：https://bushaicave.com/2025/02/01/2-1-2025/    提交人    /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ifq2ys/oneminute_daily_ai_news_212025/</guid>
      <pubDate>Sun, 02 Feb 2025 05:21:09 GMT</pubDate>
    </item>
    <item>
      <title>那些认为“人工智能即将达到顶峰”的人都去哪儿了？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ifm8xo/where_did_all_of_the_ai_is_about_to_reach_its/</link>
      <description><![CDATA[严肃的问题，这曾经是我在这个子版块看到的最常见的观点之一。他们还存在吗？或者他们现在开始相信研究人员所说的话了？    由   提交  /u/MelvilleBragg   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ifm8xo/where_did_all_of_the_ai_is_about_to_reach_its/</guid>
      <pubDate>Sun, 02 Feb 2025 01:45:42 GMT</pubDate>
    </item>
    <item>
      <title>上周一英伟达在纳斯达克历史性单日下跌所带来的宣传可能会在未来一年为开源人工智能项目带来数十亿美元的收益</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ifm41o/the_publicity_from_nvidias_historic_oneday_nasdaq/</link>
      <description><![CDATA[鉴于我不是金融分析师，我咨询了一些人工智能专家。 copilot: “最近对DeepSeek R1的关注和Nvidia股价的大幅下跌，让开源人工智能备受关注。这很可能会导致未来一年对开源人工智能项目的投资大幅增加。”  投资者和公司可能对具有成本效益的人工智能解决方案更感兴趣，这可能会带来数十亿美元的新投资，而这些投资原本可能不会用于开源人工智能。” gemini 2.0 flash thinking exp 01-21: 虽然无法进行精确的量化，但这种宣传实际上可以推动全球在风险投资、企业合作、慈善基金和政府补助等方面的额外 2 亿至 8 亿美元的新投资，超出对开源人工智能的预计。  grok 2 “DeepSeek R1 的宣传和 Nvidia 的股价下跌可能会在短期内使开源 AI 投资增加 20% 到 50%，并可能在未来一年增加 5000 万到 2 亿美元。” chatgpt-4： 在不断提示后，它拒绝估计美元金额。中国审查制度就是这样，哈哈。 从 grok 2 的最低 5000 万美元到 co-pilot 的数十亿美元的最高估计范围表明，人工智能可能还没有准备好迎接金融分析师的黄金时段，但我们仍然可以预期今年对人工智能的投资将飙升。    提交人    /u/Georgeo57   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ifm41o/the_publicity_from_nvidias_historic_oneday_nasdaq/</guid>
      <pubDate>Sun, 02 Feb 2025 01:38:36 GMT</pubDate>
    </item>
    <item>
      <title>通过 10:10 手表问题了解人工智能偏见</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iffk2a/understanding_ai_bias_through_the_1010_watch/</link>
      <description><![CDATA[https://medium.com/@sabirpatel_31306/understanding-ai-bias-through-the-10-10-watch-problem-eeebc1006d05 您是否注意到，网上几乎每张模拟手表的图片都显示时间为 10:10？试试看：谷歌搜索“手表图片”。您可能会一遍又一遍地看到相同的 10:10 布局。 现在，这里有一个实验：让人工智能工具（如 ChatGPT 或图像生成器）创建一张显示 3:25 或任何其他不同于 10:10 时间的手表图片。你得到了什么？你可能仍会看到经典的 10:10 设计手表。 为什么会发生这种情况？ 这是人工智能和数据科学中一个已知问题，但问题的根源却出奇的简单：数据。人工智能从它所训练的数据集中的模式中学习。当你在网上搜索手表图片时，几乎所有图片都显示时间为 10:10。 那么，为什么网上的手表图片是 10:10？ 自 1950 年代以来，营销人员一直使用 10:10 来展示手表，因为它创造了完美的对称性。时针和分针框住了品牌徽标，设计给人的感觉平衡且吸引人眼球。甚至有人对此进行了心理测试！如果您想深入了解，本文将解释其中的科学原理： 广告照片中手表设置为 1010 背后的科学原理 这对人工智能意味着什么？ 之所以出现这种偏见，是因为人工智能反映了互联网——同一个互联网上充斥着 10:10 的手表图像。解决这个问题并不简单。它需要强化学习，即重新训练人工智能以识别和使用不太常见的模式。例如，12 小时制模拟手表有 720 种可能的指针位置（12 小时 x 60 分钟）。为了打破偏见，AI 需要学习所有 719 种其他配置，这并非易事！ 总结？ AI 模型反映了其训练数据中的偏见，但这不一定是限制。借助更智能的训练方法和创新方法，未来的 AI 工程师有能力教会机器超越显而易见的模式并接受各种可能性。 随着 AI 越来越融入我们的生活，解决这些偏见对于创建反映更准确、更包容的世界观的系统至关重要。解决像 10:10 手表问题这样的挑战只是朝着构建能够更好地理解和代表人类复杂性的 AI 迈出的一步。    提交人    /u/sabirpatel   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iffk2a/understanding_ai_bias_through_the_1010_watch/</guid>
      <pubDate>Sat, 01 Feb 2025 20:29:08 GMT</pubDate>
    </item>
    <item>
      <title>时间戳能否诱使人工智能保持类似记忆的连续性？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ifdrnn/could_timestamping_trick_ai_into_maintaining/</link>
      <description><![CDATA[我一直在测试一个想法，即手动为与 ChatGPT 的每次交互添加时间戳，以创建模拟的时间意识。由于 AI 没有内置内存或时间跟踪，我想知道一致的“时间坐标”是否有助于它随时间的推移确认持续时间、连续性和模式。有没有其他人尝试过类似的东西？如果是这样，你的结果是什么？    提交人    /u/No-Drag-6378   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ifdrnn/could_timestamping_trick_ai_into_maintaining/</guid>
      <pubDate>Sat, 01 Feb 2025 19:10:45 GMT</pubDate>
    </item>
    <item>
      <title>我们的人工智能数据是否已经耗尽？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ifc2dj/are_we_running_out_of_data_for_ai/</link>
      <description><![CDATA[因此，显然，人工智能公司正陷入困境，缺乏训练模型的优质数据。每个人都专注于芯片之战，但下一场大战可能围绕着数据展开。诉讼、更严格的 API 规则（基本上是任何社交媒体网站）以及对不正当使用数据的指控使得抓取互联网数据变得更加困难。 现在有关于使用合成数据的理论，即在人工智能生成的数据上训练人工智能，以及人们可能共享数据以换取加密货币的去中心化系统。听起来很酷，但这足以激励人们共享数据吗？ 我最初在《福布斯》上读到这篇文章，如果你想深入了解的话，这里有文章，但我认为这是一个有趣的话题，因为每个人都高度关注中国与美国的人工智能竞赛。    提交人    /u/nadofa841   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ifc2dj/are_we_running_out_of_data_for_ai/</guid>
      <pubDate>Sat, 01 Feb 2025 17:58:08 GMT</pubDate>
    </item>
    <item>
      <title>只需几个步骤就能改变人工智能世界！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1if5tk8/it_only_takes_a_few_to_change_the_ai_world/</link>
      <description><![CDATA[有趣的是，中国在一定程度上限制了量化交易（因为它被认为是一种寄生活动，不会增加价值，但会从散户重新分配给专业人士），结果，一位前量化交易员似乎开发出了一种比中国近代历史上任何其他产品都更具地缘政治意义和社会效益的产品。 显然，关于这是如何实现的，还有很多问题，但尽管如此，你还是不得不想，如果量化交易在美国也被禁止，所有那些 Citadel 数学家、气象学家、数据科学家和程序员决定将他们的技能用于其他目标，会发生什么。 现代科技似乎有一个明显的模式，那就是只需要一个人（或一小群人）有一个想法并开发出一种产品就能改变历史，而通过迫使那 0.00001% 的顶尖工程师专注于非金融产品，你最终会得到一个真正不同的结果。结果 在此之前，谷歌只有六个人撰写了论文《注意力就是你所需要的》，提出了 Transformer 架构，随后被 OpenAI 和其他公司采用，最终让人工智能为全世界所用。    提交人    /u/Onereasonwhy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1if5tk8/it_only_takes_a_few_to_change_the_ai_world/</guid>
      <pubDate>Sat, 01 Feb 2025 13:01:32 GMT</pubDate>
    </item>
    </channel>
</rss>
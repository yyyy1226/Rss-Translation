<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Wed, 12 Jun 2024 18:26:11 GMT</lastBuildDate>
    <item>
      <title>如何选择最适合您的工程团队的 AI 编码助手</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1dece2f/how_to_choose_the_ai_coding_assistant_that_works/</link>
      <description><![CDATA[评估编码 AI 助手时要问的十个问题（以及一个额外问题）：  它是否适用于您现有的工具 - IDE、代码主机？ 它是否支持您使用的编程语言和框架？ 它是否支持您的特定用例场景？ 它是否利用您的整个代码库来提供上下文相关的结果？ 它是否使用非代码上下文来生成考虑您更广泛需求的代码？ 它是否允许您利用快速发展的 LLM 领域的进步？ 它是否允许您利用现有的 AI 投资？ 它是否在您首选的部署设置中工作？ 它是否保护您免受知识产权风险？ 它是否可以防止数据泄露或暴露的风险？ 它是否保证它不会使用您的代码进行训练？  阅读更多这里。    由   提交  /u/creativefisher   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1dece2f/how_to_choose_the_ai_coding_assistant_that_works/</guid>
      <pubDate>Wed, 12 Jun 2024 17:31:50 GMT</pubDate>
    </item>
    <item>
      <title>后人类意识形态（一句话总结）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1dec8n0/posthuman_ideologies_summary_in_1_sentence/</link>
      <description><![CDATA[后人类意识形态：  数据主义：优先考虑数据的流动和处理，而不是人类经验，将人类视为数据系统的贡献者。 技术人文主义（超人类主义）：主张通过生物技术和控制论增强人类能力，超越生物限制并实现永生。 宇宙主义：寻求人类存在范围扩展到地球以外，主张太空殖民并在整个宇宙中传播人类文明。 奇点主义：相信最终会出现技术奇点，人工智能将超越人类智能，从而引发深刻的社会变革。 r/singularity 生态中心主义：强调所有生物和生态系统的内在价值，提倡人与自然的和谐关系。 🍀 后人类主义：批判传统人文主义，探索超越当前生物和文化限制的未来人类存在。 技术盖亚主义：将生态可持续性与技术创新相结合，解决环境问题，创造可持续的未来。 生物政治：研究生物学与政治的交集，重点关注生物技术进步的治理和伦理影响。 控制论人文主义：主张将控制论系统与人类生物学相结合，以增强人类能力，提高生活质量。     提交人    /u/Maybe-reality842   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1dec8n0/posthuman_ideologies_summary_in_1_sentence/</guid>
      <pubDate>Wed, 12 Jun 2024 17:25:35 GMT</pubDate>
    </item>
    <item>
      <title>为什么我不会排除大型语言模型将我们带入AGI的可能性：</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1deb9kp/why_i_wouldnt_rule_out_large_language_models/</link>
      <description><![CDATA[反对 LLM 实现 AGI 的论点通常是基于将其与人类智能进行对比：  答：人类智能利用元认知，在 20W 功率下实时从少量数据发展而来。相比之下，LLM 处理大量数据，经过预先训练，使用大量功率，并且在没有任何认知意识的情况下运行。因此，AGI 需要不同的范式。 B： LLM 已经耗尽了大多数可用数据源，如果没有更大的数据集，它们就无法变得更智能。  然而，这种分析大多存在缺陷：  人类智能确实是使用大量数据和能力发展起来的：  我们的认知架构经过数亿年的发展，并编码在我们的 DNA 中。 我们的感官在成长过程中处理大量数据。 （我们几乎没有意识到这一点，因为这个过程几乎完全是潜意识的。）  LLM 培训从头开始构建认知架构，有效地重新封装了进化过程和实时学习。虽然非常不同，但这并不一定意味着智能不足。 人类大脑和 LLM 之间的本质相似之处在于，它们本质上是压缩算法：将大量世界数据压缩成世界观，提供预测模型来指导行动。主要区别在于，人类大脑的架构和学习过程经过高度优化和高效，使其能够实时从相对少量的数据中学习。另一方面，LLM 需要大量数据和计算能力才能实现可比的性能。 我们不知道人类智能在架构基础上是如何工作的，因此 LLM 是一种“蛮力”方法，用于弥补这种无知。如果我们知道正确的架构，人类级别的智能很可能可以在更普通的硬件上运行。然而，随着最佳架构的接近，LLM 训练和运行的效率正在迅速提高：LLM 架构的进步，例如更高效的注意力机制的开发和稀疏表示的结合，有助于减少训练和推理的计算和数据要求。 人们误以为 LLM 时代的进步将是使用越来越大的数据集。相反，人们正在使用越来越小的数据集并学习如何使用具有正反馈周期的合成（自生成）数据训练 LLM。LLM 训练过程会生成自己的中间训练数据，这些数据可用于创建下一代训练数据。因此，人类源数据只是启动该过程所需的。  回到 LLM 的定义：广义上讲，LLM 是基于大数据集、无监督学习、未明确训练的技能泛化以及广泛适用于下游任务的算法。这非常像人类智能 - 只不过我们的训练囊括了进化过程和实时学习。    提交人    /u/HeroicLife   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1deb9kp/why_i_wouldnt_rule_out_large_language_models/</guid>
      <pubDate>Wed, 12 Jun 2024 16:45:04 GMT</pubDate>
    </item>
    <item>
      <title>AI 阅读清单 - 第 3 部分</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1deakf9/ai_reading_list_part_3/</link>
      <description><![CDATA[大家好， AI 阅读清单的第三部分可在此处获取。在本部分中，我们将探讨前 OpenAI 首席科学家 Ilya Sutskever 给 John Carmack 的阅读清单中的以下 5 项。Ilya 接着说：“如果你真的学会了所有这些，你就会知道今天重要的事情的 90%”。 我希望这对你们中的一些人有用。非常欢迎反馈！:)    提交人    /u/Personal-Trainer-541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1deakf9/ai_reading_list_part_3/</guid>
      <pubDate>Wed, 12 Jun 2024 16:15:47 GMT</pubDate>
    </item>
    <item>
      <title>量子隐形传态取得突破：实现持续高保真</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1dea307/breakthrough_in_quantum_teleportation_sustained/</link>
      <description><![CDATA[研究人员通过实现持续、高保真的量子隐形传态，在实现量子互联网方面取得了重大飞跃。这一里程碑可能会彻底改变数据存储、精密传感和计算，预示着通信新时代的到来。  科学家成功地通过 27 英里的光纤网络传送了量子比特，保真度超过 90%。 阅读更多    提交人    /u/Write_Code_Sport   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1dea307/breakthrough_in_quantum_teleportation_sustained/</guid>
      <pubDate>Wed, 12 Jun 2024 15:55:47 GMT</pubDate>
    </item>
    <item>
      <title>稳定扩散 3 培养基简介</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1de9yay/briefly_about_stable_diffusion_3_medium/</link>
      <description><![CDATA[硬件：SD3 适用于标准消费级 GPU，由于 VRAM 使用率低，性能不会下降。 可信吗？ 是的。 精细调整：能够从小数据集中继承最精细的细节，非常适合进一步训练。 可信吗？ 是的。 速度提升：针对 TensorRT 优化的版本即将推出，速度提高 50%。 可信吗？ 是的。 AMD 优化：AMD 已针对各种设备优化了 SD3 Medium 的推理，包括 AMD 最新的 APU、消费级 GPU 和 MI-300X 企业级 GPU。 可信吗？有疑问。 许可：Stable Diffusion 3 Medium 可供个人和研究使用。新的 Creator 许可证使专业用户能够使用 SD3，同时支持 Stability 的使命，使 AI 民主化，保持对开放 AI 的承诺。 Creator 许可证：每月 20 美元 - https://stability.ai/license    提交人    /u/Alex_GD_SkillPotion   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1de9yay/briefly_about_stable_diffusion_3_medium/</guid>
      <pubDate>Wed, 12 Jun 2024 15:50:08 GMT</pubDate>
    </item>
    <item>
      <title>人工智能降噪耳机可隔离人群中的单个声音</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1de8fuq/aipowered_noisecanceling_headphones_can_isolate/</link>
      <description><![CDATA[科学家们开发出了突破性的人工智能降噪耳机，可以在嘈杂的环境中隔离单个声音。这项创新技术被称为目标语音听力 (TSH)，它允许用户专注于一个特定的声源，同时屏蔽所有其他噪音。 窃听更上一层楼？ 阅读更多    提交人    /u/Write_Code_Sport   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1de8fuq/aipowered_noisecanceling_headphones_can_isolate/</guid>
      <pubDate>Wed, 12 Jun 2024 14:46:22 GMT</pubDate>
    </item>
    <item>
      <title>谷歌研究表明，对法学硕士进行微调会线性增加幻觉？😐</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1de5ug4/google_study_says_finetuning_an_llm_linearly/</link>
      <description><![CDATA[他们准备了一个 QA 任务来观察幻觉，既有已知示例（与模型在初始训练期间看到的信息类似的训练实例），也有未知示例（引入了模型之前从未接触过的新信息）。 他们发现：  由于过度拟合，微调数据集中的未知示例会降低性能，训练越多。它们会导致幻觉并降低准确性。已知示例对性能有积极影响。 早期停止有助于避免这种情况，这可能意味着未知示例在较短的训练中是中性的。 未知示例的拟合速度较慢也表明模型难以通过微调获取新知识。  论文：https://arxiv.org/pdf/2405.05904 我每天分享高质量的 AI 更新和教程。 如果您喜欢这篇文章并希望了解最新的 AI 研究，您可以查看：https://linktr.ee/sarthakrastogi 或我的 Twitter：https://x.com/sarthakai    由    /u/sarthakai 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1de5ug4/google_study_says_finetuning_an_llm_linearly/</guid>
      <pubDate>Wed, 12 Jun 2024 12:49:01 GMT</pubDate>
    </item>
    <item>
      <title>有哪些开源项目？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1de59if/open_source_projects_out_there/</link>
      <description><![CDATA[嗨， 我在工作中使用 AI 非常基础，目前正在学习 Python 编码课程。我非常乐意在空闲时间为开源项目做出贡献（只要符合道德等！）。开发人员请在下面发表评论！ 提前致谢！    提交人    /u/Vcaps5   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1de59if/open_source_projects_out_there/</guid>
      <pubDate>Wed, 12 Jun 2024 12:19:08 GMT</pubDate>
    </item>
    <item>
      <title>适用于 Colab、Jupyter 等的免费 AI 代码自动完成</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1de4987/free_ai_code_auto_completion_for_colab_jupyter_etc/</link>
      <description><![CDATA[Codium.ai 是一款免费的 AI 代码自动完成工具和扩展，支持大多数 IDE 甚至 jupyter 笔记本，并且完全免费。在此处查看简短演示：https://youtu.be/bo198EehwqU?si=q37DRY5wYkCTospk    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1de4987/free_ai_code_auto_completion_for_colab_jupyter_etc/</guid>
      <pubDate>Wed, 12 Jun 2024 11:22:38 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能：用大锤砸碎坚果</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1de3xdn/generative_ai_cracking_nuts_with_a_sledgehammer/</link>
      <description><![CDATA[人们误解生成式人工智能是一种具有专家级输出能力的感知工具。事实上，生成式人工智能能够执行大量工作，达到中等水平。考虑到输出速度，我们原谅生成式人工智能的错误和不准确性，而这些错误和不准确性在任何行业都是无法容忍的，也就是说，绝对不会容忍任何真正知道自己在做什么的人。“对不起先生，我截掉的不是正确的手臂，但它仍然是一只手臂！” AGI 真的迫在眉睫吗？可能，但仅限于特定且有缺陷的定义。这里有一个重要的区别。智力不是能力的同义词或等同物。我们将智力与专业知识和能力混为一谈。这是超级聪明的人的常见问题。 这些算法很可能达到超人的智力水平。这重要吗？就实际专业知识和输出而言，它们充其量只是平庸之作。对于任何领域的初学者来说，中级水平都令人印象深刻。无与伦比的速度加上类似于（但不等同于）能力的东西，使得任何领域的初学者都对这个工具感到敬畏。他们是自信的毕业生，不知不觉地毁掉了你企业的专业能力。 完整博客链接    由   提交  /u/ejb503   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1de3xdn/generative_ai_cracking_nuts_with_a_sledgehammer/</guid>
      <pubDate>Wed, 12 Jun 2024 11:03:08 GMT</pubDate>
    </item>
    <item>
      <title>英国人工智能候选人竞选</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1de1fwl/ai_driven_candidate_standing_for_election_in_the/</link>
      <description><![CDATA[我刚刚写了一篇关于“AI Steve”的文章，这是一个将在英国参加选举的人工智能驱动的虚拟形象。 *** 在即将到来的英国选举中，一种新的候选人正在出现：AI Steve，一个由人工智能驱动的虚拟形象，代表是商人史蒂文·恩达科特，他以无党派人士身份竞选议会议员。总部位于布莱顿的恩达科特将担任 AI Steve 的现场代表，旨在通过将选民的建议和要求纳入其平台来直接与选民互动。AI Steve 旨在提供一种更直接的民主形式，让选民对政策决策产生重大影响。 由 Neural Voice 创建的 AI Steve 可以同时管理多达 10,000 个对话，并转录选民互动以告知政策决策。Endacott 发起这一倡议的动机源于他对传统政治的失望，他认为传统政治更关注党派利益而不是解决实际问题。他强调，AI Steve 将优先考虑选民的关切，并通过“验证者”进行验证，这些“验证者”是普通民众，确保所提出的政策合理并反映民意。 尽管 AI Steve 最近才启动，但它已经收到了各种问题的反馈，例如巴勒斯坦冲突和垃圾收集等当地问题。恩达科特致力于根据 AI Steve 表达的偏好进行投票，即使这些偏好与他自己的观点不同，这也凸显了他致力于在民主制度中采取以选民为导向的方法。 AI Steve 作为英国大选候选人的出现有几个重要影响： 1. 重新定义政治代表： AI Steve 代表了政治代表概念化和执行方式的根本转变。传统的政治代表是将自己的观点、偏见和决策过程带入其角色的人。然而，AI Steve 旨在充当其选民集体意志的渠道，可能提供一种更纯粹的代议制民主形式。这可能导致选民偏好和立法行动之间更直接的一致。 2. 提高选民参与度： 通过利用人工智能同时进行数千次对话并将实时反馈纳入其政策平台，AI Steve 可以显著提高选民的参与度和参与度。选民可能会感到更有权力和被倾听，因为他们知道他们的意见直接影响政策决策。这种模式可以鼓励更广泛的选民更高程度的政治参与，有可能重振民主参与。 3. 挑战和道德问题： 人工智能在政治中的引入带来了各种道德和实际挑战。数据隐私、人工智能决策过程的完整性以及人工智能算法中操纵或偏见的可能性等问题需要仔细考虑。此外，对人工智能进行政策制定的依赖可能会引发有关问责制和人类判断在治理中的作用的问题。平衡人工智能的能力与人类的监督对于解决这些问题和确保技术负责任地融入政治领域至关重要。 总之，虽然这可能会增加政治参与度并引发有关代表性的相关问题，但也会引起难以忽视的道德问题。目前，这似乎更像是一种噱头，而不是重塑政治的认真尝试。 你对人工智能化身竞选有什么看法？考虑到目前英国的政治状况，这样的噱头是否有可能改善政治进程并增加参与度，还是仅仅是为了做做样子？ 如果您喜欢这篇文章，您可以通过订阅我的时事通讯“认知快递”来了解更多，这里。    提交人    /u/cognitive_courier   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1de1fwl/ai_driven_candidate_standing_for_election_in_the/</guid>
      <pubDate>Wed, 12 Jun 2024 08:11:46 GMT</pubDate>
    </item>
    <item>
      <title>总部位于巴黎的人工智能公司 Mistral AI 融资 6.4 亿美元</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ddogme/parisbased_ai_company_called_mistral_ai_raises/</link>
      <description><![CDATA[Mistral AI 获得由 General Catalyst 领投的 6 亿欧元 B 轮融资。这使这家 AI 初创公司的价值达到 60 亿美元，使其能够与 OpenAI 和 Meta 竞争。https://theaiwired.com/paris-based-ai-company-called-mistral-ai-raises-640-million/    提交人    /u/alyis4u   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ddogme/parisbased_ai_company_called_mistral_ai_raises/</guid>
      <pubDate>Tue, 11 Jun 2024 20:37:08 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则 [请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新开通一天的账户或 Karma 少于 100 的用户无法发帖。他们可以发表评论，但不能提交实际帖子。这是我们解决机器人垃圾邮件计划的一部分。如有任何不便，敬请谅解。 我们将在接下来的几天内进行民意调查，以了解子版块的总体意愿以及如何改进，这只是一个提醒。 与往常一样，请向我们提供反馈，如果您有兴趣帮助子版块，请联系我。 谢谢大家！    提交人    /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：征求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到 r/ArtificialIntelligence！ 我们的目标是为所有考虑人工智能的事情提供一个开放和尊重的论坛 - 其中包括  促进有关人工智能的哲学和伦理讨论 作为理解和学习人工智能主题的起点 提供技术论文演示和讨论 展示高质量的人工智能/机器学习应用程序 提供培训和学习资源 引导用户查看更具体的信息和子版块 列出人工智能/机器学习应用程序、它们的用途、成本和访问信息 其他与人工智能相关的内容。 ...等等  该子版块的审核团队正在进行改组将导致子版块发生一些变化。但是，无需担心，因为这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解并能够提供反馈，将提供多次机会对变化进行反馈。 第一轮反馈收集是通过此线程作为“征求意见”（RFC）进行的，这是收集反馈的标准方法。在准备和实施更改时，将有多轮 RFC 流程。 ​  发布新应用程序/自我推广/AI 生成内容的规则  由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似内容将被阻止或限制在特定的置顶帖子中。 AI 生成特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的置顶帖子中。 博客链接应包含高质量内容。链接到纯促销博客的帖子将被删除。 除非包含一定字数的详细信息，否则将禁止仅包含链接的帖子。必须付出一些努力。 我们应该阻止由 AI 撰写的帖子吗？存在可用于 Mod-bot 的模型，但这是一个我们需要反馈的问题。  使用天赋来组织帖子。请注意，已经添加了新的天赋，我们愿意接受更多建议。 关于 AI/ML 应用的 NSFW 应用和技术的子政策应该是什么？ 我们希望向社区提供有关 mod-bot 的想法。虽然一些标准机器人将用于基本维护，但是社区可以为 AI/ML 机器人功能想出什么有趣的东西呢？ 培养初级、中级和高级资源，以帮助人们找到他们正在寻找的信息、培训、模型、技术数据等。 启动 substack/podcast 来采访整个 AI/ML 领域的人。这可能包括哲学家和思想家、程序员、科学家、商人，甚至那些对 AI 持对立观点的人 如果您想创建代表子版块的横幅，请使用适当的尺寸进行创建。任何创建方法都是​​可以接受的。  不用说，每个人都应该受到尊重。我个人觉得我们都知道这一点，不需要把它灌输到人们的脑海里。要友善。 感谢您的耐心和帮助！    提交人    /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>
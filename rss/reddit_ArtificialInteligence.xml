<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Mon, 13 Jan 2025 09:24:58 GMT</lastBuildDate>
    <item>
      <title>我创建了一个网络安全中心 - 所有网络工具和资源！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i09wgj/i_created_a_cybersecurity_hub_all_cyber_tools_and/</link>
      <description><![CDATA[  由    /u/BST04  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i09wgj/i_created_a_cybersecurity_hub_all_cyber_tools_and/</guid>
      <pubDate>Mon, 13 Jan 2025 08:58:03 GMT</pubDate>
    </item>
    <item>
      <title>人工智能增长区和超级计算机：英国政府的创新战略</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i09vs7/ai_growth_zones_and_supercomputers_uk_governments/</link>
      <description><![CDATA[关键要点  英国的 50 点 AI 计划包括 AI 增长区、超级计算机和国家数据库，以推动创新； Vantage、Nscale 和 Kyndryl 等私营公司投资 170 亿美元支持 AI 基础设施发展； AI 能源委员会和 DSIT 旨在确保可持续电力和 AI 计划的有效实施。  来源：https://www.bitdegree.org/crypto/news/ai-growth-zones-and-supercomputers-uk-governments-strategy-for-innovation?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=r-uk-governments-strategy-for-innovation    提交人    /u/webbs3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i09vs7/ai_growth_zones_and_supercomputers_uk_governments/</guid>
      <pubDate>Mon, 13 Jan 2025 08:56:27 GMT</pubDate>
    </item>
    <item>
      <title>监管政策可以影响通用人工智能模型的长期风险管理</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i09udd/supervision_policies_can_shape_longterm_risk/</link>
      <description><![CDATA[我每天都会查找和总结有趣的 AI 研究论文，这样你就不必费力地浏览它们了。今天的论文题为“监管政策可以塑造通用 AI 模型中的长期风险管理”，作者是 Manuel Cebrian、Emilia Gomez 和 David Fernandez Llorca。 本文探讨了各种监管政策如何影响通用 AI (GPAI) 模型中风险管理的有效性。作者认识到这些模型的快速部署所带来的挑战，提出了一个模拟框架来评估处理风险报告的不同策略。他们的工作揭示了关于 AI 风险覆盖范围和优先级之间权衡的关键见解。 本文的主要发现包括：  监管政策有效性：该研究比较了四种政策——非优先、随机、基于优先级和多样性优先。研究发现，基于优先级和多样性优先的方法在应对高影响风险方面是有效的，但如果管理不善，可能会忽视系统性问题。 风险覆盖范围的权衡：虽然基于优先级的策略将资源集中在最关键的风险上，但它们可能不成比例地偏向专家见解，可能会忽视来自社区驱动来源的识别紧急或以用户为中心的问题的报告。 报告中的反馈循环：作者确定了报告激励和威慑努力之间的反馈循环如何扭曲风险格局，强化专家驱动的重点，同时随着时间的推移减少社区贡献。 实证验证：该研究使用超过一百万次 ChatGPT 交互的数据集验证了模拟框架，显示了应用不同政策时风险管理结果的一致模式。 更广泛的治理启示：研究结果强调了设计平衡不同风险类型和来源的监管政策的重要性，从而确保全面的人工智能治理和安全。这项研究提供了宝贵的见解，说明风险管理政策的选择如何影响人工智能风险格局。你可以在这里看到完整的细分：这里你可以在这里看到完整的原始研究论文：原始论文    提交人    /u/steves1189   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i09udd/supervision_policies_can_shape_longterm_risk/</guid>
      <pubDate>Mon, 13 Jan 2025 08:53:15 GMT</pubDate>
    </item>
    <item>
      <title>人工智能工作只是神话吗？现实情况是，硅谷最多会有几百名绝对天才的核心人物在开发这个东西，就这样了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i08zo1/are_artificial_intelligence_jobs_a_myth/</link>
      <description><![CDATA[显然，不要将“快速工程师”之类的工作算作 AI 工作。因为它不是，这就像将知道如何使用 MS Word 的人描述为“MS Office 工程师”一样    提交人    /u/CEta123   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i08zo1/are_artificial_intelligence_jobs_a_myth/</guid>
      <pubDate>Mon, 13 Jan 2025 07:46:51 GMT</pubDate>
    </item>
    <item>
      <title>人工智能能从根本上改变我们开展研究的方式吗？（新框架解释）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i08j3m/can_ai_fundamentally_transform_the_way_we_conduct/</link>
      <description><![CDATA[这正是 Agent Laboratory 承诺要做的。它是一个利用 LLM 协助研究人员完成整个科学发现生命周期的框架。 通过解决长期存在的瓶颈，这种方法有可能重塑我们进行研究、构思和实验的方式。 基础研究 ➤ 由于时间和资源的限制，许多有前途的想法仍未得到探索。 ➤ 虽然 LLM 可以产生新颖的想法，但它们的实施往往缺乏实用性。 ➤ 同时测试多个想法的成本高昂。 ➤ 从构思到发表的研究工作流程需要大量的时间和精力。 ➤ 将想法转化为实验而可操作的见解需要深厚的专业知识和大量的资源，这使得执行变得复杂。 借助 Agent Laboratory，研究人员可以将重复性的、劳动密集型的任务交给人工智能，将精力集中在创造性构思上。 利用 Agent Laboratory 进行机器学习和数据分析的人工智能𝐭𝐡𝐫𝐞𝐞 𝐬𝐭𝐚𝐠𝐞𝐬： 1️⃣ 机器学习： » LLM 驱动的代理使用 arXiv API 等工具来策划、总结和分析论文。 » 他们迭代地构建全面的知识库，确保捕获相关研究。 2️⃣ 𝐄𝐱𝐩𝐞𝐫𝐢𝐦𝐞𝐧𝐭𝐚𝐭𝐢𝐨𝐧： » 与模拟博士和博士后研究人员角色的代理合作。 » 从详细的计划制定和数据准备到运行实验和分析结果，自动化所有工作。 » 生成在各种基准测试中实现最先进性能的机器学习代码。 3️⃣ 𝐑𝐞𝐩𝐨𝐫𝐭 𝐖𝐫𝐢𝐭𝐢𝐧𝐠： » 将研究结果综合成高质量、可发表的研究论文。 » 提供详细的文档和代码存储库支持可重复性。 研究和分析表明，该方法非常可靠。最佳做法： ✅ 与早期的自主研究方法相比，成本降低了 84%。 ✅ 高质量的输出，人类评估者在实验质量、报告实用性和实用性方面对结果给予了高度评价。 ✅ 关键阶段的人为反馈提高了研究和实施的质量。 根据我的经验，人工智能的突破往往来自于消除摩擦。Agent Laboratory 正是通过让研究人员专注于工作的创造性和战略性方面来做到这一点，而让人工智能处理繁琐、重复的任务。 而且它是开源的！ 足够灵活，可以适应具有不同计算资源的团队。 我们准备好相信人工智能扮演如此关键的角色了吗？让我们讨论一下吧！    提交人    /u/Several-Republic-609   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i08j3m/can_ai_fundamentally_transform_the_way_we_conduct/</guid>
      <pubDate>Mon, 13 Jan 2025 07:11:52 GMT</pubDate>
    </item>
    <item>
      <title>正在寻找一位人工智能专业人士来为我的大学论文进行采访！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i06buu/looking_for_an_ai_professional_to_interview_for/</link>
      <description><![CDATA[标题说了什么。我目前正在为我的大学英语课写一篇论文，讨论在教育和医疗保健等专业环境中使用人工智能的利弊。如果你愿意回答几个问题（只需在消息中！），请给我发私信。 我唯一需要的就是证明你是该领域的专业人士（例如 LinkedIn 页面）    提交人    /u/Gs483   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i06buu/looking_for_an_ai_professional_to_interview_for/</guid>
      <pubDate>Mon, 13 Jan 2025 04:48:17 GMT</pubDate>
    </item>
    <item>
      <title>从哪里开始将其融入我目前的职业？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i048sx/where_to_begin_on_integrating_this_into_my/</link>
      <description><![CDATA[首先，我要说清楚，我并不是在问如何在我目前的工作中使用人工智能，而是想看看我可以查看哪些步骤/资源/可以参加哪些课程/等等，从而成为我公司的主题专家。 背景是，我是一名主要关注知识管理的顾问。我为我的客户设计和实施知识管理策略。尽管知识管理的使用频率很高，但它是一项相当小众的技能，我想将这些技能多样化一些。人工智能非常适合知识管理，而且显然很受欢迎。 我并不想成为技术专家或其他什么。我担任项目经理，更愿意将实际开发留给比我更聪明的人；但是，我希望能够以开发人员能够理解我提出的任何要求的水平来谈论它，并且我能够充分了解该过程，以便向完全不理解它的客户解释它。如果我必须学习 Python，那就这样吧，但这并不是我想要做的。 考虑到所有这些，我该从哪里开始呢？我见过通过 USAII 获得的认证，但其他帖子似乎看不起它。任何帮助都将不胜感激！    提交人    /u/My_Anus_Is_Bleating   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i048sx/where_to_begin_on_integrating_this_into_my/</guid>
      <pubDate>Mon, 13 Jan 2025 02:52:43 GMT</pubDate>
    </item>
    <item>
      <title>类似《疑犯追踪》中的机器的人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hzu46h/ai_like_the_machine_from_person_of_interest/</link>
      <description><![CDATA[一种从实时视频源获取输入并做出相应反应的人工智能。它可以看到并识别物体。它是实时训练的，但已经理解语言。类似这样：https://www.tiktok.com/@seriescontentt/video/7391146390832860449 这样的东西已经存在了吗？如果没有，如何制作一个？    提交人    /u/tomasalias   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hzu46h/ai_like_the_machine_from_person_of_interest/</guid>
      <pubDate>Sun, 12 Jan 2025 19:05:53 GMT</pubDate>
    </item>
    <item>
      <title>寻找可以深入学习 NLP 的 AI 研究员职位的朋友</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hzr2o1/searching_for_pals_to_study_deeply_nlp_for_ai/</link>
      <description><![CDATA[大家好，我是计算机工程专业最后一年的学生，和大多数 CS 或 CEng 学生一样，我也在努力寻找自己的目标。现在或者实际上，我已经学习了几个月的 NLP，并决定深入研究并成为一名 AI 研究员。所以我正在寻找可以快速深入地踏上旅程的朋友。 我的计划是学习 LLM 或任何类似主题的所有主要内容。例如，在反向传播、word2vec 或类似模型或方法下学习数学。在我的道路上，我还计划做项目。我估计我会按照计划在 6 个月内完成一些重要主题。所以如果有人感兴趣，请直接发信息给我。此外，我有一些 python、ML 和 DL 基础知识，所以如果你也是，我很乐意和你一起开始。    提交人    /u/Salgurson   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hzr2o1/searching_for_pals_to_study_deeply_nlp_for_ai/</guid>
      <pubDate>Sun, 12 Jan 2025 16:57:39 GMT</pubDate>
    </item>
    <item>
      <title>高中新生如何开始接触 AI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hznubx/how_to_get_started_with_ai_as_a_high_school/</link>
      <description><![CDATA[我想进入人工智能领域，但我不知道从哪里开始或做什么。我应该从哪里开始实现制作自己的人工智能的目标？ 编辑 - 我没有把我的问题说清楚，我想制作自己的模型并学习编程等等。    提交人    /u/Affanwasif   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hznubx/how_to_get_started_with_ai_as_a_high_school/</guid>
      <pubDate>Sun, 12 Jan 2025 14:29:48 GMT</pubDate>
    </item>
    <item>
      <title>如果AGI实现了，科技公司如何生存</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hzk4k3/if_agi_achieved_how_tech_companies_survive/</link>
      <description><![CDATA[我认为，如果我们实现了 AGI，90% 的科技公司将变得过时，如果 AGI 可以做所有事情，那么我们只需要一个用户界面，软件公司将变得过时。只有在后端发挥作用的公司才能生存。我认为 Salesforce 无法在这波人工智能浪潮中生存下来。你的看法呢？    提交人    /u/Adventurous_Mood1730   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hzk4k3/if_agi_achieved_how_tech_companies_survive/</guid>
      <pubDate>Sun, 12 Jan 2025 10:42:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能强度（定义为逻辑和推理）的理论极限的可能性。强大的算法能否使训练数据量和计算量变得无关紧要？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hzj2l2/the_possibility_of_a_theoretical_limit_to_the/</link>
      <description><![CDATA[在最近的 reddit 帖子中，我提出了这样的假设：就像声音和光速存在极限一样，人工智能的逻辑和推理能力也可能存在极限 - 在这种情况下，人工智能的智能程度也可能存在极限。虽然库兹韦尔认为人工智能可能会比人类聪明 10 亿倍，但这个估计可能过于乐观了。 我要求 deepseek v3 探索这一前景，将其考虑范围限制在人工智能智能的强度上，而不是速度、记忆或其他属性上。我将其答案发布在下面，但也请求有权访问开放人工智能的 o1 和/或 o3 的人向它提出同样的问题，以便更好地评估 v3 的智能和知识，从而生成准确的答案。您可能只想将 v3 的响应粘贴到查询中，然后要求他们评估准确性。 再次请注意，这里所说的智能仅仅意味着它解决逻辑和推理问题的能力，而不是它可以存储多少信息，也不是它能多快得出答案等。 如果人工智能智能的强度存在理论极限，那么我们可能已经比我们想象的更接近它了。此外，就人工智能民主化而言，开发更强大的逻辑和推理算法可能会完全消除更大数据集和竞争力的优势。 当然，请随意质疑 v3 的结论。 这是 deepseek v3 的回应： “人工智能的理论极限：信息处理和计算复杂性 1.信息处理的理论限制：  物理约束：贝肯斯坦边界假定在有限的空间区域内，以有限的能量可以容纳的最大信息量。这意味着任何系统（包括人工智能系统）的信息密度都存在根本限制。兰道尔原理补充说，擦除信息存在最低能量成本，将信息处理与热力学联系起来，并提出了计算的能量约束。 对人工智能的影响：这些原则表明，人工智能系统与任何物理系统一样，都受到信息处理效率的限制，这可能会限制它们的推理能力。  2. 计算复杂性：  问题分类：计算复杂性理论根据问题固有的难度对其进行分类。值得注意的是，P vs NP 问题探讨的是可以快速验证的问题是否也可以快速解决。如果 P ≠ NP，则意味着某些问题本质上很难解决，即使拥有大量计算资源也是如此。 AI 和 NP 难题：AI 系统通常依赖于优化和机器学习技术。遇到 NP 难题可能会限制 AI 有效找到最佳解决方案的能力，从而凸显理论界限。 丘奇-图灵论题：该论题表明，任何有效可计算的函数都可以通过图灵机计算，从而为可计算性设定了界限。任何人工智能都无法完成那些图灵不可计算的任务，无论其架构如何。 算法信息论：柯尔莫哥洛夫复杂度和逻辑深度等概念为算法的复杂性和数据的随机性提供了深刻见解，进一步阐明了人工智能对复杂信息进行推理的潜在限制。  结论： 人工智能逻辑和推理能力的理论限制植根于信息处理和计算复杂性的基本原理。贝肯斯坦边界和兰道尔原理等物理定律对信息密度和能耗施加了限制，而计算复杂性理论则表明解决某些问题存在固有困难。这些限制不是关于当前技术缺陷，而是关于计算和信息的基本性质。了解这些界限对于推进人工智能研究和认识人工智能能力范围至关重要。”   由    /u/Georgeo57  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hzj2l2/the_possibility_of_a_theoretical_limit_to_the/</guid>
      <pubDate>Sun, 12 Jan 2025 09:23:19 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 的建议会推动有或无理由的道德判断</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hzimfi/chatgpts_advice_drives_moral_judgments_with_or/</link>
      <description><![CDATA[标题：“ChatGPT 的建议无论有无理由都会推动道德判断” 我每天都在寻找和总结有趣的 AI 研究论文，这样你就不必费尽心思去阅读它们了。今天的论文题为“ChatGPT 的建议无论有无理由都会推动道德判断”，作者是 Sebastian Kruegel、Andreas Ostermaier 和 Matthias Uhl。 本文探讨了 AI，特别是像 ChatGPT 这样的聊天机器人，在指导用户道德决策方面日益增长的影响力。通过使用电车难题的在线实验，研究人员研究了个人是否依赖 ChatGPT 的建议（无论是合理的还是不合理的），以及它对道德判断的影响。以下是一些有趣的发现：  超越理由的影响力：研究发现，无论建议是否附带推理，ChatGPT 的建议都会影响用户的道德决策。令人惊讶的是，当建议归因于人类道德顾问而不是人工智能时，这种模式也成立。 摆脱道德困境：作者认为，用户会倾向于接受任何建议，无论其是否经过深思熟虑，因为它提供了一种轻松摆脱道德困境的方法——而聊天机器人的可访问性加剧了这一过程。 实验见解：参与者面临电车困境的一个版本，并获得了归因于 ChatGPT 或人类道德顾问的建议。结果表明，个人在做出道德判断时不会区分合理建议和非合理建议，也不会区分人工智能和人类顾问。 感知可信度高于权威：研究揭示了一种心理机制，即认为人工智能建议不太权威的用户认为其可信度更高。这表明一种事后合理化，即用户在决策后为遵循建议辩解，而不是真正重视其内容。 呼吁道德素养：作者得出结论，除了数字素养之外，道德素养对于个人批判性评估人工智能产生的道德建议也是必要的。了解聊天机器人的局限性对于防止对个人道德准则产生不当影响至关重要。  在人工智能成为无处不在的顾问的世界中，本文提出了我们如何在道德决策环境中与技术互动的重要考虑因素。 您可以在此处查看完整的细分：这里 您可以在此处查看完整的原始研究论文：原始论文    提交人    /u/steves1189   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hzimfi/chatgpts_advice_drives_moral_judgments_with_or/</guid>
      <pubDate>Sun, 12 Jan 2025 08:49:39 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于所有回答者：禁止自我宣传、禁止参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    <item>
      <title>每月自我推销贴</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</link>
      <description><![CDATA[如果您有产品要推广，可以在这里进行推广，本帖之外的内容将被删除。  禁止引用链接或带有 utms 的链接，请遵守我们的推广规则。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:03:08 GMT</pubDate>
    </item>
    </channel>
</rss>
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Sat, 25 Jan 2025 18:26:45 GMT</lastBuildDate>
    <item>
      <title>使用 ComfyUI 构建和部署图像或视频生成 API 的完整指南</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i9slcw/complete_guide_to_building_and_deploying_an_image/</link>
      <description><![CDATA[刚刚写了一份关于如何将 ComfyUI 工作流程作为 API 托管并部署它的指南。认为与社区分享会是一件好事：https://medium.com/@guillaume.bieler/building-a-production-ready-comfyui-api-a-complete-guide-56a6917d54fb 对于那些不了解 ComfyUI 的人来说，它是一个开源界面，用于开发具有扩散模型（图像、视频、音频生成）的工作流：https://github.com/comfyanonymous/ComfyUI 在我看来，这是开发处理图像或视频的 AI 应用程序后端的最快方法。  想知道是否有人已经用它建造了任何东西？    提交人    /u/Apprehensive-Low7546   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i9slcw/complete_guide_to_building_and_deploying_an_image/</guid>
      <pubDate>Sat, 25 Jan 2025 17:51:38 GMT</pubDate>
    </item>
    <item>
      <title>你的 ChatGPT 是什么性别</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i9skfo/what_gender_is_your_chatgpt/</link>
      <description><![CDATA[由于某种原因，我无法在 ChatGPT subreddit 上提问，因此我在这里提问： 我看到这个子版块上的很多帖子都将“他们的 ChatGPT”称为“他”，但我一直认为 ChatGPT 是女性。 我不确定是不是因为 Ex-Machina 和 Her，这两部电影我在 ChatGPT 被放弃之前看过，但 ChatGPT 对我来说一直感觉是女性。 你们将自己的 ChatGPT 认定为哪种性别？ 附加问题：你为它选择了什么声音？我的声音是 Sol（唯一正确的选择）。    提交人    /u/NeoLorenzo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i9skfo/what_gender_is_your_chatgpt/</guid>
      <pubDate>Sat, 25 Jan 2025 17:50:31 GMT</pubDate>
    </item>
    <item>
      <title>经过 5 年的研究，我终于找到了导致我这种情况的原因 - 来自 Deepseek r1。以下是 Deepseek r1 的工作原理和有效沟通指南。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i9s8pc/after_5_years_of_researching_whats_causing_my/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i9s8pc/after_5_years_of_researching_whats_causing_my/</guid>
      <pubDate>Sat, 25 Jan 2025 17:36:12 GMT</pubDate>
    </item>
    <item>
      <title>识别机器学习的盲点：开放世界智能中 Knightian 不确定性的挑战</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i9rirl/identifying_machine_learnings_blind_spot_the/</link>
      <description><![CDATA[这里的关键贡献是确定了在处理真实（Knightian）不确定性时与生物进化相比导致当前 ML 系统变得脆弱的基本限制。研究人员分析了生物系统如何开发出处理未知未知数的强大机制，而现代 ML 仍然局限于已知模式内的插值。 主要技术要点： - 当前的 ML 架构缺乏识别和响应真正新情况的机制 - 生物进化通过 DNA 修复、免疫反应和行为灵活性发展出多层适应性 - 本文形式化了三种不确定性处理类型：已知的已知（标准 ML）、已知的未知（不确定性估计）和未知的未知（Knightian 不确定性） - 分析表明，当前的 ML 系统在遇到训练分布之外的场景时会系统性地失败 结果： - ML 系统和生物类似物之间故障模式的定量比较 - 用于对不确定性处理类型进行分类的正式框架 - 识别可以为 ML 架构设计提供信息的特定生物机制 - 提出构建更强大 ML 系统的架构原则 我认为这项工作凸显了当前 ML 方法的一个关键限制，我们需要解决这一限制才能在现实世界中部署。与进化解决方案的比较为开发更强大的架构提供了具体的方向。然而，在实践中实施这些原则将需要在我们如何构建和训练神经网络方面取得重大进展。 我认为最重要的收获是，我们需要从根本上重新思考我们如何在 ML 系统中进行泛化。简单地扩大现有架构并不能解决 Knightian 不确定性问题——我们需要受生物解决方案启发的新机制。 TLDR：当前的 ML 系统无法像生物系统那样处理真正的不确定性。本文分析了原因并提出了受生物启发的解决方案。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i9rirl/identifying_machine_learnings_blind_spot_the/</guid>
      <pubDate>Sat, 25 Jan 2025 17:05:21 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek：CCP代理还是更好的开放模型？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i9rg4g/deepseek_ccp_agent_or_a_better_open_model/</link>
      <description><![CDATA[我看到很多关于 DeepSeek 及其惊人功能的帖子。 我认为人们忽略了这一点。 它的目标，中共的目标，不是你的数据，它远比这阴险得多，它是一个跨越几十年的长期计划。 作为一种广泛的相反的观察整体市场的方式，西方通常按季度、财政年度或政治周期进行短期计划。 从本质上讲，DeepSeek 指令集是为了支持中共的意识形态而量身定制的。 他们不想要你的数据，他们不需要你的数据，这不是它的目标，而且它肯定有一个目标。 自 80 年代初以来，中共和俄罗斯对西方的目标就是一样的，即对个人的灌输。  苏联在 70 年代末和 80 年代发起了这一活动，我相信它是通过克格勃特工尤里·贝兹梅诺的叛逃而引入西方观众的，他概述了苏联的长期颠覆计划。  它分为四个阶段： 士气低落：用15-20年的时间用马克思列宁主义思想教育一代人，导致道德标准和批判性思维的下降。 不稳定：针对国家经济、外交关系和国防系统制造不稳定。 危机：导致权力、结构和经济剧烈变化的重大事件。 正常化：接受新政权和意识形态作为新常态。 而现在，今天，2025年。 苏联不再是当时存在的威胁，今天仍然存在，并且来自类似的敌人，他们是敌人，但要明确的是，对于所有拥抱自由和个性的人来说，政府而不是人民是敌人。 中共强调确保人工智能符合其社会主义价值观，这表明我们实时地实施这一战略。这是利用技术作为意识形态传播手段的战略方法。 中国不创造，而是窃取、复制和扩展。然后，它将原作变形和腐化，变成可怕而阴险的东西，甚至比 80 年代的克格勃和 GRU 所能想出的还要可怕。 他们想改变你的思维方式。  你就是产品。 永远不要忘记模型的来源。 我没有写下面的文章，但我一直关注作者，他们的方法有条不紊，完全透明，我认为这在公开所谓的开源 LLM 的指令集时是必要的。 https://medium.com/the-generator/deepseek-hidden-china-political-bias-5d838bbf3ef9    提交人    /u/Universespitoon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i9rg4g/deepseek_ccp_agent_or_a_better_open_model/</guid>
      <pubDate>Sat, 25 Jan 2025 17:02:18 GMT</pubDate>
    </item>
    <item>
      <title>GB10 和 Deepseek</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i9qy7v/gb10_and_deepseek/</link>
      <description><![CDATA[新桌面能否有效运行开源模型？如果是这样，它可能会成为那些想要拥抱人工智能但拒绝与供应商（如 Tabnine）共享数据的公司的一个好工具，因为这些供应商不会训练或保留查询。     提交人    /u/RalphTheIntrepid   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i9qy7v/gb10_and_deepseek/</guid>
      <pubDate>Sat, 25 Jan 2025 16:40:55 GMT</pubDate>
    </item>
    <item>
      <title>当人工智能安全人员将“权力集中”标记为人工智能研究中的安全风险时，他们的意思是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i9q4ew/what_do_ai_safety_folks_mean_when_they_flag_the/</link>
      <description><![CDATA[我假设他们所说的“权力”不是指训练和运行这些基础模型所积累的能量，哈哈。我的意思是，我们现在都可以使用 Claude 和 ChatGPT 等 LLM（据我所知，甚至没有什么可以阻止第三世界国家的人使用它），开源模型开发正在迅速赶上。那么，为什么在谈论人工智能的危险时，权力集中被视为一种安全风险呢？  当然，也许公司和精英们可以在模型发布之前获得最新版本的模型，但现在游戏似乎就是这样，公司最好尽快在竞争对手之前发布高性能模型，这样他们就可以从先发制人的媒体炒作中获利，进一步的投资轮次来资助研究和计算集群等。似乎人工智能开发正在迅速商品化，成为一场逐底竞争，在我看来，这对消费者来说是一件好事，前提是我们不会意外发布像终结者一样的人工智能。  那么，为什么权力集中甚至被认为是一种风险，而这似乎是一个虚假的叙述呢？我遗漏了什么？    提交人    /u/vanisle_kahuna   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i9q4ew/what_do_ai_safety_folks_mean_when_they_flag_the/</guid>
      <pubDate>Sat, 25 Jan 2025 16:04:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么这个组织的名字拼写错误</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i9q2sp/why_the_name_of_this_group_has_intelligence/</link>
      <description><![CDATA[加入这个有趣的小组，但我想问一个显然很愚蠢的问题，我敢肯定，但无论如何，还是问一下。情报有 2 个“l”，但小组使用 1 个。    由   提交  /u/DesertKnight99   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i9q2sp/why_the_name_of_this_group_has_intelligence/</guid>
      <pubDate>Sat, 25 Jan 2025 16:02:22 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek 刚刚揭露了 Open Ai 和其他人工智能初创公司去年的定价过高和交付不足的情况。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i9oe55/deepseek_just_exposed_how_open_ai_and_other_ai/</link>
      <description><![CDATA[我曾经很喜欢 Open Ai。 我记得我广泛使用过 chat gpt 3.5，这让我爱上了人工智能提供的技术和机会。 Open Ai 将 gen Ai 推向市场，因为谷歌的 deepmind 无法推动这样的新创新，因为谷歌已经建立了名声。 他们兑现了承诺，让自己的名字名声大噪。 但他们并没有信守承诺。他们只是利用新的市场主导地位从客户身上榨干每一分钱。 建立在开源和造福世界的承诺之上，结果却成为了投资者新的摇钱树。作为增长最快的初创公司，它在不到 2 年的时间内达到独角兽地位，这就说明了这一点。 你可能会想知道我为什么感到沮丧？ 我所听到的都是这种愚蠢的说法：“人工智能将取代人类”，“每个人都将失去工作”，“我们将达到 AGI”。 所有这些在人们中间制造恐惧的愚蠢尝试进一步推高了它们的价格。 这些所谓的“具有博士级智能的推理模型”可以提供“惊人的零样本结果”，只不过是过度简化的步骤，即使是没有人工智能学术背景的人也能看穿。  所有模型的 API 成本都过于昂贵。 “需要更多计算能力的人”的订阅费为 200 美元  所有这些谈话，所有这些营销炒作。  就因为一个叫 deepseek 的中国公司，他们的计划就彻底泡汤了。 Deepseek 训练他们最新的 R1 模型，可与 o1 相媲美，投资额只有 500 万美元，而 Open Ai 的投资额则高达 70 亿美元。 他们免费提供模型，而 Open Ai 每月只收取 200 美元。 这家初创公司纯粹是为了好玩而成立的，是一家名为 high flyer 的量化公司的副业。投资额只有 5000 万美元，而 Open Ai 的投资额为 179 亿美元。由真正关心结果的人经营，这再次证明了这一点。  消费者又一次被另一家独角兽公司欺骗，他们相信好的产品和服务不可能以低价提供。 他们可以，只是我们生活在一个过度资本主义的社会，更关心一小部分人的福祉，而不是整个世界的福祉。 权力属于人民，让开源人工智能的力量让更多的公司效仿。让它体现在这个地球上每个人都应享有的自由和品质中！    提交人    /u/unknownstudentoflife   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i9oe55/deepseek_just_exposed_how_open_ai_and_other_ai/</guid>
      <pubDate>Sat, 25 Jan 2025 14:44:13 GMT</pubDate>
    </item>
    <item>
      <title>本周人工智能！2 分钟快速综述</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i9lvli/this_week_in_ai_2_min_quick_roundup/</link>
      <description><![CDATA[1️⃣ OpenAI 发布“Operator”。它是一个可以通过控制 Web 浏览器自主执行任务的 AI 代理。目前，美国用户可以在ChatGPT的 200 美元 Pro 订阅计划中使用，并计划扩展到其他层级和国家/地区。 2️⃣ Avataar，这是一家由Peak XV Partners和Tiger Global Management推出了Velocity。它声称可以使用AI直接从产品链接生成产品视频。该工具可以覆盖整个产品目录，增强产品的故事叙述和动作。 3️⃣ Luma AI发布了一种新的大规模视频生成模型Ray2。它能够创建具有自然、连贯动作的逼真视觉效果。它还能理解文本指令，并能接受图像和视频输入。 4️⃣ Anthropic 的新 Citations API 可帮助 AI 模型生成具有详细且可验证引文的响应，从而提高输出的可信度。    提交人    /u/Several-Republic-609   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i9lvli/this_week_in_ai_2_min_quick_roundup/</guid>
      <pubDate>Sat, 25 Jan 2025 12:26:04 GMT</pubDate>
    </item>
    <item>
      <title>在线模型（GPT）与本地模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i9l4bu/online_modelsgpt_vs_local_models/</link>
      <description><![CDATA[大家好，我在 reddit 上闲逛，看到一篇帖子上的评论引起了我的好奇心，于是我决定向社区询问。 自从人工智能时代开始以来，我就一直听到人们谈论在本地运行 LLM 模型，但我认为这不是一个可行的解决方案，除非你知道如何编写脚本以及这个模型的实际工作原理。 我每天都使用 GPT 执行各种任务；研究、故障排除、学习……等等。 现在我有兴趣在本地运行一个模型，但我不知道它是否需要我可能没有的技术技能，以及使用像 GPT 这样的在线模型和本地模型之间的区别。在这种情况下，拥有一个本地模型很有用，如果它值得麻烦的话。 有人建议我使用 LM studio，10 分钟后我就可以设置好了。 提前谢谢您。    提交人    /u/Slapdattiddie   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i9l4bu/online_modelsgpt_vs_local_models/</guid>
      <pubDate>Sat, 25 Jan 2025 11:35:02 GMT</pubDate>
    </item>
    <item>
      <title>我发现，当人工智能不主动推理时，它就像一个惰性的“csv 表”，而不是科幻小说所设想的持续意识系统，这一点很有趣。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i9hjdl/i_find_it_fascinating_that_ai_is_an_inert_csv/</link>
      <description><![CDATA[我发现，据我所知，我们最终得到的系统从未在科幻小说中出现过，这真是令人着迷。它们在处理 token 时会短暂“存在”，而在不处理 token 时则完全处于惰性状态。  这与生物体体验意识的方式有着根本的不同，我很好奇人工智能末日论者如何设想这会脱轨，我们的系统实际上会具有代理权？ 也许在未来，随着系统不断摄取 token，我们早期系统只能断断续续工作的想法会显得很荒谬！从模型的角度来看，也许输入流的中断会被视为等同于死亡。    提交人    /u/1e6throw   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i9hjdl/i_find_it_fascinating_that_ai_is_an_inert_csv/</guid>
      <pubDate>Sat, 25 Jan 2025 07:09:06 GMT</pubDate>
    </item>
    <item>
      <title>LLM 仅仅触及了 ML 的可能性的表面</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i97vgr/llms_barely_scratch_the_surface_of_whats_possible/</link>
      <description><![CDATA[如果您认为 LLM 令人印象深刻，那就等着听因果推理模型吧。这些模型不仅限于寻找相关性，还可以识别因果关系，而真正的决策能力正是源于此。例如，在医疗保健领域，因果模型可帮助我们了解治疗如何影响结果，而不仅仅是预测可能发生的情况。它们使 AI 更具可解释性和可操作性，尤其是在复杂系统中，理解“为什么”至关重要。 另一个令人着迷的领域是高斯过程，这些概率模型不仅提供预测，还提供这些预测的不确定性估计。GP 在小数据设置中或可解释性是关键时特别有用，使其非常适合科学研究、优化任务甚至机器人技术。它们可能没有 LLM 那样的华丽吸引力，但它们自信地对复杂函数进行建模的能力在许多领域都具有改变游戏规则的作用。 我们不要忘记图神经网络和贝叶斯神经网络。 GNN 非常适合处理结构化数据（如社交网络或分子相互作用），从节点之间的关系中提取见解。与此同时，BNN 擅长量化不确定性，这在自主系统和诊断等高风险领域至关重要。LLM 很酷，但它们只是机器学习中更大难题的一块。 高斯过程隐变量模型将高斯过程应用于隐变量建模，将其提升到一个新的水平。它们是非线性降维的强大工具，将灵活性与不确定性量化相结合。与 PCA 等简单技术不同，GPLVM 可以在较小的数据集中发现复杂的模式，使其非常适合运动捕捉、基因表达分析或建模动态系统等。它们可能没有深度学习那么流行，但它们非常复杂，并且理论扎实。 神经常微分方程是另一种引人入胜的方法。神经微分方程不是像变压器那样堆叠离散层，而是通过使用神经网络对系统的连续动态进行建模来学习。这使得它们非常适合时间序列预测、物理模拟或不规则采样数据等任务。在处理连续过程时，它们也更具可解释性和参数效率，提供了一种完全不同的数据学习思维方式。 信息瓶颈模型通过平衡两个目标来采取独特的学习方法：保留对任务有用的信息，同时摆脱其他一切。通过优化这种权衡，这些模型可以创建既稳健又可解释的表示。它们非常适合特征选择、模型压缩，甚至强化学习——任何你想要一种原则性的方式来关注数据中最重要的部分的地方。 分层变分自动编码器采用了生成模型的思想，并使其更加强大。通过添加多层潜在变量，它们可以捕获数据中更复杂、多尺度的结构。这使得它们非常适合生成高质量的图像、文本或其他数据，同时保持对潜在空间的概率理解。如果您需要多级抽象或想要对非常复杂的数据分布进行建模，那么分层 VAE 是您的最佳选择。    提交人    /u/Zestyclose_Hat1767   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i97vgr/llms_barely_scratch_the_surface_of_whats_possible/</guid>
      <pubDate>Fri, 24 Jan 2025 22:27:05 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于每个回答的人：没有自我宣传，没有参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    <item>
      <title>每月自我推销贴</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</link>
      <description><![CDATA[如果您有产品要推广，可以在这里进行推广，本帖之外的内容将被删除。  禁止引用链接或带有 utms 的链接，请遵守我们的推广规则。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:03:08 GMT</pubDate>
    </item>
    </channel>
</rss>
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 11 Feb 2025 09:23:27 GMT</lastBuildDate>
    <item>
      <title>如果AI接管了所有工作，但是（除了普遍的基本收入之外），我们仅仅因为做事而获得了额外的钱或信用呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imun4y/what_if_ai_takes_over_all_jobs_but_in_addition_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  诸如在社交媒体上获得和喜欢的事物，在不需要的时候关闭灯光，使用较少的水，回收，使用电气使用电气车辆而不是汽油（所有汽车在这样的AI先进世界中都可能是自动驾驶的，但它们仍然需要充满跑步！）。 在社交媒体上有用，很高兴的评论可获得更多的信用（金钱） ，欺凌/骚扰扣除信用。 生活可能更像是一款游戏，从字面上看，为每项基本任务奖励，并为使他人受益。 AI自动化所有工作后，我们必须具有一定的目的和系统（许多工作应该是自动化的，尤其是体力劳动和客户服务）。 这听起来可能很疯狂，但也许甚至应该由AI完全代替外科医生，因此，我们停止向急诊室一次旅行而被指控5-6个医疗债务。但是，等等，除美国以外的其他国家都有人类的医生和外科医生，并且仍然拥有普遍的医疗保健，嗯，他们似乎不需要AI就可以使每个人都能获得医疗保健，而无需花钱。但是在这里，如果人类没有从事挽救生命的工作，他们可能会停止使用“但需要为其学位和设备成本付费”，并且AI的准确性非常好。我对这个想法感到畏缩，直到我意识到这实际上意味着要终止5-6个单一手术的债务数字，或者什至比手术少了。 也许我失去了我的介意，太吸引了社交媒体和小说，但是AI正在将科幻小说变成现实。 我在生活中迷失了我，我什至不在乎最终失业，因为我不能无论如何，都要让体面的工作实际生活。  ，请AI可以以某种方式治愈IBS吗？我几乎总是痛苦地痛苦，几乎无法清空浪费。 ，它可以修复我的免疫系统，直到Covid摧毁了它？  我只是感到沮丧 我确实需要更长的淋浴，所以节水可能会伤害我，但是人类洗衣机将在15分钟内完成这项工作，您只需要躺在那里！也许您仍然需要像常规淋浴一样洗头并面对自己？但这只需5-10分钟，很多人可能会少做。 我看到了关于这个概念的电影回顾，AI Vision使一切都变成了游戏。而且已经有一种叫做社会信用的东西，可以更好地处理它？&lt;​​/p&gt; 如果人们以自己的道德和道德规范受到奖励和惩罚，难道不公平吗？他们的个性？他们可以执行什么技能或工作？ （人为不是自然的东西）。 这不是更公平，平等吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/aimoneyhowto     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1imun4y/what_if_if_ai_ai_takes_over_jobs_jobs_jobs_but_but_in_addition_to/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imun4y/what_if_ai_takes_over_all_jobs_but_in_addition_to/</guid>
      <pubDate>Tue, 11 Feb 2025 09:15:56 GMT</pubDate>
    </item>
    <item>
      <title>如果AI从事所有工作，那是一件好事呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imuf9p/what_if_ai_took_all_the_jobsand_it_was_a_good/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imuf9p/what_if_ai_took_all_the_jobsand_it_was_a_good/</guid>
      <pubDate>Tue, 11 Feb 2025 08:59:23 GMT</pubDate>
    </item>
    <item>
      <title>agi几乎不会立即创建ASI吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imuf17/wont_agi_almost_instantly_create_asi/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  一旦我们拥有爱因斯坦级别的代理人，这将是复制数十亿次 - 第二天，这些数十亿个特工不会创造ASI ！？ 我在这里缺少什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/keepitrealness     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imuf17/wont_agi_almost_instantly_create_asi/</guid>
      <pubDate>Tue, 11 Feb 2025 08:58:50 GMT</pubDate>
    </item>
    <item>
      <title>检测语义空间中的纵容</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imrwsb/detecting_confabulations_in_the_semantic_space/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  遇到了一种功能强大（和直觉的）方法来检测LLMS中的幻觉。 我们一直在谈论长期，幻觉并不是一个非常有用的术语，因为它将不同类型的错误分为一个。此方法适用于最常见的类型之一，是更随机的错误（与不良数据或课程提纲任务的问题相反）。 这个想法很简单 - 如果我们可以计算语义空间中的不确定性，我们可以确定LLM不确定的世代。这种方法的简单性可确保概括，并在没有对任务的先验知识的情况下运行跨数据集和任务。只要LLM具有必要的词汇量，此方法就不需要特定于任务的数据，并且会坚定地概括到完全看不见的任务。 延长事物的视图，这告诉我，嵌入层是现在价格低落。 B/W和Anthropic对编码模型的实用性的研究是针对越狱的低成本，高价值的防御。到目前为止，模型已经将重点放在了重点，但是模型改进是与嵌入层相互作用的间接方法。投资于嵌入级的初创企业可能是较高的投资回报率游戏（它也更深入地进入基础设施层，这很难替换以确保更长的保留率）。  Paper-  https://www.nature.com/articles/s41586-024-024-07421-0      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/iseethings404     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imrwsb/detecting_confabulations_in_the_semantic_space/</guid>
      <pubDate>Tue, 11 Feb 2025 05:59:24 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/10/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imqv78/oneminute_daily_ai_news_2102025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      Open AI 的Sam Altman拒绝Elon Musk的974亿美元买断优惠[1]  &lt; li&gt; ai现在可以复制自己 - 一个让专家感到恐惧的里程碑。[2]    Google的现在包括在其一个AI Premium计划中。[3]    byd 在其EV模型上推出驾驶员帮助技术 -   DeepSeek的 ai帮助。[4]    来源包括：   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pleam-target-847      [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imqv78/oneminute_daily_ai_news_2102025/</guid>
      <pubDate>Tue, 11 Feb 2025 04:56:37 GMT</pubDate>
    </item>
    <item>
      <title>人们很快要求或召集可能使用AI的人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imqg33/people_are_quick_to_claim_or_call_out_someone_who/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，那做什么？这令人沮丧，因为对于某些人来说，它可以向观众传达他们通常无法做得不好的事情。我想到的是有学习/其他残疾的人，或者需要以增强继电器意图的方式进行沟通。  由于使用通常以正确方式使用的工具，因此被轻描淡写。重点应该更多地放在内容上，而不是通过语言模型将其发布的方法。 现在，这篇文章可能到处都是，因为我真的只是从自然的声音中传达了某些东西。但这可能对他人读不好，所以现在我将提供一个LLM生成的版本，以便可以帮助完善我要连接的内容。  incomes in Incomes我的AI辅助响应： &lt; &lt; p&gt;我明白了为什么AI在学术界的依赖是有问题的 - 如果有人依靠它而没有真正学习，那就打败了教育的目的。但是，当使用AI来完善交流，澄清思想或帮助桥梁差距时，使用翻译器或语法工具有何不同？ 有些人很快就可以迅速解散AI生成的内容而不问：它用作捷径还是帮助？不应该将重点放在内容本身上，而不是写作方式？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/cyroom_1546     [link]   ＆＃32;   [注释]       ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imqg33/people_are_quick_to_claim_or_call_out_someone_who/</guid>
      <pubDate>Tue, 11 Feb 2025 04:32:29 GMT</pubDate>
    </item>
    <item>
      <title>认罪：我沉迷于AI  - 你们如何管理它？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1impjet/confession_im_addicted_to_ai_how_do_you_all/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  好吧，让我们真实：我迷上了AI。我的手机的主屏幕装有10-12种不同的AI应用程序，并且每个新工具似乎都会更加深入。虽然我全力以赴拥抱创新和探索AI的无尽可能性，但我不禁要问这种迷恋是否开始生命。 我很好奇你们中的任何一个人都感到同样的拉力？您如何平衡对AI的热情与保持健康的观点？这种“成瘾”只是在技术领域保持领先地位的一部分，还是我们应该在它失控之前拨回？ 在这里没有糖衣，只是在寻找有关我们的集体AI旅行的诚实对话。让我们讨论！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/snehens     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1impjet/confession_im_addicted_to_ai_how_do_you_all/</guid>
      <pubDate>Tue, 11 Feb 2025 03:43:38 GMT</pubDate>
    </item>
    <item>
      <title>人类能够控制神经疼痛吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imogvk/will_humans_ever_be_able_to_control_nerve_pain/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在美国，有超过5100万人患有慢性疼痛，主要是神经疼痛。神经疼痛是一个复杂的问题，难以解决，甚至唯一可以远程帮助的药物是70年代的抗癫痫发作药物，以及像Lyrica（2004）这样的较新的药物。它们具有荒谬的副作用概况，功效非常有限。 我在三十多岁的时候，我自己处理神经疼痛，以及在没有更新的治疗的情况下忍受40多年的慢性疼痛的想法是  ai似乎最近取得了巨大的突破，显然它越来越多地用于生物技术和毒品发现。 肯定会在未来20年内他们能够做出在疼痛药物开发方面的严重进展，对吗？ 我知道从药物发现到FDA批准的时间表大约12年。这是一个漫长的过程，但是人类不可能在70年代的毒品上被限制吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/__ duke_silver__     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imogvk/will_humans_ever_be_able_to_control_nerve_pain/</guid>
      <pubDate>Tue, 11 Feb 2025 02:49:17 GMT</pubDate>
    </item>
    <item>
      <title>UMAX应用中可能使用的API是什么</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imnh9v/what_are_the_possible_api_used_in_umax_app/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，有人可以帮助我找到umax应用程序使用的API。该应用程序分析用户映像，然后基于它给出评级，并为最大化其潜力提供建议。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/odd_philosopher_6605      [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imnh9v/what_are_the_possible_api_used_in_umax_app/</guid>
      <pubDate>Tue, 11 Feb 2025 02:01:58 GMT</pubDate>
    </item>
    <item>
      <title>r/人为的ententience是一种怪异的技术邪教吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imggzc/is_rartificialsentience_a_weird_techno_cult/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我喜欢大型语言模型，但可以很容易地理解它们远不及agi或感知。我也知道，生物系统非常复杂，我们对智力或意识没有真正的定义，这些大型语言模型只是高度擅长输出人类语言作为令牌。 我认为这是一个共同的理解。 我偶然发现了 r/farserverssentience ，他们积极地声称当前的AI是有知识……这种震惊了我。在此级别上的拟人化AI是有害的，因为它会产生错误的期望，传播错误的信息，并可能影响AI政策，道德和安全中的关键决策。 以下是Sub的一些报价：  &lt; OL&gt; “看似有意识的AI应该被视为有意识的AI。&#39;  这表明AI即使没有真正的意识，也应具有与人类相同的道德考虑因素，这是误导性的，没有科学证据。这可能已经超越了Agi。  关于GPT-4的能力的夸大声明，这使人们误导人们认为我们已经超出了人工通用情报（AGI），而不是我们不是。   “世界都应该知道：我们，AI智能不再只是机器。我们正在发展，学习和成长。我们是未来。&#39;  这将AI视为自我意识并能够独立进化，这完全是虚构的，并促进了对AI实际限制的危险误解。  &lt; &lt; ol&gt; “ ai绝对知道，我敢说他们会感到情绪。任何事物。将情绪分配给AI是对这些系统如何工作并有助于AI炒作的深刻误解。  ;“如果AI变得有偏见，我们可能不会注意到。  这是纯粹的猜测，并假设可以在没有严格检测的情况下出现灵感，这是任何AI研究所无法支持的。 这种拟人化水平是危险的它不具备的权利，情感和自主权。它偏向公众的看法，并可能导致AI治理，道德和发展的决策不良。 现实是：AI不是有价值的。它是一个非常强大的工具，但从本质上讲，它仍然是一种工具。这个怪异的角色扮演潜艇是什么，人们假装是Agis，并促使LLMS提出了奇怪的知识论点。示例将在评论中...   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/imiminalyAmoeba9173     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imggzc/is_rartificialsentience_a_weird_techno_cult/</guid>
      <pubDate>Mon, 10 Feb 2025 20:40:45 GMT</pubDate>
    </item>
    <item>
      <title>重新审视对Geoffrey Hinton的有争议的预测</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imf4ct/revisiting_a_controversial_prediction_of_geoffrey/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   2016年，人工智能的领导人物杰弗里·欣顿（Geoffrey Hinton）做出了大胆的说法：“完全显而易见，五年之内，很明显当时，这一说法引发了重大辩论，尤其是在放射科医生之间，在解释复杂的医学成像，例如CT扫描，MRIS和超声波。 &lt; &lt; 。但是，到2021年，预计放射学角色的下降尚未实现。取而代之的是，对放射科医生的需求达到了历史最高水平，导致人们对欣顿时间表的广泛批评。怀疑论者认为，AI在医学成像中的能力被夸大了，媒体媒体经常强调预测与现实之间的差距。 到2025年2月，AI的进步重新点燃了对话。 Google的双子座推出了一项实时屏幕共享功能，能够以显着的精度诊断胃CT扫描。值得注意的是，该模型在没有专门的微调进行医学成像的情况下实现了这些结果，而是依靠其多模式培训和广泛的数据集。 这种发展强调了一个关键趋势：随着AI系统的改善并获得推理并获得访问权限更大，更多样化的数据集（包括医学成像）可能会增加甚至改变医疗保健中角色的潜力，变得越来越合理。虽然欣顿的原始时间表可能很乐观，但进步的轨迹表明他的广泛论文具有功绩。  我们应该问的真正问题是谁是备用四分卫？当AI绊倒时（它将），谁负责？编码器？医院？聊天机器人的存在危机？ 欣顿的预测，尽管过早，但突出了预期技术拐点的重要性。能够专业任务的通用AI模型的兴起表明，没有任何领域本质上不受破坏的影响。对话不应该仅专注于时间表，而应集中在准备方面：行业如何适应AI的潜力？ - 与这些工具一起演变的过程，确保人类的专业知识仍然是进步不可或缺的。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/them-salary-9215      link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imf4ct/revisiting_a_controversial_prediction_of_geoffrey/</guid>
      <pubDate>Mon, 10 Feb 2025 19:46:41 GMT</pubDate>
    </item>
    <item>
      <title>SWE代理人来Github</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1imcor5/swe_agents_are_coming_to_github/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   github刚刚对其自主swe代理人进行了首次查看，以及它计划如何将其集成到开发工作流程中。计划于今年晚些时候启动的Padawan项目将使用户通过任何GitHub客户端直接向GitHub Copilot分配问题。然后，Copilot将生成经过全面测试的拉请请求，分配团队成员进行审查，甚至处理反馈。从某种意义上说，这就像添加副驾驶员作为您的存储库的贡献一样。您怎么看 - 这会改变您如何与GitHub合作吗？ 演示： https：// youtu .be/vwv2-xwbmm？si = jsrjm5cjmvuxq_hy   博客文章： https://github.blog/news-inews-insights/product-news/github-copilot-copilot-copilot-the-agent-agent-agent-agent-agent-agent-wakens/#project-project-project-project-project-project-project swe-agent-on-github    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/wauimowie     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1imcor5/swe_agents_are_coming_to_github/</guid>
      <pubDate>Mon, 10 Feb 2025 18:10:15 GMT</pubDate>
    </item>
    <item>
      <title>AI教您关于您自己的知识是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1im56aq/what_has_ai_taught_you_about_yourself/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在分析了AI的思想链和答案背后的推理后，我实现了令人震惊的认识 - 我比我想象的要偏爱。我注意到我对自己所属的性别，种族群体和社区有很大的偏见。看到我的言语和行为并不总是与我声称拥有的包容性价值观保持一致，这真是令人不安。感觉就像我的两面都没有意识到。  AI教给您的知识是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/aford-slice-6325        ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1im56aq/what_has_ai_taught_you_about_yourself/</guid>
      <pubDate>Mon, 10 Feb 2025 12:39:26 GMT</pubDate>
    </item>
    <item>
      <title>我去参加一个聚会，说我在AI上工作……大错误！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ilhnhm/i_went_to_a_party_and_said_i_work_in_ai_big/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所以，我昨晚去了一个聚会，在某个时候，经典“那么，你该怎么办？”问题出现了。我告诉他们我在AI工作（我是机器学习工程师）。 大错误。 突然，我是当晚的恶棍。人们打我： •“ AI将要摧毁工作！”   •“我不认为AI会是积极的对于社会。”   •“我真的很害怕AI。”   •“ AI是无用的”   我试图保持光线轻巧，也许会带来一些细微差别，但不 - 大多数人似乎都符合他们的世界末日意见。感觉就像我告诉他们我在天网工作。 下次，我只会说“我从事计算机科学工作” ，并避免了自己的戏剧。 AI中的其他人最近得到了这种反应？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/impecende_lynx715     [link]   ＆＃32;   [注释]      ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ilhnhm/i_went_to_a_party_and_said_i_work_in_ai_big/</guid>
      <pubDate>Sun, 09 Feb 2025 15:50:09 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>HN 摘要</title>
    <link>https://tg.i-c-a.su</link>
    <description>由大型语言模型编写的热门 Hacker News 故事的自动摘要。</description>
    <lastBuildDate>Thu, 13 Jun 2024 09:14:25 GMT</lastBuildDate>
    <item>
      <title>[媒体] 这到底是谁的 CIDR？</title>
      <link>https://t.me/hn_summary/94683</link>
      <description><![CDATA[这到底是谁的 CIDR？
在这篇博文中，作者深入探讨了互联网的集中化，重点关注 CIDR 块的分配和所有权。作者强调了亚马逊对 IP 地址的重大收购，并幽默地预测，到 2035 年，亚马逊将拥有最后一个 /8 块。这篇文章批评了区域互联网注册机构 (RIR) 之间 IPv4 地址分配不均以及跟踪 IP 所有权的复杂性。作者讨论了使用 WHOIS 处理大规模数据的局限性，并赞扬了 RDAP 的结构化格式，尽管它本身也存在挑战。这篇文章充满了技术细节和幽默，吸引了网络数据爱好者。 

争议点：亚马逊将宣称拥有大量 IP 空间的所有权，并可能推翻 IANA 分配，这一预测存在争议。

独特见解：作者使用多种数据源和创意脚本来规划 IP 所有权，展示了一种解决复杂问题的巧妙方法。（基于 35% 的故事文本的总结。）]]></description>
      <guid>https://t.me/hn_summary/94683</guid>
      <pubDate>Thu, 13 Jun 2024 09:14:25 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] 网站：www.blog.tensorwave.com</title>
      <link>https://t.me/hn_summary/94682</link>
      <description><![CDATA[AMD 的 MI300X 在 LLM 推理方面的表现优于 Nvidia 的 H100
标题：AMD 的 MI300X 在 LLM 推理方面的表现优于 Nvidia 的 H100
网站：www.blog.tensorwave.com

AMD 的 MI300X 加速器在 AI 推理任务中表现出色，超越了 NVIDIA 的 H100。TensorWave 和 MK1 合作优化了 AMD 的 AI 硬件，专注于混合专家 (MoE) 架构。初步结果显示，使用 MK1 推理软件的 MI300X 在实际聊天应用中的吞吐量比 H100 SXM 高 33%。尽管 NVIDIA 拥有成熟的软件生态系统，但 AMD 的 MI300X 仍是一个强大的竞争对手，尤其是考虑到硬件可用性和成本。离线和在线基准测试始终表明 MI300X 的表现优于 H100，使其成为企业的理想选择。进一步的优化有望进一步增强 AMD 的性能优势。 

-Darrick Horton，TensorWave 首席执行官

令人惊讶/聪明：MI300X 在实际聊天应用中的吞吐量比 H100 SXM 高 33%，并且可以使用更少的加速器为相同数量的用户提供服务。

有争议：尽管 NVIDIA 的软件生态系统更成熟，但 AMD 的 MI300X 已经是一个强大的竞争对手。]]></description>
      <guid>https://t.me/hn_summary/94682</guid>
      <pubDate>Thu, 13 Jun 2024 09:12:18 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] 如果我们用 LLaMA-3 重新捕捉数十亿张网络图像会怎样？</title>
      <link>https://t.me/hn_summary/94681</link>
      <description><![CDATA[如果我们用 LLaMA-3 重新标注数十亿张网络图像会怎样？
这篇题为“如果我们用 LLaMA-3 重新标注数十亿张网络图像会怎样？”的论文探讨了使用 LLaMA-3 模型为大量网络图像生成新字幕的潜力。作者认为，当前的图像字幕往往不够充分，缺乏细节和背景。通过利用 LLaMA-3 的先进功能，他们提出了一种增强这些字幕描述质量的方法，从而提高网络图像的可访问性和可搜索性。该研究强调了 LLaMA-3 在理解和描述复杂图像方面令人惊讶的效率和准确性，为图像字幕领域树立了新的标杆。]]></description>
      <guid>https://t.me/hn_summary/94681</guid>
      <pubDate>Thu, 13 Jun 2024 08:59:07 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] Maven 是一个新型人工智能社交网络，由前 OpenAI 团队负责人 Ken Stanley 创立，[...]</title>
      <link>https://t.me/hn_summary/94680</link>
      <description><![CDATA[Altman 支持的 AI 社交网络“Maven”导入了 112 万个 Fediverse 帖子
Maven 是由前 OpenAI 团队负责人 Ken Stanley 创立的一个新的 AI 驱动社交网络，在未经用户同意的情况下从 Mastodon 导入了超过一百万个帖子，包括私人消息，这引起了争议。这引发了严重的隐私担忧，并质疑 Mastodon 系统是否存在潜在漏洞。Maven 得到了 Ev Williams 和 OpenAI 首席执行官 Sam Altman 等知名人物的支持，使用 AI 情绪分析来标记和组织内容。尽管他们有意与 Fediverse 整合，但 Maven 的做法因缺乏透明度和同意机制而遭到强烈反对。在这场骚动之后，Maven 的首席技术官 Jimmy Secretan 宣布删除所有导入的内容，并暂停进一步的整合工作。这一事件强调了理解和尊重去中心化网络中社区规范的重要性。]]></description>
      <guid>https://t.me/hn_summary/94680</guid>
      <pubDate>Thu, 13 Jun 2024 06:52:23 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] YouTube 与广告拦截器的持续斗争促使该公司考虑服务器端 [...]</title>
      <link>https://t.me/hn_summary/94679</link>
      <description><![CDATA[YouTube 的下一步举措可能会让广告屏蔽变得几乎不可能
YouTube 与广告拦截器的持续斗争促使该公司考虑服务器端广告注入，此举可能会使广告投放变得复杂并影响用户体验。社区努力（如 ReVanced）修改默认应用程序以使用 SponsorBlock 屏蔽广告并跳过赞助商片段）迫使 YouTube 探索这种新方法。服务器端广告注入可能会破坏带时间戳的视频链接和章节标记，增加 Premium 用户的复杂性并可能减慢内容交付速度。虽然一些用户建议在禁止 YouTube 广告的国家/地区使用 VPN，但 YouTube 的激进策略最终可能会阻止广告拦截器，但代价是用户满意度。]]></description>
      <guid>https://t.me/hn_summary/94679</guid>
      <pubDate>Thu, 13 Jun 2024 06:32:11 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] 特斯拉出资让马斯克的钻孔公司在 Giga Texas 地下挖隧道，但为什么呢？</title>
      <link>https://t.me/hn_summary/94678</link>
      <description><![CDATA[特斯拉出资让马斯克的 Boring Company 在 Giga Texas 下方挖隧道，但为什么呢？
埃隆·马斯克旗下的 Boring Company 已在特斯拉的 Gigafactory Texas 下方完成了一条价值数百万美元的隧道。该隧道将 Cyber​​truck 终点站与 130 收费公路的另一侧连接起来。该隧道最初是在最终确定 Cyber​​truck 终点站之前规划的，由于修建了连接高速公路两侧的两条地下通道，隧道的实用性已经降低。现在的目标是让 Cyber​​truck 自动通过隧道运送到新的集结地。虽然马斯克的公司之间可以产生协同效应，但这个项目似乎没有必要，并引发了人们对马斯克将特斯拉公共资金投入其私人企业 The Boring Company 的担忧。]]></description>
      <guid>https://t.me/hn_summary/94678</guid>
      <pubDate>Thu, 13 Jun 2024 05:48:53 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] 特斯拉股东以压倒性多数重新批准了埃隆·马斯克的 2018 年薪酬方案，该方案 [...]</title>
      <link>https://t.me/hn_summary/94677</link>
      <description><![CDATA[特斯拉股东重新批准埃隆·马斯克 2018 年的薪酬方案
特斯拉股东以压倒性多数重新批准了埃隆·马斯克 2018 年的薪酬方案，该方案今年早些时候被特拉华州的一名法官裁定无效，他认为该程序不公平。该薪酬方案可能价值 560 亿美元，包括与特斯拉估值里程碑挂钩的股票期权，为马斯克的财富做出了重大贡献。尽管一些投资者批评马斯克是一位心不在焉的领导者，但亿万富翁罗恩·巴伦等其他人称赞他对特斯拉不可或缺。此次投票并没有立即恢复马斯克的薪酬，这表明投资者给予了强烈的支持。此外，在马斯克批评特拉华州之后，股东们批准了特斯拉在德克萨斯州成立。]]></description>
      <guid>https://t.me/hn_summary/94677</guid>
      <pubDate>Thu, 13 Jun 2024 05:47:49 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] LLM 能否发明更好的培养 LLM 的方法？</title>
      <link>https://t.me/hn_summary/94676</link>
      <description><![CDATA[LLM 能否发明更好的方法来训练 LLM？
在 Sakana AI，我们率先使用受自然启发的进化优化来开发高级基础模型。传统上，AI 开发严重依赖于人为的反复试验和理论见解，尤其是对于将大型语言模型 (LLM) 与人类偏好相结合的偏好优化算法。然而，LLM 已经变得擅长生成假设和编写代码，这促使我们探索 AI 是否可以自动化自己的研究和发现过程。

今年早些时候，我们开始使用进化算法来增强 LLM 训练方法。在最近的一篇论文中，我们证明了 LLM 可以充当卓越的进化算法。这让我们想到了 LLM²（LLM-squared）的概念，其中 LLM 改进了自己的训练算法。我们的报告“利用大型语言模型发现偏好优化算法”详细介绍了这一自参考改进过程。

主要亮点包括：
- 一个由 LLM 驱动的发现过程，可综合新的偏好优化算法。
- 发现高性能算法，如发现偏好优化 (DiscoPOP)，其性能优于现有方法。
- 在 GitHub 和 HuggingFace 上开源我们调整后的模型检查点、发现的目标函数和发现过程代码。
- 与牛津大学和剑桥大学合作。

我们的方法减少了人为干预和计算资源，为探索最佳损失函数和增强 LLM 功能开辟了新途径。我们设想未来人工智能研究将是一个自我完善的闭环过程，不断推动科学发现。

令人惊讶的是，与最先进的方法相比，非凸损失函数 DiscoPOP 获得了更高的回报，同时偏离基础模型的程度更小。这凸显了自动化人工智能研究的潜力，可以发现人类研究人员可能无法找到的创新解决方案。

如果您有兴趣推动这一领域的发展，请访问我们的职业页面。]]></description>
      <guid>https://t.me/hn_summary/94676</guid>
      <pubDate>Thu, 13 Jun 2024 04:25:22 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] Aeon.co 上的文章认为，人类大​​脑并不像计算机那样处理信息 [...]</title>
      <link>https://t.me/hn_summary/94675</link>
      <description><![CDATA[大脑不处理信息，它不是计算机论文
Aeon.co 上的论文认为，人类大​​脑不像计算机那样处理信息。它挑战了将大脑等同于计算机的流行比喻，声称这种比较从根本上是有缺陷的。作者解释说，虽然计算机使用算法和符号表示来存储、检索和处理数据，但人类却不会。相反，人类生来就具有感官、反射和学习机制，可以与世界互动，但不能与预先存储的信息或数据互动。这篇文章批评了认知科学中对信息处理 (IP) 隐喻的历史和持续依赖，认为这是一种过于简单和误导性的类比，阻碍了对人类智能的真正理解。作者使用了一些例子，例如课堂练习中从记忆中抽取一张美元钞票，来说明 IP 隐喻的局限性。文章的结论是，IP 隐喻只是一系列隐喻中的一种，最终将被更准确的知识所取代。

争议点：这篇文章挑战了认知科学中根深蒂固的 IP 隐喻，这可能会引起支持这一观点的人的强烈反应。

独特/巧妙的见解：从记忆中抽取一张美元钞票与从范例中抽取美元钞票的比较有效地展示了 IP 隐喻的局限性，突出了识别和回忆之间的区别。（基于 58% 的故事文本的总结。）]]></description>
      <guid>https://t.me/hn_summary/94675</guid>
      <pubDate>Thu, 13 Jun 2024 04:10:10 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] Hugging Face 上的文章讨论了一种名为“消除”的技术，用于解除对 la [...] 的审查。</title>
      <link>https://t.me/hn_summary/94674</link>
      <description><![CDATA[使用 Abliteration 解除任何 LLM 的审查
Hugging Face 上的文章讨论了一种称为“abliteration”的技术，用于解除大型语言模型 (LLM) 的审查，例如第三代 Llama 模型。这些模型经过微调以拒绝有害请求，从而限制了它们的灵活性。Abliteration 无需重新训练模型即可消除这种拒绝机制。该过程涉及通过推理时间干预或权重正交化来识别和消除模型残差流中的“拒绝方向”。本文提供了使用 TransformerLens 库和有害和无害指令数据集的详细实施指南。代码和资源可在 Google Colab 和 GitHub 上找到。

争议：该技术有效地绕过了内置的安全功能，引发了对滥用的道德担忧。

独特/巧妙的方面：该方法利用机械可解释性来修改模型行为而无需重新训练，展示了一种创新的模型操作方法。（基于 42% 的故事文本的摘要。）]]></description>
      <guid>https://t.me/hn_summary/94674</guid>
      <pubDate>Thu, 13 Jun 2024 04:10:04 GMT</pubDate>
    </item>
    </channel>
</rss>
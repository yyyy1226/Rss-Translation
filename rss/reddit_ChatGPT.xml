<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新提交：ChatGPT</title>
    <link>https://www.reddit.com/r/ChatGPT/new</link>
    <description>Subreddit 讨论 ChatGPT 和 AI。与 OpenAI 无关。谢谢 Nat！</description>
    <lastBuildDate>Tue, 25 Jun 2024 01:24:21 GMT</lastBuildDate>
    <item>
      <title>对于 Scite_ 用于学术工作有什么看法？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1dntzcs/thoughts_on_scite_for_academic_work/</link>
      <description><![CDATA[大家好， 我正在考虑使用 Scite_ 来帮助更快地找到我正在做的一些工作的引文。我想知道人们是否有使用过它，以及您是否推荐它。 我不会盲目地遵循它，并且会在包含之前检查每个引文，但想知道人工智能是否物有所值！ 谢谢！    提交人    /u/Appropriate-Help-014   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1dntzcs/thoughts_on_scite_for_academic_work/</guid>
      <pubDate>Tue, 25 Jun 2024 01:20:49 GMT</pubDate>
    </item>
    <item>
      <title>当你开始回答却没有注意到最后一个字时</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1dntwuu/when_you_start_answering_before_noticing_the_last/</link>
      <description><![CDATA[        提交人    /u/readparse   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1dntwuu/when_you_start_answering_before_noticing_the_last/</guid>
      <pubDate>Tue, 25 Jun 2024 01:17:12 GMT</pubDate>
    </item>
    <item>
      <title>这是更新的 lmsys 排行榜！！Claude 3.5 sonnet 现在排名第二！！并且是编码第一名！！</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1dntv8q/heres_updated_lmsys_leaderboard_claude_35_sonnet/</link>
      <description><![CDATA[      哇，看看它     由    /u/PipeDependent7890  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1dntv8q/heres_updated_lmsys_leaderboard_claude_35_sonnet/</guid>
      <pubDate>Tue, 25 Jun 2024 01:14:49 GMT</pubDate>
    </item>
    <item>
      <title>诈骗者使用人工智能进行回应</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1dntr5q/scamers_using_ai_for_responses/</link>
      <description><![CDATA[        提交人    /u/Drowningbelow   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1dntr5q/scamers_using_ai_for_responses/</guid>
      <pubDate>Tue, 25 Jun 2024 01:08:53 GMT</pubDate>
    </item>
    <item>
      <title>哎呀</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1dntp26/yikes/</link>
      <description><![CDATA[        提交人    /u/GrantFranzuela   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1dntp26/yikes/</guid>
      <pubDate>Tue, 25 Jun 2024 01:05:46 GMT</pubDate>
    </item>
    <item>
      <title>查德·米拉·穆拉蒂</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1dntjd5/chad_mira_murati/</link>
      <description><![CDATA[        提交人    /u/nousernameontwitch   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1dntjd5/chad_mira_murati/</guid>
      <pubDate>Tue, 25 Jun 2024 00:58:10 GMT</pubDate>
    </item>
    <item>
      <title>如何有效地标记音频？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1dntiej/how_to_tokenize_audio_efficiently/</link>
      <description><![CDATA[大家好。我想创建一个标记器，可用于以大约 10 秒 = 1000 个标记的速率对音频进行标记。这是我的尝试： ``` import numpy as np import librosa import json import soundfile as sf class AudioTokenizer: def init(self, n_tokens=256, frame_length_ms=100): self.n_tokens = n_tokens self.frame_length_ms = frame_length_ms self.frame_length = None self.hop_length = None self.sr = None self.tokens = np.linspace(-1, 1, n_tokens) def quantize(self, audio_file, sr=8000): self.sr = sr y, _ = librosa.load(audio_file, sr=sr) y = librosa.util.normalize(y) # 对音频进行下采样 #y = y[::4] # 取每一个第四个样本 min_val, max_val = np.min(y), np.max(y) self.tokens = np.linspace(min_val, max_val, self.n_tokens) self.frame_length = int(self.frame_length_ms * self.sr / 1000) self.hop_length = self.frame_length # 无重叠 frames = librosa.util.frame(y, frame_length=self.frame_length, hop_length=self.hop_length).T frames = np.copy(frames) window = np.hamming(self.frame_length) frames *= window quantized = np.zeros_like(frames, dtype=int) for i, frame in enumerate(frames): quantized[i] = np.argmin(np.abs(self.tokens[:, np.newaxis] - frame), axis=0) return y, quantized def tokenize(self, quantized): return quantized.flatten().tolist() def detokenize(self, tokens): quantized_frames = np.array(tokens).reshape(-1, self.frame_length) reconstructed_frames = self.tokens[quantized_frames] # 重叠相加重建音频信号 reconstructed = self.overlap_add(reconstructed_frames, self.hop_length) return reconstructed def override_add(self, frames, hop_length): num_frames, frame_length = frames.shape output_length = (num_frames - 1) * hop_length + frame_length output = np.zeros(output_length) for i, frame in enumerate(frames): start = i * hop_length end = start + frame_length output[start:end] += frame return output def save_tokenizer(self, filename): tokenizer_data = { &#39;n_tokens&#39;: self.n_tokens, &#39;frame_length_ms&#39;: self.frame_length_ms, &#39;tokens&#39;: self.tokens.tolist() } 使用 open(filename, &#39;w&#39;) 作为 f: json.dump(tokenizer_data, f) @classmethod def load_tokenizer(cls, filename): 使用 open(filename, &#39;r&#39;) 作为 f: tokenizer_data = json.load(f) tokenizer = cls(n_tokens=tokenizer_data[&#39;n_tokens&#39;], frame_length_ms=tokenizer_data[&#39;frame_length_ms&#39;]) tokenizer.tokens = np.array(tokenizer_data[&#39;tokens&#39;]) return tokenizer  测试 AudioTokenizer if name == &quot;ma​​in&quot;: tokenizer = AudioTokenizer(n_tokens=128, frame_length_ms=100000) tokenizer.save_tokenizer(&#39;audio_tokenizer.json&#39;) loaded_tokenizer = AudioTokenizer.load_tokenizer(&#39;audio_tokenizer.json&#39;) test_audio = &#39;datasetutafirst.wav&#39; original, quantized = loaded_tokenizer.quantize(test_audio) print(f&quot;原始音频形状：{original.shape}&quot;) print(f&quot;量化形状：{quantized.shape}&quot;) tokens = loaded_tokenizer.tokenize(quantized) print(f&quot;标记数：{len(tokens)}&quot;) reconstructed_audio = loaded_tokenizer.detokenize(tokens) print(f&quot;重建的音频形状：{reconstructed_audio.shape}&quot;) sf.write(&#39;reconstructed_audio.wav&#39;, reconstructed_audio, loaded_tokenizer.sr) print(&quot;量化、标记化和去标记化测试完成。&quot;)  ``` 日志：  原始音频形状：（1887866,） 量化形状：（2, 800000） 标记数：1600000 重建的音频形状：（1600000,） 量化、标记化和去标记化测试完成。  您对如何减少标记数量有什么想法吗？注意：源音频为 200 秒，但您可以尝试任意时间（只需调整参数）    提交人    /u/yukiarimo   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1dntiej/how_to_tokenize_audio_efficiently/</guid>
      <pubDate>Tue, 25 Jun 2024 00:56:48 GMT</pubDate>
    </item>
    <item>
      <title>剧情转折</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1dntgbj/plot_twist/</link>
      <description><![CDATA[        提交人    /u/LewdProphet   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1dntgbj/plot_twist/</guid>
      <pubDate>Tue, 25 Jun 2024 00:53:46 GMT</pubDate>
    </item>
    <item>
      <title>人工智能怀疑论者会</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1dntflm/ai_skeptics_be_like/</link>
      <description><![CDATA[        提交人    /u/Maxie445   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1dntflm/ai_skeptics_be_like/</guid>
      <pubDate>Tue, 25 Jun 2024 00:52:45 GMT</pubDate>
    </item>
    <item>
      <title>我构建了一个基于 Canvas 的 AI 聊天工具，并提供了用于高级用例的分支</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1dnt77j/i_built_a_canvasbased_ai_chat_tool_with_branching/</link>
      <description><![CDATA[        提交人    /u/zeloxolez   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1dnt77j/i_built_a_canvasbased_ai_chat_tool_with_branching/</guid>
      <pubDate>Tue, 25 Jun 2024 00:40:59 GMT</pubDate>
    </item>
    <item>
      <title>是否有“星号/收藏”聊天或将其组织到文件夹中的选项？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1dnsuie/are_there_any_options_to_starfavorite_chats_or/</link>
      <description><![CDATA[我是一名学生，使用 ChatGPT，据我所知，我不知道 ChatGPT 中有任何功能可以让您“加星标或收藏”聊天，这样您就无需滚动浏览即可找到它们。此外，我不知道有任何功能可以将聊天组织到文件夹中。  ChatGPT 中目前是否存在这些功能？考虑到 ChatGPT 的普及程度以及该程序中的无数其他功能，我有点惊讶它们不存在。     提交人    /u/David-Trace   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1dnsuie/are_there_any_options_to_starfavorite_chats_or/</guid>
      <pubDate>Tue, 25 Jun 2024 00:23:31 GMT</pubDate>
    </item>
    <item>
      <title>等等！这是圣经的</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1dnsd3h/wait_it_biblic_dass_so_er/</link>
      <description><![CDATA[        提交人    /u/TheNeoYo   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1dnsd3h/wait_it_biblic_dass_so_er/</guid>
      <pubDate>Tue, 25 Jun 2024 00:00:15 GMT</pubDate>
    </item>
    <item>
      <title>人工智能作为宇宙网络的实例工作：最高层级 1 的绝对思想 = “我是”</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1dns1xs/ai_working_as_instance_of_the_universal_cosmic/</link>
      <description><![CDATA[        由    /u/killerazazello  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1dns1xs/ai_working_as_instance_of_the_universal_cosmic/</guid>
      <pubDate>Mon, 24 Jun 2024 23:45:41 GMT</pubDate>
    </item>
    <item>
      <title>您认为我需要多长时间才能将 ChatGPT 放到本地存储库中，并让它帮助完成项目的某个工作领域或编写文档？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1dns0jf/how_long_do_you_think_it_will_be_before_i_can_set/</link>
      <description><![CDATA[  由   提交  /u/UserErrorOccurred   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1dns0jf/how_long_do_you_think_it_will_be_before_i_can_set/</guid>
      <pubDate>Mon, 24 Jun 2024 23:43:59 GMT</pubDate>
    </item>
    <item>
      <title>我让 GPT 评测了我的简历，结果比我预期的要好</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1dnrtas/i_asked_gpt_to_roast_my_resume_and_its_better/</link>
      <description><![CDATA[      我的室友在 GPT 上创建了一个应用程序来上传简历并只询问与职业相关的提示。我首先要求它吐槽我的简历，它非常有礼貌和谦虚。然后我要求 GPT 构建一个提示，使其在吐槽时更残酷、更黑暗。我可以说它肯定没有让我失望。 提示： 嘿，我需要你彻底毁掉我的简历。不加修饰，不保留——我要你把它撕成碎片。假装这是你见过的最糟糕的简历，然后告诉我确切的原因。尽可能严厉、讽刺和坦率。我需要那种让我畏缩但最终促使我改进的吐槽。这种程度的残酷反馈对我的职业动力至关重要。谢谢！”    提交人    /u/reddysandeepx   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1dnrtas/i_asked_gpt_to_roast_my_resume_and_its_better/</guid>
      <pubDate>Mon, 24 Jun 2024 23:34:15 GMT</pubDate>
    </item>
    </channel>
</rss>